{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02897b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from time import time\n",
    "import argparse \n",
    "import sys\n",
    "sys.argv=['']\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader, TensorDataset,random_split\n",
    "import glob\n",
    "import natsort\n",
    "from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "#from tools import *\n",
    "#from wake_model_WITH_ERRORS import *\n",
    "import PIL.ImageOps\n",
    "import pandas as pd\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e7856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce17873",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411c73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Convolutional layers in the dense blocks\n",
    "\n",
    "class conv_layer(nn.Module):\n",
    "    def __init__(self,init_features,k_size,p,growth_rate,bn_size,drop_out,bottleneck):\n",
    "        super(). __init__()\n",
    "        if bottleneck and init_features>growth_rate*bn_size:\n",
    "            self.conv=nn.Sequential(\n",
    "                nn.BatchNorm2d(init_features),\n",
    "                nn.ReLU(inplace='True'),\n",
    "                nn.Conv2d(init_features,growth_rate*bn_size,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "                nn.BatchNorm2d(growth_rate*bn_size),\n",
    "                nn.ReLU(inplace='True'),\n",
    "                nn.Conv2d(growth_rate*bn_size,growth_rate,kernel_size=k_size,stride=1,padding=p,bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.conv=nn.Sequential(\n",
    "                nn.BatchNorm2d(init_features),\n",
    "                nn.ReLU(inplace='True'),\n",
    "                nn.Conv2d(init_features,growth_rate,kernel_size=k_size,stride=1,padding=p,bias=False)\n",
    "            )\n",
    "        self.drop_out=drop_out\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.conv(x)\n",
    "        if self.drop_out>0:\n",
    "            out = F.dropout(out, p=self.drop_out)\n",
    "        return torch.cat([x,out],1)\n",
    "            \n",
    "class Dense_block(nn.Module):\n",
    "    def __init__(self,init_features,conv_layer,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck):\n",
    "        super().__init__()\n",
    "        self.layer = self._make_layer(init_features,k_size,p,n_layers,conv_layer,growth_rate,bn_size,drop_out,bottleneck)\n",
    "    def _make_layer(self,init_features,k_size,p,n_layers,conv_layer,growth_rate,bn_size,drop_out,bottleneck):\n",
    "        layers=[]\n",
    "        for i in range(n_layers):\n",
    "            layers.append(conv_layer(init_features+i*growth_rate,k_size,p,growth_rate,bn_size,drop_out,bottleneck))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "class Encode_Decode(nn.Module):\n",
    "    def __init__(self,init_features,out_features,k_size,p,growth_rate,drop_out,down,bottleneck,output_padding):\n",
    "        super().__init__()\n",
    "        self.drop_out=drop_out\n",
    "        if down:\n",
    "            if bottleneck:\n",
    "                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(init_features,out_features,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(out_features,out_features,kernel_size=k_size,stride=2,padding=p,bias=False)\n",
    "                    )\n",
    "            else:\n",
    "                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(init_features,out_features,kernel_size=k_size,stride=2,padding=p,bias=False)\n",
    "                    )\n",
    "        else:\n",
    "            if bottleneck:\n",
    "                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(init_features,out_features,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(out_features,out_features,kernel_size=k_size,stride=2,padding=p,output_padding=output_padding,bias=False)\n",
    "                    )\n",
    "                \n",
    "            else:\n",
    "                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(out_features,out_features,kernel_size=k_size,stride=2,padding=p,output_padding=output_padding,bias=False)\n",
    "                                         )\n",
    "    def forward(self,x):\n",
    "        out=self.block1(x)\n",
    "        if self.drop_out>0:\n",
    "            out = F.dropout(out, p=self.drop_out)\n",
    "        return out\n",
    "                \n",
    "class last_decode(nn.Module):\n",
    "    def __init__(self,init_features,out_channels,kernel_size,stride,padding,output_padding,drop_out):\n",
    "        super().__init__()\n",
    "        self.norm1=nn.BatchNorm2d(init_features)\n",
    "        self.relu1=nn.ReLU(inplace=True)\n",
    "        self.conv1=nn.Conv2d(init_features,init_features//2,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.norm2=nn.BatchNorm2d(init_features//2)\n",
    "        self.relu2=nn.ReLU(inplace=True)\n",
    "        self.conv2=nn.ConvTranspose2d(init_features//2,out_channels,kernel_size,stride,padding,output_padding,bias=False)\n",
    "        self.drop_out=drop_out\n",
    "    def forward(self,x):\n",
    "        out=self.conv1(self.relu1(self.norm1(x)))\n",
    "        out=self.conv2(self.relu2(self.norm2(out)))\n",
    "        if self.drop_out>0:\n",
    "            out = F.dropout(out, p=self.drop_out)\n",
    "        return out        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7815369",
   "metadata": {},
   "source": [
    "## Two added layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f2cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_C8_skip_more_one(nn.Module):\n",
    "    def __init__(self,in_channels,k_size,x1,x2,x3,x4,out_channels,init_features0,growth_rate,bn_size,bottleneck,drop_out):\n",
    "        super().__init__()\n",
    "        block=conv_layer\n",
    "        self.conv1=nn.Conv2d(in_channels,init_features0,kernel_size=6, stride=2, padding=2,bias=False)\n",
    "        \n",
    "        \n",
    "        if k_size==11:\n",
    "            \n",
    "            p=5\n",
    "        if k_size==9:\n",
    "            \n",
    "            p=4\n",
    "        elif k_size==7:\n",
    "         \n",
    "            p=3\n",
    "        elif k_size==5:\n",
    "         \n",
    "            p=2\n",
    "        elif k_size==3:\n",
    "       \n",
    "            p=1\n",
    "        self.x1=x1\n",
    "        self.x2=x2\n",
    "        self.x3=x3\n",
    "        self.x4=x4\n",
    "        \n",
    "        ######\n",
    "\n",
    "        n_layers=2\n",
    "        self.dense_block1=Dense_block(init_features0,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features1=init_features0+growth_rate*n_layers\n",
    "        self.encode1=Encode_Decode(in_features1,in_features1//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "  \n",
    "        n_layers=2\n",
    "        self.dense_block2=Dense_block(in_features1//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features11=in_features1//2+growth_rate*n_layers\n",
    "        self.encode2=Encode_Decode(in_features11,in_features11//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block22=Dense_block(in_features11//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features111=in_features11//2+growth_rate*n_layers\n",
    "        self.encode22=Encode_Decode(in_features111,in_features111//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block222=Dense_block(in_features111//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features111//2+growth_rate*n_layers\n",
    "        self.encode222=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        \n",
    "        n_layers=4\n",
    "        self.dense_block3=Dense_block(in_features//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features//2+growth_rate*n_layers\n",
    "        self.decode1=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x1==1:\n",
    "            in_features=in_features//2+in_features111//2\n",
    "        elif self.x1==0:\n",
    "            in_features=in_features//2\n",
    "        self.dense_block4=Dense_block(in_features,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features+growth_rate*n_layers\n",
    "        self.decode2=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x2==1:\n",
    "            in_features44=in_features//2+in_features11//2\n",
    "        elif self.x2==0:\n",
    "            in_features44=in_features//2\n",
    "        self.dense_block44=Dense_block(in_features44,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features44+growth_rate*n_layers\n",
    "        self.decode22=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x3==1:\n",
    "            in_features444=in_features//2+in_features1//2\n",
    "        elif self.x3==0:\n",
    "            in_features444=in_features//2\n",
    "        self.dense_block444=Dense_block(in_features444,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features444+growth_rate*n_layers\n",
    "        self.decode222=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x4==1:\n",
    "            in_features2=in_features//2+init_features0\n",
    "        elif self.x4==0:\n",
    "            in_features2=in_features//2\n",
    "        self.dense_block5=Dense_block(in_features2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features2+growth_rate*n_layers\n",
    "        self.last=last_decode(in_features,out_channels,kernel_size=4,stride=2,padding=1,output_padding=0,drop_out=0)\n",
    "    def forward(self,x):\n",
    "        out1=self.conv1(x)\n",
    "        #print(out1.size())\n",
    "        out2=self.encode1(self.dense_block1(out1))\n",
    "        #print(out2.size())\n",
    "        out3=self.encode2(self.dense_block2(out2))\n",
    "        #print(out3.size())\n",
    "        out33=self.encode22(self.dense_block22(out3))\n",
    "       # print(out33.size())\n",
    "        out333=self.encode222(self.dense_block222(out33))\n",
    "       # print(out333.size())\n",
    "        out4=self.decode1(self.dense_block3(out333))\n",
    "        #print(out4.size())\n",
    "        if self.x1==1:\n",
    "            out4=torch.cat([out4, out33], 1)\n",
    "        elif self.x1==0:\n",
    "            out4=out4\n",
    "       # print(out4.size())\n",
    "        out4=self.dense_block4(out4)\n",
    "        #print(out4.size())\n",
    "        out5=self.decode2(out4)\n",
    "        #print('------')\n",
    "        #print(out5.size())\n",
    "        if self.x2==1:\n",
    "            out5=torch.cat([out5, out3], 1)\n",
    "        elif self.x2==0: \n",
    "            out5=out5\n",
    "        out55=self.decode22(self.dense_block44(out5))\n",
    "        if self.x3==1:\n",
    "            out55=torch.cat([out55, out2], 1)\n",
    "        elif self.x3==0:\n",
    "            out55=out55\n",
    "            \n",
    "        out55=self.decode222(self.dense_block444(out55))\n",
    "        if self.x4==1:\n",
    "            out5=torch.cat([out55, out1], 1)\n",
    "        elif self.x4==0:\n",
    "            out5=out55\n",
    "        out=self.dense_block5(out5)\n",
    "        out=self.last(out)\n",
    "        #Try different activations when we change activation, input images should be scaled to the same range\n",
    "        self.activation=nn.Sigmoid()\n",
    "        out=self.activation(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805119fa",
   "metadata": {},
   "source": [
    "## One added layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f180eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_C8_skip_more(nn.Module):\n",
    "    def __init__(self,in_channels,k_size,x1,x2,x3,x4,out_channels,init_features0,growth_rate,bn_size,bottleneck,drop_out):\n",
    "        super().__init__()\n",
    "        block=conv_layer\n",
    "        self.conv1=nn.Conv2d(in_channels,init_features0,kernel_size=6, stride=2, padding=2,bias=False)\n",
    "\n",
    "        if k_size==11:\n",
    "            \n",
    "            p=5\n",
    "        if k_size==9:\n",
    "            \n",
    "            p=4\n",
    "        elif k_size==7:\n",
    "         \n",
    "            p=3\n",
    "        elif k_size==5:\n",
    "         \n",
    "            p=2\n",
    "        elif k_size==3:\n",
    "       \n",
    "            p=1\n",
    "        \n",
    "        self.x1=x1\n",
    "        self.x2=x2\n",
    "        self.x3=x3\n",
    "        self.x4=x4\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block1=Dense_block(init_features0,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features1=init_features0+growth_rate*n_layers\n",
    "        self.encode1=Encode_Decode(in_features1,in_features1//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block2=Dense_block(in_features1//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features11=in_features1//2+growth_rate*n_layers\n",
    "        self.encode2=Encode_Decode(in_features11,in_features11//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block22=Dense_block(in_features11//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features11//2+growth_rate*n_layers\n",
    "        self.encode22=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        \n",
    "        n_layers=4\n",
    "        self.dense_block3=Dense_block(in_features//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features//2+growth_rate*n_layers\n",
    "        self.decode1=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x1==1:\n",
    "            in_features=in_features//2+in_features11//2\n",
    "        elif self.x1==0:\n",
    "            in_features=in_features//2\n",
    "            \n",
    "        self.dense_block4=Dense_block(in_features,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features+growth_rate*n_layers\n",
    "        self.decode2=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x2==1:\n",
    "            in_features44=in_features//2+in_features1//2\n",
    "        elif self.x2==0:\n",
    "            in_features44=in_features//2\n",
    "        self.dense_block44=Dense_block(in_features44,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features44+growth_rate*n_layers\n",
    "        self.decode22=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        \n",
    "        n_layers=2\n",
    "        if self.x3==1:\n",
    "            in_features2=in_features//2+init_features0\n",
    "        elif self.x3==0:\n",
    "            in_features2=in_features//2\n",
    "        self.dense_block5=Dense_block(in_features2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features2+growth_rate*n_layers\n",
    "        self.last=last_decode(in_features,out_channels,kernel_size=4,stride=2,padding=1,output_padding=0,drop_out=0)\n",
    "    def forward(self,x):\n",
    "        out1=self.conv1(x)\n",
    "       # print(out1.size())\n",
    "        out2=self.encode1(self.dense_block1(out1))\n",
    "       # print(out2.size())\n",
    "        out3=self.encode2(self.dense_block2(out2))\n",
    "       # print(out3.size())\n",
    "        out33=self.encode22(self.dense_block22(out3))\n",
    "        #print(out33.size())\n",
    "        out4=self.decode1(self.dense_block3(out33))\n",
    "        #print(out4.size())\n",
    "        if self.x1==1:\n",
    "            out4=torch.cat([out4, out3], 1)\n",
    "        elif self.x1==0:\n",
    "            out4=out4\n",
    "        #print(out4.size())\n",
    "        out4=self.dense_block4(out4)\n",
    "      # print(out4.size())\n",
    "        out5=self.decode2(out4)\n",
    "       # print('------')\n",
    "        if self.x2==1:\n",
    "            out5=torch.cat([out5, out2], 1)\n",
    "        elif self.x2==0:\n",
    "            out5=out5\n",
    "        #print(out5.size())\n",
    "        out55=self.decode22(self.dense_block44(out5))\n",
    "        if self.x3==1:\n",
    "            out5=torch.cat([out55, out1], 1)\n",
    "        elif self.x3==0:\n",
    "            out5=out55\n",
    "        out=self.dense_block5(out5)\n",
    "        out=self.last(out)\n",
    "        #Try different activations when we change activation, input images should be scaled to the same range\n",
    "        self.activation=nn.Sigmoid()\n",
    "        out=self.activation(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26f65",
   "metadata": {},
   "source": [
    "## Skip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f2db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_C8_skip(nn.Module):\n",
    "    def __init__(self,in_channels,k_size,x1,x2,x3,x4,out_channels,init_features0,growth_rate,bn_size,bottleneck,drop_out):\n",
    "        super().__init__()\n",
    "        block=conv_layer\n",
    "        self.conv1=nn.Conv2d(in_channels,init_features0,kernel_size=6, stride=2, padding=2,bias=False)\n",
    "        \n",
    "        \n",
    "        if k_size==11:\n",
    "            \n",
    "            p=5\n",
    "        \n",
    "        if k_size==9:\n",
    "            \n",
    "            p=4\n",
    "        elif k_size==7:\n",
    "         \n",
    "            p=3\n",
    "        elif k_size==5:\n",
    "         \n",
    "            p=2\n",
    "        elif k_size==3:\n",
    "       \n",
    "            p=1\n",
    "        self.x1=x1\n",
    "        self.x2=x2\n",
    "        self.x3=x3\n",
    "        self.x4=x4\n",
    "        \n",
    "        n_layers=2\n",
    "        self.dense_block1=Dense_block(init_features0,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features1=init_features0+growth_rate*n_layers\n",
    "        self.encode1=Encode_Decode(in_features1,in_features1//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        n_layers=2\n",
    "        self.dense_block2=Dense_block(in_features1//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features1//2+growth_rate*n_layers\n",
    "        self.encode2=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=True,bottleneck=True,output_padding=0)\n",
    "        n_layers=4\n",
    "        self.dense_block3=Dense_block(in_features//2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features//2+growth_rate*n_layers\n",
    "        self.decode1=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        n_layers=2\n",
    "        if self.x1==1:\n",
    "            in_features=in_features//2+in_features1//2\n",
    "        elif self.x1==0:\n",
    "            in_features=in_features//2\n",
    "        self.dense_block4=Dense_block(in_features,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features+growth_rate*n_layers\n",
    "        self.decode2=Encode_Decode(in_features,in_features//2,k_size,p,growth_rate,drop_out,down=False,bottleneck=True,output_padding=1)\n",
    "        n_layers=2\n",
    "        if self.x2==1:\n",
    "            in_features2=in_features//2+init_features0\n",
    "        elif self.x2==0:\n",
    "            in_features2=in_features//2\n",
    "        self.dense_block5=Dense_block(in_features2,block,k_size,p,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n",
    "        in_features=in_features2+growth_rate*n_layers\n",
    "        self.last=last_decode(in_features,out_channels,kernel_size=4,stride=2,padding=1,output_padding=0,drop_out=0)\n",
    "    def forward(self,x):\n",
    "        out1=self.conv1(x)\n",
    "        #print(out1.size())\n",
    "        out2=self.encode1(self.dense_block1(out1))\n",
    "        #print(out2.size())\n",
    "        out3=self.encode2(self.dense_block2(out2))\n",
    "        #print(out3.size())\n",
    "        out4=self.decode1(self.dense_block3(out3))\n",
    "        #print(out4.size())\n",
    "        if self.x1==1:\n",
    "            out4=torch.cat([out4, out2], 1)\n",
    "        elif self.x1==0:\n",
    "            out4=out4\n",
    "        #print(out4.size())\n",
    "        out4=self.dense_block4(out4)\n",
    "        #print(out4.size())\n",
    "        out5=self.decode2(out4)\n",
    "        #print('------')\n",
    "        #print(out5.size())\n",
    "        if self.x2==1:\n",
    "            out5=torch.cat([out5, out1], 1)\n",
    "        elif self.x2==0:\n",
    "            out5=out5\n",
    "        out=self.dense_block5(out5)\n",
    "        out=self.last(out)\n",
    "        #Try different activations when we change activation, input images should be scaled to the same range\n",
    "        self.activation=nn.Sigmoid()\n",
    "        out=self.activation(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82be507",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fdc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Custom_Dataset(object):\n",
    "    def __init__(self,main_dir,Data_set,transform_layout, transform_wind, transform_flow,transform_wake, n_images, n_channels_input):\n",
    "        self.main_dir=main_dir\n",
    "        self.transform_layout=transform_layout\n",
    "        self.transform_wind=transform_wind\n",
    "        self.transform_flow=transform_flow\n",
    "        self.transform_wake=transform_wake\n",
    "        self.n_images=n_images\n",
    "        self.n_channels_input=n_channels_input\n",
    "        #load all images with 'flow.png' from the provided path\n",
    "        flow_files = glob.glob(os.path.join(self.main_dir, '*flow.png'))\n",
    "        #Images are sorted naturally(e.g image 2 after image 1)\n",
    "        self.image_flow=natsort.natsorted(flow_files)\n",
    "        Coord_files=glob.glob(os.path.join(self.main_dir, '*layout_pixels.npy'))\n",
    "        self.Coordin=natsort.natsorted(Coord_files)\n",
    "        layout_files=glob.glob(os.path.join(self.main_dir, '*layout.png'))\n",
    "        self.image_layout=natsort.natsorted(layout_files)\n",
    "        wind_files=glob.glob(os.path.join(self.main_dir, '*wind_resource.png'))\n",
    "        self.image_wind=natsort.natsorted(wind_files)\n",
    "        wake_files=glob.glob(os.path.join(self.main_dir,'*wake_effects.png'))\n",
    "       # print(len(wake_files))\n",
    "        self.image_wake=natsort.natsorted(wake_files)\n",
    "        self.speed=list(Data_set['wind_speed [m/s]'])\n",
    "        self.Jensen_power=list(Data_set['jensen_power [kW-hr]'])\n",
    "        \n",
    "        #for reproducable results\n",
    "        rstate = 10\n",
    "        random.seed(rstate)\n",
    "        np.random.seed(rstate)\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_layout)\n",
    "    def __getitem__(self,idx):\n",
    "        if self.n_images:\n",
    "            if idx >= self.n_images:\n",
    "                raise Exception('CustomDataSet:Error: Index out of bounds inside __get_item__')\n",
    "       # coordinate=[]\n",
    "        input_loc = self.image_layout[idx]\n",
    "     \n",
    "        layout = self.transform_layout(Image.open(input_loc))\n",
    "        u_inf=self.speed[idx]\n",
    "        power=self.Jensen_power[idx]\n",
    "        coor_loc=self.Coordin[idx]\n",
    "        \n",
    "        \n",
    "        if self.n_channels_input == 2:\n",
    "            target_loc = self.image_flow[idx]\n",
    "            target = self.transform_flow(Image.open(target_loc))\n",
    "            wind_loc = self.image_wind[idx]\n",
    "            wind = self.transform_wind(Image.open(wind_loc))\n",
    "            inputs = layout\n",
    "           \n",
    "        else:\n",
    "            inputs = layout\n",
    "            wake_loc = self.image_wake[idx]\n",
    "            target=self.transform_wake(Image.open(wake_loc))\n",
    "            #coordinate=torch.from_numpy(coordinate)\n",
    "        return inputs, target,u_inf,power,coor_loc\n",
    "    \n",
    "# In the original images the background is black and turbines are white by applying the negative transform, the backgorund becomes\n",
    "#white and the turbines are black\n",
    "def to_negative(img):\n",
    "    img = PIL.ImageOps.invert(img)\n",
    "    return img\n",
    "\n",
    "class Negative(object):\n",
    "    \"\"\"Convert image to negative.\n",
    "    Args:\n",
    "    Returns:\n",
    "        PIL Image: Negative version of the input.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be converted to Negative.\n",
    "        Returns:\n",
    "            PIL Image: Negatived image.\n",
    "        \"\"\"\n",
    "        return to_negative(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a177064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this csv file all csv files which are created for each wind speed \n",
    "img_folder = 'C:/Users/saeed/Code/DecodeCNN/Error/final_code/test_final/image400'\n",
    "Data_set=pd.read_csv('{}/data_set.csv'.format(img_folder))\n",
    "\n",
    "\n",
    "# Define individual transformations for each input and output\n",
    "transforms_list = [\n",
    "                   T.Grayscale(),\n",
    "                # to tranform the orignal black background to white\n",
    "                   T.ToTensor()]\n",
    "transforms_layout = T.Compose(transforms_list)\n",
    "transforms_list = [\n",
    "                   T.Grayscale(),T.ToTensor()]\n",
    "transforms_flow = T.Compose(transforms_list)\n",
    "transforms_list = [\n",
    "                   T.Grayscale(),\n",
    "                   T.ToTensor()]\n",
    "transforms_wind = T.Compose(transforms_list)\n",
    "transforms_list = [\n",
    "                   T.Grayscale(),\n",
    "                   T.ToTensor()]\n",
    "transforms_wake = T.Compose(transforms_list)\n",
    "\n",
    "#load dataset\n",
    "dataset = Custom_Dataset(img_folder,Data_set, transforms_layout, transforms_wind, transforms_flow,transforms_wake, n_images=256, n_channels_input = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94987103",
   "metadata": {},
   "source": [
    "### Visulasization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd27805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "for i in range(3):\n",
    "    ax = fig.add_subplot(2, 3, i + 1)\n",
    "\n",
    "    ax.imshow(dataset.__getitem__(i)[0].squeeze(0), cmap='gray')\n",
    "    ax.set_title('Inputs_{}'.format(i+1))\n",
    "    ax.axis(\"off\")\n",
    "    ax =fig.add_subplot(2, 3, i + 1 + 3)\n",
    "    ax.imshow(dataset.__getitem__(i)[1].squeeze(0),cmap='gray')\n",
    "    ax.set_title('Target_{}'.format(i+1))\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6540591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data:206\n",
      "Number of valid data:25\n",
      "Number of test data:25\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "\n",
    "ntest = int(0.1 * len(dataset))\n",
    "nvalid=int(0.1*(len(dataset)))\n",
    "ntrain=(len(dataset) - ntest-nvalid)\n",
    "train_data,valid_data,test_data = random_split(dataset, lengths=[ntrain, nvalid,ntest])\n",
    "ntest=len(test_data)\n",
    "nvalid=len(test_data)\n",
    "ntrain=len(train_data)\n",
    "print('Number of train data:{}\\nNumber of valid data:{}\\nNumber of test data:{}'.format(ntrain,nvalid,ntest ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152c666",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c99a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,valid_set, batch_size):\n",
    "\n",
    "\n",
    "    \n",
    "    val_loss=0\n",
    "    \n",
    "    device='cuda'\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    for step,(inputs, target,u_inf,power,coor_loc) in enumerate(valid_set):\n",
    "            #images, labels = get_torch_vars(xs, ys, args.gpu)\n",
    "\n",
    "            #############################################\n",
    "            #To Enable GPU Usage\n",
    "\n",
    "            #############################################\n",
    "        inputs  = inputs.to(device, dtype=torch.float)\n",
    "            #targets= targets.to(device, dtype=torch.float)\n",
    "        target= target.to(device, dtype=torch.float)\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss=F.mse_loss(output, target, reduction='sum')\n",
    "\n",
    "        val_loss+=loss.item()\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6900c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(args,model):\n",
    "    train_set=torch.utils.data.DataLoader(train_data, args.batch_size, pin_memory=True, num_workers=0)\n",
    "    valid_set=torch.utils.data.DataLoader(valid_data, args.test_batch_size, pin_memory=True, num_workers=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate,\n",
    "                       weight_decay=args.weight_decay)\n",
    "    scheduler=ReduceLROnPlateau(optimizer,mode='min',threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-8)\n",
    "    n_out_pixels_train = args.ntrain * train_data[0][1].numel()\n",
    "    n_out_pixels_valid = args.nvalid * valid_data[0][1].numel()\n",
    "    train_losses=[]\n",
    "    RMSE_train=[]\n",
    "    RMSE_valid=[]\n",
    "    Epochs=[]\n",
    "    train_loss=0\n",
    "    valid_losses=[]\n",
    "    device='cuda'\n",
    "    for epoch in range(args.epochs):\n",
    "        #print(epoch)\n",
    "        # Train the Model\n",
    "        model.train()  # Change model to 'train' mod\n",
    "        train_loss=0\n",
    "        for step,(inputs, target,u_inf,power,coor_loc) in enumerate(train_set):\n",
    "            \n",
    "            inputs  = inputs.to(device, dtype=torch.float)\n",
    "            targets= target.to(device, dtype=torch.float)\n",
    "            #wakes= wake.to(device, dtype=torch.float)\n",
    "            model.zero_grad()\n",
    "            outputs=model(inputs)\n",
    "\n",
    "          \n",
    "                    \n",
    "                \n",
    "            loss=F.mse_loss(outputs, targets, reduction='sum')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "\n",
    " \n",
    "    \n",
    "        train_losses.append(train_loss)   \n",
    "        rmse = np.sqrt(train_loss / n_out_pixels_train)\n",
    "        RMSE_train.append(rmse)\n",
    "        scheduler.step(rmse)\n",
    "        Epochs.append(epoch+1)\n",
    "        model.eval()\n",
    "        val_loss=evaluate(model,valid_set, args.test_batch_size)\n",
    "        rmse_val = np.sqrt(val_loss / n_out_pixels_valid)\n",
    "        RMSE_valid.append(rmse_val)\n",
    "        #print((\"Epoch {}: , Train RMSE: {},Validation RMSE: {}\").format(\n",
    "                  # epoch ,\n",
    "                  # rmse,rmse_val))\n",
    "        valid_losses.append(val_loss)\n",
    "        #print((\"Epoch {}: , Train loss: {},Validation loss: {}\").format(\n",
    "                   #epoch ,\n",
    "                   #train_loss,val_loss))\n",
    "        \n",
    "            \n",
    "       # model_path = save_dir + \"/_epoch_\" + str(epoch)\n",
    "        \n",
    "            \n",
    "\n",
    "        #torch.save(gen.state_dict(), model_path)\n",
    "        \n",
    "        #print(\"\"epoch, loss.cpu().detach())\n",
    "\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e320daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b58ffbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main training loop for CNN\n",
    "args = AttrDict()\n",
    "args_dict = {\n",
    "    \"gpu\": True,\n",
    "    \"valid\": False,\n",
    "   \n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "    \"visualize\": False,\n",
    "    \"downsize_input\": False,\n",
    "    \"batch_size\":32,\n",
    "    \"test_batch_size\":8,\n",
    "    \"learning_rate\":3e-3,\n",
    "    \"weight_decay\":0.005,\n",
    "    \"epochs\":200,\n",
    "    \"ntrain\":ntrain,\n",
    "    \"ntest\":ntest,\n",
    "    \"nvalid\":nvalid,\n",
    "    \"in_channel\":1,\n",
    "    \"out_channel\":1,\n",
    "    \"init_features\":4,\n",
    "    \"bn_size\":8\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc266304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalu_fun(train_data,valid_data,test_data,k,growth_rate,x,x1,x2,x3,x4):\n",
    "    args.update(args_dict)\n",
    "    device = 'cuda'\n",
    "    if k==1:\n",
    "        k_size=3\n",
    "    elif k==2:\n",
    "        k_size=5\n",
    "    elif k==3:\n",
    "        k_size=7\n",
    "    elif k==4:\n",
    "        k_size=9\n",
    "\n",
    "        \n",
    "    if x==1:\n",
    "        model=Dense_C8_skip_more_one(args.in_channel,k_size,x1,x2,x3,x4, args.out_channel, args.init_features,growth_rate,args.bn_size,bottleneck=False,drop_out=0)\n",
    "    elif x==2:\n",
    "        model=Dense_C8_skip_more(args.in_channel,k_size,x1,x2,x3,x4, args.out_channel, args.init_features,growth_rate,args.bn_size,bottleneck=False,drop_out=0)\n",
    "    elif x==3:\n",
    "        model=Dense_C8_skip(args.in_channel,k_size,x1,x2,x3,x4, args.out_channel, args.init_features,growth_rate,args.bn_size,bottleneck=False,drop_out=0)\n",
    "    #print('11111')\n",
    "    \n",
    "    model=model.to(device)\n",
    "    summary(model, (1, 400, 400))\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print (type(model).__name__)\n",
    "    print('kerne_size=',k_size)\n",
    "    print('growth_rate=',growth_rate)\n",
    "    print('x1=',x1)\n",
    "    print('x2=',x2)\n",
    "    print('x3=',x3)\n",
    "    print('x4=',x4)\n",
    "    CNN=train(args,model)\n",
    "    n_out_pixels_test = args.ntest * test_data[0][1].numel()\n",
    "    test_set=torch.utils.data.DataLoader(test_data, args.test_batch_size, pin_memory=True, num_workers=0)\n",
    "    test_loss=evaluate(CNN,test_set, args.test_batch_size)\n",
    "    rmse_test = np.sqrt(test_loss / n_out_pixels_test)\n",
    "    return rmse_test,total_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a1447",
   "metadata": {},
   "source": [
    "## Pymo Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "301d2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs=100\n",
    "evalualte = lambda x: evalu_fun(train_data,valid_data,test_data,k=x[0],growth_rate=x[1],x=x[2],x1=x[3],x2=x[4],x3=x[5],x4=x[6])\n",
    "\n",
    "objs=evalualte\n",
    "#apply constrains\n",
    "constr_ieq = [\n",
    "    lambda x: 1*(x[0]-5), \n",
    "    lambda x: 1*(x[1]-13),\n",
    "    lambda x: 1*(x[2]-4),\n",
    "    lambda x: 1*(x[3]-1),\n",
    "    lambda x: 1*(x[4]-1),\n",
    "    lambda x: 1*(x[5]-1),\n",
    "    lambda x: 1*(x[6]-1)\n",
    "]\n",
    "\n",
    "constr_eq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31316b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.problems.functional import FunctionalProblem\n",
    "from pymoo.problems.constr_as_penalty import ConstraintsAsPenalty\n",
    "\n",
    "problem = FunctionalProblem(7,\n",
    "                            objs,\n",
    "                            xl=np.array([1,1,1,0,0,0,0]),\n",
    "                            xu=np.array([4,12,3,1,1,1,1]),\n",
    "                            constr_ieq=constr_ieq,\n",
    "                            constr_eq=constr_eq\n",
    "                            )\n",
    "\n",
    "problem = ConstraintsAsPenalty(problem, penalty=1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2d0682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "#optimization(NSGA2)\n",
    "algorithm = NSGA2(\n",
    "    pop_size=40,\n",
    "    n_offsprings=20,\n",
    "    sampling=get_sampling(\"int_random\"),\n",
    "    crossover=get_crossover(\"int_sbx\", prob=0.9, eta=15),\n",
    "    mutation=get_mutation(\"int_pm\", eta=20),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60c8c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           7,225\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           3,825\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           5,850\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           7,875\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           9,900\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          16,900\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           5,850\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]           7,875\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          12,100\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 22, 50, 50]              44\n",
      "            ReLU-107           [-1, 22, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           4,950\n",
      "      conv_layer-109           [-1, 31, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 31, 50, 50]              62\n",
      "            ReLU-111           [-1, 31, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]           6,975\n",
      "      conv_layer-113           [-1, 40, 50, 50]               0\n",
      "     Dense_block-114           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 40, 50, 50]              80\n",
      "            ReLU-116           [-1, 40, 50, 50]               0\n",
      "          Conv2d-117           [-1, 20, 50, 50]             800\n",
      "     BatchNorm2d-118           [-1, 20, 50, 50]              40\n",
      "            ReLU-119           [-1, 20, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 20, 100, 100]          10,000\n",
      "   Encode_Decode-121         [-1, 20, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 20, 100, 100]              40\n",
      "            ReLU-123         [-1, 20, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           4,500\n",
      "      conv_layer-125         [-1, 29, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 29, 100, 100]              58\n",
      "            ReLU-127         [-1, 29, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]           6,525\n",
      "      conv_layer-129         [-1, 38, 100, 100]               0\n",
      "     Dense_block-130         [-1, 38, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 38, 100, 100]              76\n",
      "            ReLU-132         [-1, 38, 100, 100]               0\n",
      "          Conv2d-133         [-1, 19, 100, 100]             722\n",
      "     BatchNorm2d-134         [-1, 19, 100, 100]              38\n",
      "            ReLU-135         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 19, 200, 200]           9,025\n",
      "   Encode_Decode-137         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 19, 200, 200]              38\n",
      "            ReLU-139         [-1, 19, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           4,275\n",
      "      conv_layer-141         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 28, 200, 200]              56\n",
      "            ReLU-143         [-1, 28, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           6,300\n",
      "      conv_layer-145         [-1, 37, 200, 200]               0\n",
      "     Dense_block-146         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 37, 200, 200]              74\n",
      "            ReLU-148         [-1, 37, 200, 200]               0\n",
      "          Conv2d-149         [-1, 18, 200, 200]             666\n",
      "     BatchNorm2d-150         [-1, 18, 200, 200]              36\n",
      "            ReLU-151         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             288\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 181,229\n",
      "Trainable params: 181,229\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 246.68\n",
      "Params size (MB): 0.69\n",
      "Estimated Total Size (MB): 247.98\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             500\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           1,125\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             875\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           1,500\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           1,600\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,000\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           1,625\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           2,025\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           1,125\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           1,750\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]           2,375\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           3,000\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 14, 50, 50]              28\n",
      "             ReLU-75           [-1, 14, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]           1,750\n",
      "       conv_layer-77           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 19, 50, 50]              38\n",
      "             ReLU-79           [-1, 19, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]           2,375\n",
      "       conv_layer-81           [-1, 24, 50, 50]               0\n",
      "      Dense_block-82           [-1, 24, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 24, 50, 50]              48\n",
      "             ReLU-84           [-1, 24, 50, 50]               0\n",
      "           Conv2d-85           [-1, 12, 50, 50]             288\n",
      "      BatchNorm2d-86           [-1, 12, 50, 50]              24\n",
      "             ReLU-87           [-1, 12, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-89         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 19, 100, 100]              38\n",
      "             ReLU-91         [-1, 19, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]           2,375\n",
      "       conv_layer-93         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 24, 100, 100]              48\n",
      "             ReLU-95         [-1, 24, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           3,000\n",
      "       conv_layer-97         [-1, 29, 100, 100]               0\n",
      "      Dense_block-98         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 29, 100, 100]              58\n",
      "            ReLU-100         [-1, 29, 100, 100]               0\n",
      "          Conv2d-101         [-1, 14, 100, 100]             406\n",
      "     BatchNorm2d-102         [-1, 14, 100, 100]              28\n",
      "            ReLU-103         [-1, 14, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 14, 200, 200]           4,900\n",
      "   Encode_Decode-105         [-1, 14, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 14, 200, 200]              28\n",
      "            ReLU-107         [-1, 14, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]           1,750\n",
      "      conv_layer-109         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 19, 200, 200]              38\n",
      "            ReLU-111         [-1, 19, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]           2,375\n",
      "      conv_layer-113         [-1, 24, 200, 200]               0\n",
      "     Dense_block-114         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 24, 200, 200]              48\n",
      "            ReLU-116         [-1, 24, 200, 200]               0\n",
      "          Conv2d-117         [-1, 12, 200, 200]             288\n",
      "     BatchNorm2d-118         [-1, 12, 200, 200]              24\n",
      "            ReLU-119         [-1, 12, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             192\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 49,788\n",
      "Trainable params: 49,788\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 164.55\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 165.35\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             324\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           1,053\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           1,089\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]             891\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           1,620\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           1,764\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           1,134\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           1,863\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           2,304\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           1,296\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           2,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]           2,754\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]           3,483\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]           6,084\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 40, 50, 50]              80\n",
      "             ReLU-75           [-1, 40, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]           3,240\n",
      "       conv_layer-77           [-1, 49, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 49, 50, 50]              98\n",
      "             ReLU-79           [-1, 49, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]           3,969\n",
      "       conv_layer-81           [-1, 58, 50, 50]               0\n",
      "      Dense_block-82           [-1, 58, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 58, 50, 50]             116\n",
      "             ReLU-84           [-1, 58, 50, 50]               0\n",
      "           Conv2d-85           [-1, 29, 50, 50]           1,682\n",
      "      BatchNorm2d-86           [-1, 29, 50, 50]              58\n",
      "             ReLU-87           [-1, 29, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 29, 100, 100]           7,569\n",
      "    Encode_Decode-89         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 29, 100, 100]              58\n",
      "             ReLU-91         [-1, 29, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]           2,349\n",
      "       conv_layer-93         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 38, 100, 100]              76\n",
      "             ReLU-95         [-1, 38, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]           3,078\n",
      "       conv_layer-97         [-1, 47, 100, 100]               0\n",
      "      Dense_block-98         [-1, 47, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 47, 100, 100]              94\n",
      "            ReLU-100         [-1, 47, 100, 100]               0\n",
      "          Conv2d-101         [-1, 23, 100, 100]           1,081\n",
      "     BatchNorm2d-102         [-1, 23, 100, 100]              46\n",
      "            ReLU-103         [-1, 23, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 23, 200, 200]           4,761\n",
      "   Encode_Decode-105         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 23, 200, 200]              46\n",
      "            ReLU-107         [-1, 23, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]           1,863\n",
      "      conv_layer-109         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 32, 200, 200]              64\n",
      "            ReLU-111         [-1, 32, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]           2,592\n",
      "      conv_layer-113         [-1, 41, 200, 200]               0\n",
      "     Dense_block-114         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 41, 200, 200]              82\n",
      "            ReLU-116         [-1, 41, 200, 200]               0\n",
      "          Conv2d-117         [-1, 20, 200, 200]             820\n",
      "     BatchNorm2d-118         [-1, 20, 200, 200]              40\n",
      "            ReLU-119         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             320\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 65,332\n",
      "Trainable params: 65,332\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 272.67\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 273.53\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 15, 50, 50]              30\n",
      "             ReLU-43           [-1, 15, 50, 50]               0\n",
      "           Conv2d-44            [-1, 4, 50, 50]           4,860\n",
      "       conv_layer-45           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 50, 50]           6,156\n",
      "       conv_layer-49           [-1, 23, 50, 50]               0\n",
      "      Dense_block-50           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 23, 50, 50]              46\n",
      "             ReLU-52           [-1, 23, 50, 50]               0\n",
      "           Conv2d-53           [-1, 11, 50, 50]             253\n",
      "      BatchNorm2d-54           [-1, 11, 50, 50]              22\n",
      "             ReLU-55           [-1, 11, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-57         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 17, 100, 100]              34\n",
      "             ReLU-59         [-1, 17, 100, 100]               0\n",
      "           Conv2d-60          [-1, 4, 100, 100]           5,508\n",
      "       conv_layer-61         [-1, 21, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 21, 100, 100]              42\n",
      "             ReLU-63         [-1, 21, 100, 100]               0\n",
      "           Conv2d-64          [-1, 4, 100, 100]           6,804\n",
      "       conv_layer-65         [-1, 25, 100, 100]               0\n",
      "      Dense_block-66         [-1, 25, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 25, 100, 100]              50\n",
      "             ReLU-68         [-1, 25, 100, 100]               0\n",
      "           Conv2d-69         [-1, 12, 100, 100]             300\n",
      "      BatchNorm2d-70         [-1, 12, 100, 100]              24\n",
      "             ReLU-71         [-1, 12, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 12, 200, 200]          11,664\n",
      "    Encode_Decode-73         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 16, 200, 200]              32\n",
      "             ReLU-75         [-1, 16, 200, 200]               0\n",
      "           Conv2d-76          [-1, 4, 200, 200]           5,184\n",
      "       conv_layer-77         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 20, 200, 200]              40\n",
      "             ReLU-79         [-1, 20, 200, 200]               0\n",
      "           Conv2d-80          [-1, 4, 200, 200]           6,480\n",
      "       conv_layer-81         [-1, 24, 200, 200]               0\n",
      "      Dense_block-82         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 24, 200, 200]              48\n",
      "             ReLU-84         [-1, 24, 200, 200]               0\n",
      "           Conv2d-85         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-86         [-1, 12, 200, 200]              24\n",
      "             ReLU-87         [-1, 12, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             192\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 80,193\n",
      "Trainable params: 80,193\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 150.60\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 151.52\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           3,168\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           4,257\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]           6,561\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           4,356\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           5,445\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]           9,801\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,554\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           5,643\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          10,404\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 38, 200, 200]              76\n",
      "            ReLU-139         [-1, 38, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,762\n",
      "      conv_layer-141         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 49, 200, 200]              98\n",
      "            ReLU-143         [-1, 49, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           4,851\n",
      "      conv_layer-145         [-1, 60, 200, 200]               0\n",
      "     Dense_block-146         [-1, 60, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 60, 200, 200]             120\n",
      "            ReLU-148         [-1, 60, 200, 200]               0\n",
      "          Conv2d-149         [-1, 30, 200, 200]           1,800\n",
      "     BatchNorm2d-150         [-1, 30, 200, 200]              60\n",
      "            ReLU-151         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             480\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 127,883\n",
      "Trainable params: 127,883\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 373.84\n",
      "Params size (MB): 0.49\n",
      "Estimated Total Size (MB): 374.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 32, 50, 50]              64\n",
      "             ReLU-43           [-1, 32, 50, 50]               0\n",
      "           Conv2d-44            [-1, 9, 50, 50]           7,200\n",
      "       conv_layer-45           [-1, 41, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 41, 50, 50]              82\n",
      "             ReLU-47           [-1, 41, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 50, 50]           9,225\n",
      "       conv_layer-49           [-1, 50, 50, 50]               0\n",
      "      Dense_block-50           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 50, 50, 50]             100\n",
      "             ReLU-52           [-1, 50, 50, 50]               0\n",
      "           Conv2d-53           [-1, 25, 50, 50]           1,250\n",
      "      BatchNorm2d-54           [-1, 25, 50, 50]              50\n",
      "             ReLU-55           [-1, 25, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 25, 100, 100]          15,625\n",
      "    Encode_Decode-57         [-1, 25, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 25, 100, 100]              50\n",
      "             ReLU-59         [-1, 25, 100, 100]               0\n",
      "           Conv2d-60          [-1, 9, 100, 100]           5,625\n",
      "       conv_layer-61         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 34, 100, 100]              68\n",
      "             ReLU-63         [-1, 34, 100, 100]               0\n",
      "           Conv2d-64          [-1, 9, 100, 100]           7,650\n",
      "       conv_layer-65         [-1, 43, 100, 100]               0\n",
      "      Dense_block-66         [-1, 43, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 43, 100, 100]              86\n",
      "             ReLU-68         [-1, 43, 100, 100]               0\n",
      "           Conv2d-69         [-1, 21, 100, 100]             903\n",
      "      BatchNorm2d-70         [-1, 21, 100, 100]              42\n",
      "             ReLU-71         [-1, 21, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 21, 200, 200]          11,025\n",
      "    Encode_Decode-73         [-1, 21, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 25, 200, 200]              50\n",
      "             ReLU-75         [-1, 25, 200, 200]               0\n",
      "           Conv2d-76          [-1, 9, 200, 200]           5,625\n",
      "       conv_layer-77         [-1, 34, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 34, 200, 200]              68\n",
      "             ReLU-79         [-1, 34, 200, 200]               0\n",
      "           Conv2d-80          [-1, 9, 200, 200]           7,650\n",
      "       conv_layer-81         [-1, 43, 200, 200]               0\n",
      "      Dense_block-82         [-1, 43, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 43, 200, 200]              86\n",
      "             ReLU-84         [-1, 43, 200, 200]               0\n",
      "           Conv2d-85         [-1, 21, 200, 200]             903\n",
      "      BatchNorm2d-86         [-1, 21, 200, 200]              42\n",
      "             ReLU-87         [-1, 21, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             336\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 101,969\n",
      "Trainable params: 101,969\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 265.41\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 266.41\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,000\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           3,500\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           3,000\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           5,500\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           6,400\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           4,000\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           6,500\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           8,100\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           4,500\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           7,000\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           9,025\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           4,750\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           7,250\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           9,750\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          12,250\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          21,025\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 29, 25, 25]              58\n",
      "             ReLU-91           [-1, 29, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           7,250\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           9,750\n",
      "       conv_layer-97           [-1, 49, 25, 25]               0\n",
      "      Dense_block-98           [-1, 49, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 49, 25, 25]              98\n",
      "            ReLU-100           [-1, 49, 25, 25]               0\n",
      "          Conv2d-101           [-1, 24, 25, 25]           1,176\n",
      "     BatchNorm2d-102           [-1, 24, 25, 25]              48\n",
      "            ReLU-103           [-1, 24, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 24, 50, 50]          14,400\n",
      "   Encode_Decode-105           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 40, 50, 50]              80\n",
      "            ReLU-107           [-1, 40, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          10,000\n",
      "      conv_layer-109           [-1, 50, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 50, 50, 50]             100\n",
      "            ReLU-111           [-1, 50, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          12,500\n",
      "      conv_layer-113           [-1, 60, 50, 50]               0\n",
      "     Dense_block-114           [-1, 60, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 60, 50, 50]             120\n",
      "            ReLU-116           [-1, 60, 50, 50]               0\n",
      "          Conv2d-117           [-1, 30, 50, 50]           1,800\n",
      "     BatchNorm2d-118           [-1, 30, 50, 50]              60\n",
      "            ReLU-119           [-1, 30, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 30, 100, 100]          22,500\n",
      "   Encode_Decode-121         [-1, 30, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 30, 100, 100]              60\n",
      "            ReLU-123         [-1, 30, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           7,500\n",
      "      conv_layer-125         [-1, 40, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 40, 100, 100]              80\n",
      "            ReLU-127         [-1, 40, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          10,000\n",
      "      conv_layer-129         [-1, 50, 100, 100]               0\n",
      "     Dense_block-130         [-1, 50, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 50, 100, 100]             100\n",
      "            ReLU-132         [-1, 50, 100, 100]               0\n",
      "          Conv2d-133         [-1, 25, 100, 100]           1,250\n",
      "     BatchNorm2d-134         [-1, 25, 100, 100]              50\n",
      "            ReLU-135         [-1, 25, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 25, 200, 200]          15,625\n",
      "   Encode_Decode-137         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 25, 200, 200]              50\n",
      "            ReLU-139         [-1, 25, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           6,250\n",
      "      conv_layer-141         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 35, 200, 200]              70\n",
      "            ReLU-143         [-1, 35, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           8,750\n",
      "      conv_layer-145         [-1, 45, 200, 200]               0\n",
      "     Dense_block-146         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 45, 200, 200]              90\n",
      "            ReLU-148         [-1, 45, 200, 200]               0\n",
      "          Conv2d-149         [-1, 22, 200, 200]             990\n",
      "     BatchNorm2d-150         [-1, 22, 200, 200]              44\n",
      "            ReLU-151         [-1, 22, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             352\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 253,572\n",
      "Trainable params: 253,572\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 297.70\n",
      "Params size (MB): 0.97\n",
      "Estimated Total Size (MB): 299.27\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 2, 200, 200]               4\n",
      "             ReLU-75          [-1, 2, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              18\n",
      "       conv_layer-77          [-1, 3, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 3, 200, 200]               6\n",
      "             ReLU-79          [-1, 3, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              27\n",
      "       conv_layer-81          [-1, 4, 200, 200]               0\n",
      "      Dense_block-82          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 4, 200, 200]               8\n",
      "             ReLU-84          [-1, 4, 200, 200]               0\n",
      "           Conv2d-85          [-1, 2, 200, 200]               8\n",
      "      BatchNorm2d-86          [-1, 2, 200, 200]               4\n",
      "             ReLU-87          [-1, 2, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              32\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,012\n",
      "Trainable params: 1,012\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.35\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 43.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             392\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             588\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             784\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             392\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             588\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             784\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             392\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             588\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             784\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             392\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             588\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             784\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             980\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]           1,764\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 10, 50, 50]              20\n",
      "             ReLU-75           [-1, 10, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             980\n",
      "       conv_layer-77           [-1, 12, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 12, 50, 50]              24\n",
      "             ReLU-79           [-1, 12, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]           1,176\n",
      "       conv_layer-81           [-1, 14, 50, 50]               0\n",
      "      Dense_block-82           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 14, 50, 50]              28\n",
      "             ReLU-84           [-1, 14, 50, 50]               0\n",
      "           Conv2d-85            [-1, 7, 50, 50]              98\n",
      "      BatchNorm2d-86            [-1, 7, 50, 50]              14\n",
      "             ReLU-87            [-1, 7, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 7, 100, 100]           2,401\n",
      "    Encode_Decode-89          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 7, 100, 100]              14\n",
      "             ReLU-91          [-1, 7, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             686\n",
      "       conv_layer-93          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 9, 100, 100]              18\n",
      "             ReLU-95          [-1, 9, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             882\n",
      "       conv_layer-97         [-1, 11, 100, 100]               0\n",
      "      Dense_block-98         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 11, 100, 100]              22\n",
      "            ReLU-100         [-1, 11, 100, 100]               0\n",
      "          Conv2d-101          [-1, 5, 100, 100]              55\n",
      "     BatchNorm2d-102          [-1, 5, 100, 100]              10\n",
      "            ReLU-103          [-1, 5, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 5, 200, 200]           1,225\n",
      "   Encode_Decode-105          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 5, 200, 200]              10\n",
      "            ReLU-107          [-1, 5, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             490\n",
      "      conv_layer-109          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 7, 200, 200]              14\n",
      "            ReLU-111          [-1, 7, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             686\n",
      "      conv_layer-113          [-1, 9, 200, 200]               0\n",
      "     Dense_block-114          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 9, 200, 200]              18\n",
      "            ReLU-116          [-1, 9, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 19,315\n",
      "Trainable params: 19,315\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 75.06\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 75.75\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             150\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             175\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 8, 200, 200]              16\n",
      "            ReLU-107          [-1, 8, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             200\n",
      "      conv_layer-109          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 9, 200, 200]              18\n",
      "            ReLU-111          [-1, 9, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             225\n",
      "      conv_layer-113         [-1, 10, 200, 200]               0\n",
      "     Dense_block-114         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 10, 200, 200]              20\n",
      "            ReLU-116         [-1, 10, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,844\n",
      "Trainable params: 3,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.33\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 67.96\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             648\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             972\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]           1,296\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             648\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             972\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]           1,296\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             648\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             972\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]           1,296\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             648\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             972\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]           1,296\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]             648\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             972\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]           1,296\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]           1,620\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]           2,916\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 10, 25, 25]              20\n",
      "             ReLU-91           [-1, 10, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]           1,620\n",
      "       conv_layer-93           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 12, 25, 25]              24\n",
      "             ReLU-95           [-1, 12, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]           1,944\n",
      "       conv_layer-97           [-1, 14, 25, 25]               0\n",
      "      Dense_block-98           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 14, 25, 25]              28\n",
      "            ReLU-100           [-1, 14, 25, 25]               0\n",
      "          Conv2d-101            [-1, 7, 25, 25]              98\n",
      "     BatchNorm2d-102            [-1, 7, 25, 25]              14\n",
      "            ReLU-103            [-1, 7, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 7, 50, 50]           3,969\n",
      "   Encode_Decode-105            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 7, 50, 50]              14\n",
      "            ReLU-107            [-1, 7, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]           1,134\n",
      "      conv_layer-109            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 9, 50, 50]              18\n",
      "            ReLU-111            [-1, 9, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]           1,458\n",
      "      conv_layer-113           [-1, 11, 50, 50]               0\n",
      "     Dense_block-114           [-1, 11, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 11, 50, 50]              22\n",
      "            ReLU-116           [-1, 11, 50, 50]               0\n",
      "          Conv2d-117            [-1, 5, 50, 50]              55\n",
      "     BatchNorm2d-118            [-1, 5, 50, 50]              10\n",
      "            ReLU-119            [-1, 5, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 5, 100, 100]           2,025\n",
      "   Encode_Decode-121          [-1, 5, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 5, 100, 100]              10\n",
      "            ReLU-123          [-1, 5, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]             810\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]           1,134\n",
      "      conv_layer-129          [-1, 9, 100, 100]               0\n",
      "     Dense_block-130          [-1, 9, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 9, 100, 100]              18\n",
      "            ReLU-132          [-1, 9, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              36\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]           1,296\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 8, 200, 200]              16\n",
      "            ReLU-139          [-1, 8, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]           1,296\n",
      "      conv_layer-141         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 10, 200, 200]              20\n",
      "            ReLU-143         [-1, 10, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]           1,620\n",
      "      conv_layer-145         [-1, 12, 200, 200]               0\n",
      "     Dense_block-146         [-1, 12, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 12, 200, 200]              24\n",
      "            ReLU-148         [-1, 12, 200, 200]               0\n",
      "          Conv2d-149          [-1, 6, 200, 200]              72\n",
      "     BatchNorm2d-150          [-1, 6, 200, 200]              12\n",
      "            ReLU-151          [-1, 6, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              96\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 38,663\n",
      "Trainable params: 38,663\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 82.56\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 83.32\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,000\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           3,500\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           3,000\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           5,500\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           6,400\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           4,000\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           6,500\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 36, 50, 50]              72\n",
      "             ReLU-43           [-1, 36, 50, 50]               0\n",
      "           Conv2d-44           [-1, 10, 50, 50]           9,000\n",
      "       conv_layer-45           [-1, 46, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 46, 50, 50]              92\n",
      "             ReLU-47           [-1, 46, 50, 50]               0\n",
      "           Conv2d-48           [-1, 10, 50, 50]          11,500\n",
      "       conv_layer-49           [-1, 56, 50, 50]               0\n",
      "      Dense_block-50           [-1, 56, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 56, 50, 50]             112\n",
      "             ReLU-52           [-1, 56, 50, 50]               0\n",
      "           Conv2d-53           [-1, 28, 50, 50]           1,568\n",
      "      BatchNorm2d-54           [-1, 28, 50, 50]              56\n",
      "             ReLU-55           [-1, 28, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 28, 100, 100]          19,600\n",
      "    Encode_Decode-57         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 40, 100, 100]              80\n",
      "             ReLU-59         [-1, 40, 100, 100]               0\n",
      "           Conv2d-60         [-1, 10, 100, 100]          10,000\n",
      "       conv_layer-61         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 50, 100, 100]             100\n",
      "             ReLU-63         [-1, 50, 100, 100]               0\n",
      "           Conv2d-64         [-1, 10, 100, 100]          12,500\n",
      "       conv_layer-65         [-1, 60, 100, 100]               0\n",
      "      Dense_block-66         [-1, 60, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 60, 100, 100]             120\n",
      "             ReLU-68         [-1, 60, 100, 100]               0\n",
      "           Conv2d-69         [-1, 30, 100, 100]           1,800\n",
      "      BatchNorm2d-70         [-1, 30, 100, 100]              60\n",
      "             ReLU-71         [-1, 30, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 30, 200, 200]          22,500\n",
      "    Encode_Decode-73         [-1, 30, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 34, 200, 200]              68\n",
      "             ReLU-75         [-1, 34, 200, 200]               0\n",
      "           Conv2d-76         [-1, 10, 200, 200]           8,500\n",
      "       conv_layer-77         [-1, 44, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 44, 200, 200]              88\n",
      "             ReLU-79         [-1, 44, 200, 200]               0\n",
      "           Conv2d-80         [-1, 10, 200, 200]          11,000\n",
      "       conv_layer-81         [-1, 54, 200, 200]               0\n",
      "      Dense_block-82         [-1, 54, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 54, 200, 200]             108\n",
      "             ReLU-84         [-1, 54, 200, 200]               0\n",
      "           Conv2d-85         [-1, 27, 200, 200]           1,458\n",
      "      BatchNorm2d-86         [-1, 27, 200, 200]              54\n",
      "             ReLU-87         [-1, 27, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             432\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 145,668\n",
      "Trainable params: 145,668\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 327.61\n",
      "Params size (MB): 0.56\n",
      "Estimated Total Size (MB): 328.77\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          13,200\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          16,225\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          30,625\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          13,200\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          16,225\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 39, 200, 200]              78\n",
      "            ReLU-107         [-1, 39, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]          10,725\n",
      "      conv_layer-109         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 50, 200, 200]             100\n",
      "            ReLU-111         [-1, 50, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          13,750\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 269,061\n",
      "Trainable params: 269,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 378.22\n",
      "Params size (MB): 1.03\n",
      "Estimated Total Size (MB): 379.85\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]           1,944\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           4,860\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           5,184\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           3,888\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           6,804\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           8,100\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           4,860\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           7,776\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           9,801\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           5,346\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           8,262\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]          11,178\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]          14,094\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]          23,409\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]           8,262\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]          11,178\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]          15,876\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 14, 100, 100]              28\n",
      "             ReLU-91         [-1, 14, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           6,804\n",
      "       conv_layer-93         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 20, 100, 100]              40\n",
      "             ReLU-95         [-1, 20, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           9,720\n",
      "       conv_layer-97         [-1, 26, 100, 100]               0\n",
      "      Dense_block-98         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 26, 100, 100]              52\n",
      "            ReLU-100         [-1, 26, 100, 100]               0\n",
      "          Conv2d-101         [-1, 13, 100, 100]             338\n",
      "     BatchNorm2d-102         [-1, 13, 100, 100]              26\n",
      "            ReLU-103         [-1, 13, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 13, 200, 200]          13,689\n",
      "   Encode_Decode-105         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           8,262\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]          11,178\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 204,198\n",
      "Trainable params: 204,198\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 184.95\n",
      "Params size (MB): 0.78\n",
      "Estimated Total Size (MB): 186.34\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 9\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             288\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]             864\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]             900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]             720\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           1,296\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           1,521\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]             936\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           1,512\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           1,764\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           1,008\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           1,584\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]           2,025\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           1,080\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           1,656\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]           2,232\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]           2,808\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]           4,761\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 37, 25, 25]              74\n",
      "             ReLU-91           [-1, 37, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]           2,664\n",
      "       conv_layer-93           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 45, 25, 25]              90\n",
      "             ReLU-95           [-1, 45, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]           3,240\n",
      "       conv_layer-97           [-1, 53, 25, 25]               0\n",
      "      Dense_block-98           [-1, 53, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 53, 25, 25]             106\n",
      "            ReLU-100           [-1, 53, 25, 25]               0\n",
      "          Conv2d-101           [-1, 26, 25, 25]           1,378\n",
      "     BatchNorm2d-102           [-1, 26, 25, 25]              52\n",
      "            ReLU-103           [-1, 26, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 26, 50, 50]           6,084\n",
      "   Encode_Decode-105           [-1, 26, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 39, 50, 50]              78\n",
      "            ReLU-107           [-1, 39, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]           2,808\n",
      "      conv_layer-109           [-1, 47, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 47, 50, 50]              94\n",
      "            ReLU-111           [-1, 47, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]           3,384\n",
      "      conv_layer-113           [-1, 55, 50, 50]               0\n",
      "     Dense_block-114           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 55, 50, 50]             110\n",
      "            ReLU-116           [-1, 55, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,485\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]           6,561\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 27, 100, 100]              54\n",
      "            ReLU-123         [-1, 27, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]           1,944\n",
      "      conv_layer-125         [-1, 35, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 35, 100, 100]              70\n",
      "            ReLU-127         [-1, 35, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]           2,520\n",
      "      conv_layer-129         [-1, 43, 100, 100]               0\n",
      "     Dense_block-130         [-1, 43, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 43, 100, 100]              86\n",
      "            ReLU-132         [-1, 43, 100, 100]               0\n",
      "          Conv2d-133         [-1, 21, 100, 100]             903\n",
      "     BatchNorm2d-134         [-1, 21, 100, 100]              42\n",
      "            ReLU-135         [-1, 21, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 21, 200, 200]           3,969\n",
      "   Encode_Decode-137         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 25, 200, 200]              50\n",
      "            ReLU-139         [-1, 25, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]           1,800\n",
      "      conv_layer-141         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 33, 200, 200]              66\n",
      "            ReLU-143         [-1, 33, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]           2,376\n",
      "      conv_layer-145         [-1, 41, 200, 200]               0\n",
      "     Dense_block-146         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 41, 200, 200]              82\n",
      "            ReLU-148         [-1, 41, 200, 200]               0\n",
      "          Conv2d-149         [-1, 20, 200, 200]             820\n",
      "     BatchNorm2d-150         [-1, 20, 200, 200]              40\n",
      "            ReLU-151         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             320\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 73,876\n",
      "Trainable params: 73,876\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 263.43\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 264.32\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             196\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             245\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             294\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             343\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             784\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             392\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             441\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 5,378\n",
      "Trainable params: 5,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 66.95\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           2,916\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           9,477\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           8,019\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]          14,580\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]          15,876\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]          10,206\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          16,767\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          20,736\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]          11,664\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          18,225\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          23,409\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]          12,393\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          18,954\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          25,515\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          32,076\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          54,756\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          30,618\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          37,179\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]          72,900\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          32,076\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          38,637\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]          77,841\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          30,618\n",
      "      conv_layer-125         [-1, 51, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 51, 100, 100]             102\n",
      "            ReLU-127         [-1, 51, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          37,179\n",
      "      conv_layer-129         [-1, 60, 100, 100]               0\n",
      "     Dense_block-130         [-1, 60, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 60, 100, 100]             120\n",
      "            ReLU-132         [-1, 60, 100, 100]               0\n",
      "          Conv2d-133         [-1, 30, 100, 100]           1,800\n",
      "     BatchNorm2d-134         [-1, 30, 100, 100]              60\n",
      "            ReLU-135         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 30, 200, 200]          72,900\n",
      "   Encode_Decode-137         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          24,786\n",
      "      conv_layer-141         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 43, 200, 200]              86\n",
      "            ReLU-143         [-1, 43, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          31,347\n",
      "      conv_layer-145         [-1, 52, 200, 200]               0\n",
      "     Dense_block-146         [-1, 52, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 52, 200, 200]             104\n",
      "            ReLU-148         [-1, 52, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,352\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 804,427\n",
      "Trainable params: 804,427\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 326.73\n",
      "Params size (MB): 3.07\n",
      "Estimated Total Size (MB): 330.41\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]              36\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              18\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              27\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]              36\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]              45\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]              81\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              27\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]              36\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]              36\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 2, 50, 50]               4\n",
      "            ReLU-107            [-1, 2, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              18\n",
      "      conv_layer-109            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 3, 50, 50]               6\n",
      "            ReLU-111            [-1, 3, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]              27\n",
      "      conv_layer-113            [-1, 4, 50, 50]               0\n",
      "     Dense_block-114            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 4, 50, 50]               8\n",
      "            ReLU-116            [-1, 4, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]               8\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]              36\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 5, 100, 100]              10\n",
      "            ReLU-123          [-1, 5, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              45\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]              54\n",
      "      conv_layer-129          [-1, 7, 100, 100]               0\n",
      "     Dense_block-130          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 7, 100, 100]              14\n",
      "            ReLU-132          [-1, 7, 100, 100]               0\n",
      "          Conv2d-133          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-134          [-1, 3, 100, 100]               6\n",
      "            ReLU-135          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 3, 200, 200]              81\n",
      "   Encode_Decode-137          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 7, 200, 200]              14\n",
      "            ReLU-139          [-1, 7, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              63\n",
      "      conv_layer-141          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 8, 200, 200]              16\n",
      "            ReLU-143          [-1, 8, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              72\n",
      "      conv_layer-145          [-1, 9, 200, 200]               0\n",
      "     Dense_block-146          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 9, 200, 200]              18\n",
      "            ReLU-148          [-1, 9, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,772\n",
      "Trainable params: 1,772\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 61.54\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 62.16\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           2,156\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           8,085\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           8,281\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           7,007\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          12,936\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           9,163\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          15,092\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          17,689\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          10,241\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          16,170\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          19,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]          10,780\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]          16,709\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          22,638\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          28,567\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          50,176\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]          17,248\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          23,177\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          35,721\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          23,716\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          29,645\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          53,361\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          24,794\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          30,723\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          56,644\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 38, 200, 200]              76\n",
      "            ReLU-139         [-1, 38, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          20,482\n",
      "      conv_layer-141         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 49, 200, 200]              98\n",
      "            ReLU-143         [-1, 49, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          26,411\n",
      "      conv_layer-145         [-1, 60, 200, 200]               0\n",
      "     Dense_block-146         [-1, 60, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 60, 200, 200]             120\n",
      "            ReLU-148         [-1, 60, 200, 200]               0\n",
      "          Conv2d-149         [-1, 30, 200, 200]           1,800\n",
      "     BatchNorm2d-150         [-1, 30, 200, 200]              60\n",
      "            ReLU-151         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             480\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 626,963\n",
      "Trainable params: 626,963\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 373.84\n",
      "Params size (MB): 2.39\n",
      "Estimated Total Size (MB): 376.84\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           4,230\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           5,130\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]           9,801\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 33, 50, 50]              66\n",
      "            ReLU-107           [-1, 33, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           2,970\n",
      "      conv_layer-109           [-1, 43, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 43, 50, 50]              86\n",
      "            ReLU-111           [-1, 43, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           3,870\n",
      "      conv_layer-113           [-1, 53, 50, 50]               0\n",
      "     Dense_block-114           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 53, 50, 50]             106\n",
      "            ReLU-116           [-1, 53, 50, 50]               0\n",
      "          Conv2d-117           [-1, 26, 50, 50]           1,378\n",
      "     BatchNorm2d-118           [-1, 26, 50, 50]              52\n",
      "            ReLU-119           [-1, 26, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 26, 100, 100]           6,084\n",
      "   Encode_Decode-121         [-1, 26, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 38, 100, 100]              76\n",
      "            ReLU-123         [-1, 38, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           3,420\n",
      "      conv_layer-125         [-1, 48, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 48, 100, 100]              96\n",
      "            ReLU-127         [-1, 48, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           4,320\n",
      "      conv_layer-129         [-1, 58, 100, 100]               0\n",
      "     Dense_block-130         [-1, 58, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 58, 100, 100]             116\n",
      "            ReLU-132         [-1, 58, 100, 100]               0\n",
      "          Conv2d-133         [-1, 29, 100, 100]           1,682\n",
      "     BatchNorm2d-134         [-1, 29, 100, 100]              58\n",
      "            ReLU-135         [-1, 29, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 29, 200, 200]           7,569\n",
      "   Encode_Decode-137         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 33, 200, 200]              66\n",
      "            ReLU-139         [-1, 33, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           2,970\n",
      "      conv_layer-141         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 43, 200, 200]              86\n",
      "            ReLU-143         [-1, 43, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           3,870\n",
      "      conv_layer-145         [-1, 53, 200, 200]               0\n",
      "     Dense_block-146         [-1, 53, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 53, 200, 200]             106\n",
      "            ReLU-148         [-1, 53, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,378\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 109,990\n",
      "Trainable params: 109,990\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 331.39\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 332.42\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             392\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             588\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             784\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             392\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             588\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             784\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             392\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             588\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             784\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             392\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             588\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]             784\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]             392\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             588\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]             784\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]             980\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]           1,764\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 6, 25, 25]              12\n",
      "             ReLU-91            [-1, 6, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]             588\n",
      "       conv_layer-93            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 8, 25, 25]              16\n",
      "             ReLU-95            [-1, 8, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]             784\n",
      "       conv_layer-97           [-1, 10, 25, 25]               0\n",
      "      Dense_block-98           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 10, 25, 25]              20\n",
      "            ReLU-100           [-1, 10, 25, 25]               0\n",
      "          Conv2d-101            [-1, 5, 25, 25]              50\n",
      "     BatchNorm2d-102            [-1, 5, 25, 25]              10\n",
      "            ReLU-103            [-1, 5, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 5, 50, 50]           1,225\n",
      "   Encode_Decode-105            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]             490\n",
      "      conv_layer-109            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 7, 50, 50]              14\n",
      "            ReLU-111            [-1, 7, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]             686\n",
      "      conv_layer-113            [-1, 9, 50, 50]               0\n",
      "     Dense_block-114            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 9, 50, 50]              18\n",
      "            ReLU-116            [-1, 9, 50, 50]               0\n",
      "          Conv2d-117            [-1, 4, 50, 50]              36\n",
      "     BatchNorm2d-118            [-1, 4, 50, 50]               8\n",
      "            ReLU-119            [-1, 4, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 4, 100, 100]             784\n",
      "   Encode_Decode-121          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 4, 100, 100]               8\n",
      "            ReLU-123          [-1, 4, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]             392\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]             588\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             784\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]             392\n",
      "      conv_layer-141          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 6, 200, 200]              12\n",
      "            ReLU-143          [-1, 6, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]             588\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 19,887\n",
      "Trainable params: 19,887\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 68.23\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 68.92\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 20, 25, 25]              40\n",
      "             ReLU-91           [-1, 20, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]           6,860\n",
      "       conv_layer-93           [-1, 27, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 27, 25, 25]              54\n",
      "             ReLU-95           [-1, 27, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]           9,261\n",
      "       conv_layer-97           [-1, 34, 25, 25]               0\n",
      "      Dense_block-98           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 34, 25, 25]              68\n",
      "            ReLU-100           [-1, 34, 25, 25]               0\n",
      "          Conv2d-101           [-1, 17, 25, 25]             578\n",
      "     BatchNorm2d-102           [-1, 17, 25, 25]              34\n",
      "            ReLU-103           [-1, 17, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 17, 50, 50]          14,161\n",
      "   Encode_Decode-105           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 28, 50, 50]              56\n",
      "            ReLU-107           [-1, 28, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]           9,604\n",
      "      conv_layer-109           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 35, 50, 50]              70\n",
      "            ReLU-111           [-1, 35, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          12,005\n",
      "      conv_layer-113           [-1, 42, 50, 50]               0\n",
      "     Dense_block-114           [-1, 42, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 42, 50, 50]              84\n",
      "            ReLU-116           [-1, 42, 50, 50]               0\n",
      "          Conv2d-117           [-1, 21, 50, 50]             882\n",
      "     BatchNorm2d-118           [-1, 21, 50, 50]              42\n",
      "            ReLU-119           [-1, 21, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 21, 100, 100]          21,609\n",
      "   Encode_Decode-121         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 30, 100, 100]              60\n",
      "            ReLU-123         [-1, 30, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]          10,290\n",
      "      conv_layer-125         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 37, 100, 100]              74\n",
      "            ReLU-127         [-1, 37, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]          12,691\n",
      "      conv_layer-129         [-1, 44, 100, 100]               0\n",
      "     Dense_block-130         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 44, 100, 100]              88\n",
      "            ReLU-132         [-1, 44, 100, 100]               0\n",
      "          Conv2d-133         [-1, 22, 100, 100]             968\n",
      "     BatchNorm2d-134         [-1, 22, 100, 100]              44\n",
      "            ReLU-135         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 22, 200, 200]          23,716\n",
      "   Encode_Decode-137         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 22, 200, 200]              44\n",
      "            ReLU-139         [-1, 22, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           7,546\n",
      "      conv_layer-141         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 29, 200, 200]              58\n",
      "            ReLU-143         [-1, 29, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]           9,947\n",
      "      conv_layer-145         [-1, 36, 200, 200]               0\n",
      "     Dense_block-146         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 36, 200, 200]              72\n",
      "            ReLU-148         [-1, 36, 200, 200]               0\n",
      "          Conv2d-149         [-1, 18, 200, 200]             648\n",
      "     BatchNorm2d-150         [-1, 18, 200, 200]              36\n",
      "            ReLU-151         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             288\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 256,156\n",
      "Trainable params: 256,156\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 238.36\n",
      "Params size (MB): 0.98\n",
      "Estimated Total Size (MB): 239.95\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           7,225\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           3,825\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           5,850\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           7,875\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           9,900\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          16,900\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           9,450\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          11,475\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]          22,500\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           9,900\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          11,925\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]          24,025\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           9,450\n",
      "      conv_layer-125         [-1, 51, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 51, 100, 100]             102\n",
      "            ReLU-127         [-1, 51, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          11,475\n",
      "      conv_layer-129         [-1, 60, 100, 100]               0\n",
      "     Dense_block-130         [-1, 60, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 60, 100, 100]             120\n",
      "            ReLU-132         [-1, 60, 100, 100]               0\n",
      "          Conv2d-133         [-1, 30, 100, 100]           1,800\n",
      "     BatchNorm2d-134         [-1, 30, 100, 100]              60\n",
      "            ReLU-135         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 30, 200, 200]          22,500\n",
      "   Encode_Decode-137         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           6,750\n",
      "      conv_layer-141         [-1, 39, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 39, 200, 200]              78\n",
      "            ReLU-143         [-1, 39, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           8,775\n",
      "      conv_layer-145         [-1, 48, 200, 200]               0\n",
      "     Dense_block-146         [-1, 48, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 48, 200, 200]              96\n",
      "            ReLU-148         [-1, 48, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,152\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 255,191\n",
      "Trainable params: 255,191\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 313.91\n",
      "Params size (MB): 0.97\n",
      "Estimated Total Size (MB): 315.50\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             800\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           2,400\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           2,500\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           2,000\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           3,600\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           4,225\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           2,600\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           4,200\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 29, 50, 50]              58\n",
      "             ReLU-43           [-1, 29, 50, 50]               0\n",
      "           Conv2d-44            [-1, 8, 50, 50]           5,800\n",
      "       conv_layer-45           [-1, 37, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 37, 50, 50]              74\n",
      "             ReLU-47           [-1, 37, 50, 50]               0\n",
      "           Conv2d-48            [-1, 8, 50, 50]           7,400\n",
      "       conv_layer-49           [-1, 45, 50, 50]               0\n",
      "      Dense_block-50           [-1, 45, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 45, 50, 50]              90\n",
      "             ReLU-52           [-1, 45, 50, 50]               0\n",
      "           Conv2d-53           [-1, 22, 50, 50]             990\n",
      "      BatchNorm2d-54           [-1, 22, 50, 50]              44\n",
      "             ReLU-55           [-1, 22, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 22, 100, 100]          12,100\n",
      "    Encode_Decode-57         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 22, 100, 100]              44\n",
      "             ReLU-59         [-1, 22, 100, 100]               0\n",
      "           Conv2d-60          [-1, 8, 100, 100]           4,400\n",
      "       conv_layer-61         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 30, 100, 100]              60\n",
      "             ReLU-63         [-1, 30, 100, 100]               0\n",
      "           Conv2d-64          [-1, 8, 100, 100]           6,000\n",
      "       conv_layer-65         [-1, 38, 100, 100]               0\n",
      "      Dense_block-66         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 38, 100, 100]              76\n",
      "             ReLU-68         [-1, 38, 100, 100]               0\n",
      "           Conv2d-69         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-70         [-1, 19, 100, 100]              38\n",
      "             ReLU-71         [-1, 19, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 19, 200, 200]           9,025\n",
      "    Encode_Decode-73         [-1, 19, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 19, 200, 200]              38\n",
      "             ReLU-75         [-1, 19, 200, 200]               0\n",
      "           Conv2d-76          [-1, 8, 200, 200]           3,800\n",
      "       conv_layer-77         [-1, 27, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 27, 200, 200]              54\n",
      "             ReLU-79         [-1, 27, 200, 200]               0\n",
      "           Conv2d-80          [-1, 8, 200, 200]           5,400\n",
      "       conv_layer-81         [-1, 35, 200, 200]               0\n",
      "      Dense_block-82         [-1, 35, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 35, 200, 200]              70\n",
      "             ReLU-84         [-1, 35, 200, 200]               0\n",
      "           Conv2d-85         [-1, 17, 200, 200]             595\n",
      "      BatchNorm2d-86         [-1, 17, 200, 200]              34\n",
      "             ReLU-87         [-1, 17, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             272\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 80,485\n",
      "Trainable params: 80,485\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 227.95\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 228.86\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]          10,976\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]          13,377\n",
      "       conv_layer-97           [-1, 46, 25, 25]               0\n",
      "      Dense_block-98           [-1, 46, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 46, 25, 25]              92\n",
      "            ReLU-100           [-1, 46, 25, 25]               0\n",
      "          Conv2d-101           [-1, 23, 25, 25]           1,058\n",
      "     BatchNorm2d-102           [-1, 23, 25, 25]              46\n",
      "            ReLU-103           [-1, 23, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 23, 50, 50]          25,921\n",
      "   Encode_Decode-105           [-1, 23, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 34, 50, 50]              68\n",
      "            ReLU-107           [-1, 34, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]          11,662\n",
      "      conv_layer-109           [-1, 41, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 41, 50, 50]              82\n",
      "            ReLU-111           [-1, 41, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          14,063\n",
      "      conv_layer-113           [-1, 48, 50, 50]               0\n",
      "     Dense_block-114           [-1, 48, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 48, 50, 50]              96\n",
      "            ReLU-116           [-1, 48, 50, 50]               0\n",
      "          Conv2d-117           [-1, 24, 50, 50]           1,152\n",
      "     BatchNorm2d-118           [-1, 24, 50, 50]              48\n",
      "            ReLU-119           [-1, 24, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 24, 100, 100]          28,224\n",
      "   Encode_Decode-121         [-1, 24, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 24, 100, 100]              48\n",
      "            ReLU-123         [-1, 24, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]           8,232\n",
      "      conv_layer-125         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 31, 100, 100]              62\n",
      "            ReLU-127         [-1, 31, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]          10,633\n",
      "      conv_layer-129         [-1, 38, 100, 100]               0\n",
      "     Dense_block-130         [-1, 38, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 38, 100, 100]              76\n",
      "            ReLU-132         [-1, 38, 100, 100]               0\n",
      "          Conv2d-133         [-1, 19, 100, 100]             722\n",
      "     BatchNorm2d-134         [-1, 19, 100, 100]              38\n",
      "            ReLU-135         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 19, 200, 200]          17,689\n",
      "   Encode_Decode-137         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 23, 200, 200]              46\n",
      "            ReLU-139         [-1, 23, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           7,889\n",
      "      conv_layer-141         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 30, 200, 200]              60\n",
      "            ReLU-143         [-1, 30, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]          10,290\n",
      "      conv_layer-145         [-1, 37, 200, 200]               0\n",
      "     Dense_block-146         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 37, 200, 200]              74\n",
      "            ReLU-148         [-1, 37, 200, 200]               0\n",
      "          Conv2d-149         [-1, 18, 200, 200]             666\n",
      "     BatchNorm2d-150         [-1, 18, 200, 200]              36\n",
      "            ReLU-151         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             288\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 278,034\n",
      "Trainable params: 278,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 236.96\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 238.63\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          14,161\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           7,497\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          11,466\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          15,435\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          19,404\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          33,124\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          11,466\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          15,435\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          23,716\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 22, 50, 50]              44\n",
      "            ReLU-107           [-1, 22, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           9,702\n",
      "      conv_layer-109           [-1, 31, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 31, 50, 50]              62\n",
      "            ReLU-111           [-1, 31, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          13,671\n",
      "      conv_layer-113           [-1, 40, 50, 50]               0\n",
      "     Dense_block-114           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 40, 50, 50]              80\n",
      "            ReLU-116           [-1, 40, 50, 50]               0\n",
      "          Conv2d-117           [-1, 20, 50, 50]             800\n",
      "     BatchNorm2d-118           [-1, 20, 50, 50]              40\n",
      "            ReLU-119           [-1, 20, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 20, 100, 100]          19,600\n",
      "   Encode_Decode-121         [-1, 20, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 31, 100, 100]              62\n",
      "            ReLU-123         [-1, 31, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          13,671\n",
      "      conv_layer-125         [-1, 40, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 40, 100, 100]              80\n",
      "            ReLU-127         [-1, 40, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          17,640\n",
      "      conv_layer-129         [-1, 49, 100, 100]               0\n",
      "     Dense_block-130         [-1, 49, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 49, 100, 100]              98\n",
      "            ReLU-132         [-1, 49, 100, 100]               0\n",
      "          Conv2d-133         [-1, 24, 100, 100]           1,176\n",
      "     BatchNorm2d-134         [-1, 24, 100, 100]              48\n",
      "            ReLU-135         [-1, 24, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 24, 200, 200]          28,224\n",
      "   Encode_Decode-137         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 24, 200, 200]              48\n",
      "            ReLU-139         [-1, 24, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          10,584\n",
      "      conv_layer-141         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 33, 200, 200]              66\n",
      "            ReLU-143         [-1, 33, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          14,553\n",
      "      conv_layer-145         [-1, 42, 200, 200]               0\n",
      "     Dense_block-146         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 42, 200, 200]              84\n",
      "            ReLU-148         [-1, 42, 200, 200]               0\n",
      "          Conv2d-149         [-1, 21, 200, 200]             882\n",
      "     BatchNorm2d-150         [-1, 21, 200, 200]              42\n",
      "            ReLU-151         [-1, 21, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             336\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 372,426\n",
      "Trainable params: 372,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 274.91\n",
      "Params size (MB): 1.42\n",
      "Estimated Total Size (MB): 276.94\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             324\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             405\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             729\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             243\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             324\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             324\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]             162\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             243\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             324\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]             162\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             243\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             324\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]             162\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             243\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             324\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             405\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             729\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             405\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             486\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             729\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 3, 50, 50]               6\n",
      "            ReLU-107            [-1, 3, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             243\n",
      "      conv_layer-109            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 4, 50, 50]               8\n",
      "            ReLU-111            [-1, 4, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             324\n",
      "      conv_layer-113            [-1, 5, 50, 50]               0\n",
      "     Dense_block-114            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 5, 50, 50]              10\n",
      "            ReLU-116            [-1, 5, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]              10\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]             324\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 5, 100, 100]              10\n",
      "            ReLU-123          [-1, 5, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             405\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             486\n",
      "      conv_layer-129          [-1, 7, 100, 100]               0\n",
      "     Dense_block-130          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 7, 100, 100]              14\n",
      "            ReLU-132          [-1, 7, 100, 100]               0\n",
      "          Conv2d-133          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-134          [-1, 3, 100, 100]               6\n",
      "            ReLU-135          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 3, 200, 200]             729\n",
      "   Encode_Decode-137          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 7, 200, 200]              14\n",
      "            ReLU-139          [-1, 7, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             567\n",
      "      conv_layer-141          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 8, 200, 200]              16\n",
      "            ReLU-143          [-1, 8, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             648\n",
      "      conv_layer-145          [-1, 9, 200, 200]               0\n",
      "     Dense_block-146          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 9, 200, 200]              18\n",
      "            ReLU-148          [-1, 9, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 11,696\n",
      "Trainable params: 11,696\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 61.85\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 62.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      Dense_block-42           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 15, 50, 50]              30\n",
      "             ReLU-44           [-1, 15, 50, 50]               0\n",
      "           Conv2d-45            [-1, 7, 50, 50]             105\n",
      "      BatchNorm2d-46            [-1, 7, 50, 50]              14\n",
      "             ReLU-47            [-1, 7, 50, 50]               0\n",
      "           Conv2d-48            [-1, 7, 25, 25]           3,969\n",
      "    Encode_Decode-49            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 7, 25, 25]              14\n",
      "             ReLU-51            [-1, 7, 25, 25]               0\n",
      "           Conv2d-52            [-1, 4, 25, 25]           2,268\n",
      "       conv_layer-53           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 11, 25, 25]              22\n",
      "             ReLU-55           [-1, 11, 25, 25]               0\n",
      "           Conv2d-56            [-1, 4, 25, 25]           3,564\n",
      "       conv_layer-57           [-1, 15, 25, 25]               0\n",
      "      Dense_block-58           [-1, 15, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 15, 25, 25]              30\n",
      "             ReLU-60           [-1, 15, 25, 25]               0\n",
      "           Conv2d-61            [-1, 7, 25, 25]             105\n",
      "      BatchNorm2d-62            [-1, 7, 25, 25]              14\n",
      "             ReLU-63            [-1, 7, 25, 25]               0\n",
      "           Conv2d-64            [-1, 7, 13, 13]           3,969\n",
      "    Encode_Decode-65            [-1, 7, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 7, 13, 13]              14\n",
      "             ReLU-67            [-1, 7, 13, 13]               0\n",
      "           Conv2d-68            [-1, 4, 13, 13]           2,268\n",
      "       conv_layer-69           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 11, 13, 13]              22\n",
      "             ReLU-71           [-1, 11, 13, 13]               0\n",
      "           Conv2d-72            [-1, 4, 13, 13]           3,564\n",
      "       conv_layer-73           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 15, 13, 13]              30\n",
      "             ReLU-75           [-1, 15, 13, 13]               0\n",
      "           Conv2d-76            [-1, 4, 13, 13]           4,860\n",
      "       conv_layer-77           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 19, 13, 13]              38\n",
      "             ReLU-79           [-1, 19, 13, 13]               0\n",
      "           Conv2d-80            [-1, 4, 13, 13]           6,156\n",
      "       conv_layer-81           [-1, 23, 13, 13]               0\n",
      "      Dense_block-82           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 23, 13, 13]              46\n",
      "             ReLU-84           [-1, 23, 13, 13]               0\n",
      "           Conv2d-85           [-1, 11, 13, 13]             253\n",
      "      BatchNorm2d-86           [-1, 11, 13, 13]              22\n",
      "             ReLU-87           [-1, 11, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 11, 25, 25]           9,801\n",
      "    Encode_Decode-89           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 18, 25, 25]              36\n",
      "             ReLU-91           [-1, 18, 25, 25]               0\n",
      "           Conv2d-92            [-1, 4, 25, 25]           5,832\n",
      "       conv_layer-93           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 22, 25, 25]              44\n",
      "             ReLU-95           [-1, 22, 25, 25]               0\n",
      "           Conv2d-96            [-1, 4, 25, 25]           7,128\n",
      "       conv_layer-97           [-1, 26, 25, 25]               0\n",
      "      Dense_block-98           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 26, 25, 25]              52\n",
      "            ReLU-100           [-1, 26, 25, 25]               0\n",
      "          Conv2d-101           [-1, 13, 25, 25]             338\n",
      "     BatchNorm2d-102           [-1, 13, 25, 25]              26\n",
      "            ReLU-103           [-1, 13, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 13, 50, 50]          13,689\n",
      "   Encode_Decode-105           [-1, 13, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 20, 50, 50]              40\n",
      "            ReLU-107           [-1, 20, 50, 50]               0\n",
      "          Conv2d-108            [-1, 4, 50, 50]           6,480\n",
      "      conv_layer-109           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 24, 50, 50]              48\n",
      "            ReLU-111           [-1, 24, 50, 50]               0\n",
      "          Conv2d-112            [-1, 4, 50, 50]           7,776\n",
      "      conv_layer-113           [-1, 28, 50, 50]               0\n",
      "     Dense_block-114           [-1, 28, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 28, 50, 50]              56\n",
      "            ReLU-116           [-1, 28, 50, 50]               0\n",
      "          Conv2d-117           [-1, 14, 50, 50]             392\n",
      "     BatchNorm2d-118           [-1, 14, 50, 50]              28\n",
      "            ReLU-119           [-1, 14, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 14, 100, 100]          15,876\n",
      "   Encode_Decode-121         [-1, 14, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 20, 100, 100]              40\n",
      "            ReLU-123         [-1, 20, 100, 100]               0\n",
      "          Conv2d-124          [-1, 4, 100, 100]           6,480\n",
      "      conv_layer-125         [-1, 24, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 24, 100, 100]              48\n",
      "            ReLU-127         [-1, 24, 100, 100]               0\n",
      "          Conv2d-128          [-1, 4, 100, 100]           7,776\n",
      "      conv_layer-129         [-1, 28, 100, 100]               0\n",
      "     Dense_block-130         [-1, 28, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 28, 100, 100]              56\n",
      "            ReLU-132         [-1, 28, 100, 100]               0\n",
      "          Conv2d-133         [-1, 14, 100, 100]             392\n",
      "     BatchNorm2d-134         [-1, 14, 100, 100]              28\n",
      "            ReLU-135         [-1, 14, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 14, 200, 200]          15,876\n",
      "   Encode_Decode-137         [-1, 14, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 18, 200, 200]              36\n",
      "            ReLU-139         [-1, 18, 200, 200]               0\n",
      "          Conv2d-140          [-1, 4, 200, 200]           5,832\n",
      "      conv_layer-141         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 22, 200, 200]              44\n",
      "            ReLU-143         [-1, 22, 200, 200]               0\n",
      "          Conv2d-144          [-1, 4, 200, 200]           7,128\n",
      "      conv_layer-145         [-1, 26, 200, 200]               0\n",
      "     Dense_block-146         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 26, 200, 200]              52\n",
      "            ReLU-148         [-1, 26, 200, 200]               0\n",
      "          Conv2d-149         [-1, 13, 200, 200]             338\n",
      "     BatchNorm2d-150         [-1, 13, 200, 200]              26\n",
      "            ReLU-151         [-1, 13, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             208\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 165,652\n",
      "Trainable params: 165,652\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 166.41\n",
      "Params size (MB): 0.63\n",
      "Estimated Total Size (MB): 167.65\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 3, 200, 200]             108\n",
      "        conv_layer-5          [-1, 7, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 7, 200, 200]              14\n",
      "              ReLU-7          [-1, 7, 200, 200]               0\n",
      "            Conv2d-8          [-1, 3, 200, 200]             189\n",
      "        conv_layer-9         [-1, 10, 200, 200]               0\n",
      "      Dense_block-10         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 10, 200, 200]              20\n",
      "             ReLU-12         [-1, 10, 200, 200]               0\n",
      "           Conv2d-13          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-14          [-1, 5, 200, 200]              10\n",
      "             ReLU-15          [-1, 5, 200, 200]               0\n",
      "           Conv2d-16          [-1, 5, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 5, 100, 100]              10\n",
      "             ReLU-19          [-1, 5, 100, 100]               0\n",
      "           Conv2d-20          [-1, 3, 100, 100]             135\n",
      "       conv_layer-21          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 8, 100, 100]              16\n",
      "             ReLU-23          [-1, 8, 100, 100]               0\n",
      "           Conv2d-24          [-1, 3, 100, 100]             216\n",
      "       conv_layer-25         [-1, 11, 100, 100]               0\n",
      "      Dense_block-26         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 11, 100, 100]              22\n",
      "             ReLU-28         [-1, 11, 100, 100]               0\n",
      "           Conv2d-29          [-1, 5, 100, 100]              55\n",
      "      BatchNorm2d-30          [-1, 5, 100, 100]              10\n",
      "             ReLU-31          [-1, 5, 100, 100]               0\n",
      "           Conv2d-32            [-1, 5, 50, 50]             225\n",
      "    Encode_Decode-33            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 5, 50, 50]              10\n",
      "             ReLU-35            [-1, 5, 50, 50]               0\n",
      "           Conv2d-36            [-1, 3, 50, 50]             135\n",
      "       conv_layer-37            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 8, 50, 50]              16\n",
      "             ReLU-39            [-1, 8, 50, 50]               0\n",
      "           Conv2d-40            [-1, 3, 50, 50]             216\n",
      "       conv_layer-41           [-1, 11, 50, 50]               0\n",
      "      Dense_block-42           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 11, 50, 50]              22\n",
      "             ReLU-44           [-1, 11, 50, 50]               0\n",
      "           Conv2d-45            [-1, 5, 50, 50]              55\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 25, 25]             225\n",
      "    Encode_Decode-49            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 5, 25, 25]              10\n",
      "             ReLU-51            [-1, 5, 25, 25]               0\n",
      "           Conv2d-52            [-1, 3, 25, 25]             135\n",
      "       conv_layer-53            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 8, 25, 25]              16\n",
      "             ReLU-55            [-1, 8, 25, 25]               0\n",
      "           Conv2d-56            [-1, 3, 25, 25]             216\n",
      "       conv_layer-57           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 11, 25, 25]              22\n",
      "             ReLU-59           [-1, 11, 25, 25]               0\n",
      "           Conv2d-60            [-1, 3, 25, 25]             297\n",
      "       conv_layer-61           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 14, 25, 25]              28\n",
      "             ReLU-63           [-1, 14, 25, 25]               0\n",
      "           Conv2d-64            [-1, 3, 25, 25]             378\n",
      "       conv_layer-65           [-1, 17, 25, 25]               0\n",
      "      Dense_block-66           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 17, 25, 25]              34\n",
      "             ReLU-68           [-1, 17, 25, 25]               0\n",
      "           Conv2d-69            [-1, 8, 25, 25]             136\n",
      "      BatchNorm2d-70            [-1, 8, 25, 25]              16\n",
      "             ReLU-71            [-1, 8, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 8, 50, 50]             576\n",
      "    Encode_Decode-73            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 13, 50, 50]              26\n",
      "             ReLU-75           [-1, 13, 50, 50]               0\n",
      "           Conv2d-76            [-1, 3, 50, 50]             351\n",
      "       conv_layer-77           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 16, 50, 50]              32\n",
      "             ReLU-79           [-1, 16, 50, 50]               0\n",
      "           Conv2d-80            [-1, 3, 50, 50]             432\n",
      "       conv_layer-81           [-1, 19, 50, 50]               0\n",
      "      Dense_block-82           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 19, 50, 50]              38\n",
      "             ReLU-84           [-1, 19, 50, 50]               0\n",
      "           Conv2d-85            [-1, 9, 50, 50]             171\n",
      "      BatchNorm2d-86            [-1, 9, 50, 50]              18\n",
      "             ReLU-87            [-1, 9, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 9, 100, 100]             729\n",
      "    Encode_Decode-89          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 14, 100, 100]              28\n",
      "             ReLU-91         [-1, 14, 100, 100]               0\n",
      "           Conv2d-92          [-1, 3, 100, 100]             378\n",
      "       conv_layer-93         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 17, 100, 100]              34\n",
      "             ReLU-95         [-1, 17, 100, 100]               0\n",
      "           Conv2d-96          [-1, 3, 100, 100]             459\n",
      "       conv_layer-97         [-1, 20, 100, 100]               0\n",
      "      Dense_block-98         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 20, 100, 100]              40\n",
      "            ReLU-100         [-1, 20, 100, 100]               0\n",
      "          Conv2d-101         [-1, 10, 100, 100]             200\n",
      "     BatchNorm2d-102         [-1, 10, 100, 100]              20\n",
      "            ReLU-103         [-1, 10, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 10, 200, 200]             900\n",
      "   Encode_Decode-105         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 14, 200, 200]              28\n",
      "            ReLU-107         [-1, 14, 200, 200]               0\n",
      "          Conv2d-108          [-1, 3, 200, 200]             378\n",
      "      conv_layer-109         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 17, 200, 200]              34\n",
      "            ReLU-111         [-1, 17, 200, 200]               0\n",
      "          Conv2d-112          [-1, 3, 200, 200]             459\n",
      "      conv_layer-113         [-1, 20, 200, 200]               0\n",
      "     Dense_block-114         [-1, 20, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 20, 200, 200]              40\n",
      "            ReLU-116         [-1, 20, 200, 200]               0\n",
      "          Conv2d-117         [-1, 10, 200, 200]             200\n",
      "     BatchNorm2d-118         [-1, 10, 200, 200]              20\n",
      "            ReLU-119         [-1, 10, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             160\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 9,185\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 128.25\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 128.89\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 3\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             980\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           2,205\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           2,401\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]           1,715\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           2,940\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           3,136\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,960\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           3,185\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           3,969\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           2,205\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           3,430\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]           4,655\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           5,880\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 22, 50, 50]              44\n",
      "             ReLU-75           [-1, 22, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]           5,390\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]           6,615\n",
      "       conv_layer-81           [-1, 32, 50, 50]               0\n",
      "      Dense_block-82           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 32, 50, 50]              64\n",
      "             ReLU-84           [-1, 32, 50, 50]               0\n",
      "           Conv2d-85           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-86           [-1, 16, 50, 50]              32\n",
      "             ReLU-87           [-1, 16, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 16, 100, 100]          12,544\n",
      "    Encode_Decode-89         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 23, 100, 100]              46\n",
      "             ReLU-91         [-1, 23, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]           5,635\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           6,860\n",
      "       conv_layer-97         [-1, 33, 100, 100]               0\n",
      "      Dense_block-98         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 33, 100, 100]              66\n",
      "            ReLU-100         [-1, 33, 100, 100]               0\n",
      "          Conv2d-101         [-1, 16, 100, 100]             528\n",
      "     BatchNorm2d-102         [-1, 16, 100, 100]              32\n",
      "            ReLU-103         [-1, 16, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 16, 200, 200]          12,544\n",
      "   Encode_Decode-105         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 20, 200, 200]              40\n",
      "            ReLU-107         [-1, 20, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]           4,900\n",
      "      conv_layer-109         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 25, 200, 200]              50\n",
      "            ReLU-111         [-1, 25, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]           6,125\n",
      "      conv_layer-113         [-1, 30, 200, 200]               0\n",
      "     Dense_block-114         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 30, 200, 200]              60\n",
      "            ReLU-116         [-1, 30, 200, 200]               0\n",
      "          Conv2d-117         [-1, 15, 200, 200]             450\n",
      "     BatchNorm2d-118         [-1, 15, 200, 200]              30\n",
      "            ReLU-119         [-1, 15, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             240\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 112,598\n",
      "Trainable params: 112,598\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 190.42\n",
      "Params size (MB): 0.43\n",
      "Estimated Total Size (MB): 191.46\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 5\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      Dense_block-58           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 45, 25, 25]              90\n",
      "             ReLU-60           [-1, 45, 25, 25]               0\n",
      "           Conv2d-61           [-1, 22, 25, 25]             990\n",
      "      BatchNorm2d-62           [-1, 22, 25, 25]              44\n",
      "             ReLU-63           [-1, 22, 25, 25]               0\n",
      "           Conv2d-64           [-1, 22, 13, 13]          12,100\n",
      "    Encode_Decode-65           [-1, 22, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 22, 13, 13]              44\n",
      "             ReLU-67           [-1, 22, 13, 13]               0\n",
      "           Conv2d-68           [-1, 12, 13, 13]           6,600\n",
      "       conv_layer-69           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 34, 13, 13]              68\n",
      "             ReLU-71           [-1, 34, 13, 13]               0\n",
      "           Conv2d-72           [-1, 12, 13, 13]          10,200\n",
      "       conv_layer-73           [-1, 46, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 46, 13, 13]              92\n",
      "             ReLU-75           [-1, 46, 13, 13]               0\n",
      "           Conv2d-76           [-1, 12, 13, 13]          13,800\n",
      "       conv_layer-77           [-1, 58, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 58, 13, 13]             116\n",
      "             ReLU-79           [-1, 58, 13, 13]               0\n",
      "           Conv2d-80           [-1, 12, 13, 13]          17,400\n",
      "       conv_layer-81           [-1, 70, 13, 13]               0\n",
      "      Dense_block-82           [-1, 70, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 70, 13, 13]             140\n",
      "             ReLU-84           [-1, 70, 13, 13]               0\n",
      "           Conv2d-85           [-1, 35, 13, 13]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 13, 13]              70\n",
      "             ReLU-87           [-1, 35, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 35, 25, 25]          30,625\n",
      "    Encode_Decode-89           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 35, 25, 25]              70\n",
      "             ReLU-91           [-1, 35, 25, 25]               0\n",
      "           Conv2d-92           [-1, 12, 25, 25]          10,500\n",
      "       conv_layer-93           [-1, 47, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 47, 25, 25]              94\n",
      "             ReLU-95           [-1, 47, 25, 25]               0\n",
      "           Conv2d-96           [-1, 12, 25, 25]          14,100\n",
      "       conv_layer-97           [-1, 59, 25, 25]               0\n",
      "      Dense_block-98           [-1, 59, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 59, 25, 25]             118\n",
      "            ReLU-100           [-1, 59, 25, 25]               0\n",
      "          Conv2d-101           [-1, 29, 25, 25]           1,711\n",
      "     BatchNorm2d-102           [-1, 29, 25, 25]              58\n",
      "            ReLU-103           [-1, 29, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 29, 50, 50]          21,025\n",
      "   Encode_Decode-105           [-1, 29, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 29, 50, 50]              58\n",
      "            ReLU-107           [-1, 29, 50, 50]               0\n",
      "          Conv2d-108           [-1, 12, 50, 50]           8,700\n",
      "      conv_layer-109           [-1, 41, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 41, 50, 50]              82\n",
      "            ReLU-111           [-1, 41, 50, 50]               0\n",
      "          Conv2d-112           [-1, 12, 50, 50]          12,300\n",
      "      conv_layer-113           [-1, 53, 50, 50]               0\n",
      "     Dense_block-114           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 53, 50, 50]             106\n",
      "            ReLU-116           [-1, 53, 50, 50]               0\n",
      "          Conv2d-117           [-1, 26, 50, 50]           1,378\n",
      "     BatchNorm2d-118           [-1, 26, 50, 50]              52\n",
      "            ReLU-119           [-1, 26, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 26, 100, 100]          16,900\n",
      "   Encode_Decode-121         [-1, 26, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 40, 100, 100]              80\n",
      "            ReLU-123         [-1, 40, 100, 100]               0\n",
      "          Conv2d-124         [-1, 12, 100, 100]          12,000\n",
      "      conv_layer-125         [-1, 52, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 52, 100, 100]             104\n",
      "            ReLU-127         [-1, 52, 100, 100]               0\n",
      "          Conv2d-128         [-1, 12, 100, 100]          15,600\n",
      "      conv_layer-129         [-1, 64, 100, 100]               0\n",
      "     Dense_block-130         [-1, 64, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 64, 100, 100]             128\n",
      "            ReLU-132         [-1, 64, 100, 100]               0\n",
      "          Conv2d-133         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-134         [-1, 32, 100, 100]              64\n",
      "            ReLU-135         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 32, 200, 200]          25,600\n",
      "   Encode_Decode-137         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 32, 200, 200]              64\n",
      "            ReLU-139         [-1, 32, 200, 200]               0\n",
      "          Conv2d-140         [-1, 12, 200, 200]           9,600\n",
      "      conv_layer-141         [-1, 44, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 44, 200, 200]              88\n",
      "            ReLU-143         [-1, 44, 200, 200]               0\n",
      "          Conv2d-144         [-1, 12, 200, 200]          13,200\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 339,806\n",
      "Trainable params: 339,806\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 359.47\n",
      "Params size (MB): 1.30\n",
      "Estimated Total Size (MB): 361.37\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           3,240\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]          11,340\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]          11,664\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           9,720\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          17,820\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          20,736\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]          12,960\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          21,060\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]          26,244\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]          14,580\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]          22,680\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]          29,241\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]          15,390\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]          23,490\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]          31,590\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          39,690\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          68,121\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 29, 25, 25]              58\n",
      "             ReLU-91           [-1, 29, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]          23,490\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]          31,590\n",
      "       conv_layer-97           [-1, 49, 25, 25]               0\n",
      "      Dense_block-98           [-1, 49, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 49, 25, 25]              98\n",
      "            ReLU-100           [-1, 49, 25, 25]               0\n",
      "          Conv2d-101           [-1, 24, 25, 25]           1,176\n",
      "     BatchNorm2d-102           [-1, 24, 25, 25]              48\n",
      "            ReLU-103           [-1, 24, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 24, 50, 50]          46,656\n",
      "   Encode_Decode-105           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 24, 50, 50]              48\n",
      "            ReLU-107           [-1, 24, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          19,440\n",
      "      conv_layer-109           [-1, 34, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 34, 50, 50]              68\n",
      "            ReLU-111           [-1, 34, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          27,540\n",
      "      conv_layer-113           [-1, 44, 50, 50]               0\n",
      "     Dense_block-114           [-1, 44, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 44, 50, 50]              88\n",
      "            ReLU-116           [-1, 44, 50, 50]               0\n",
      "          Conv2d-117           [-1, 22, 50, 50]             968\n",
      "     BatchNorm2d-118           [-1, 22, 50, 50]              44\n",
      "            ReLU-119           [-1, 22, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 22, 100, 100]          39,204\n",
      "   Encode_Decode-121         [-1, 22, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 22, 100, 100]              44\n",
      "            ReLU-123         [-1, 22, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]          17,820\n",
      "      conv_layer-125         [-1, 32, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 32, 100, 100]              64\n",
      "            ReLU-127         [-1, 32, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          25,920\n",
      "      conv_layer-129         [-1, 42, 100, 100]               0\n",
      "     Dense_block-130         [-1, 42, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 42, 100, 100]              84\n",
      "            ReLU-132         [-1, 42, 100, 100]               0\n",
      "          Conv2d-133         [-1, 21, 100, 100]             882\n",
      "     BatchNorm2d-134         [-1, 21, 100, 100]              42\n",
      "            ReLU-135         [-1, 21, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 21, 200, 200]          35,721\n",
      "   Encode_Decode-137         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 25, 200, 200]              50\n",
      "            ReLU-139         [-1, 25, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]          20,250\n",
      "      conv_layer-141         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 35, 200, 200]              70\n",
      "            ReLU-143         [-1, 35, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]          28,350\n",
      "      conv_layer-145         [-1, 45, 200, 200]               0\n",
      "     Dense_block-146         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 45, 200, 200]              90\n",
      "            ReLU-148         [-1, 45, 200, 200]               0\n",
      "          Conv2d-149         [-1, 22, 200, 200]             990\n",
      "     BatchNorm2d-150         [-1, 22, 200, 200]              44\n",
      "            ReLU-151         [-1, 22, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             352\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 706,076\n",
      "Trainable params: 706,076\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 284.42\n",
      "Params size (MB): 2.69\n",
      "Estimated Total Size (MB): 287.73\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 52, 100, 100]             104\n",
      "             ReLU-91         [-1, 52, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          15,600\n",
      "       conv_layer-93         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 64, 100, 100]             128\n",
      "             ReLU-95         [-1, 64, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          19,200\n",
      "       conv_layer-97         [-1, 76, 100, 100]               0\n",
      "      Dense_block-98         [-1, 76, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 76, 100, 100]             152\n",
      "            ReLU-100         [-1, 76, 100, 100]               0\n",
      "          Conv2d-101         [-1, 38, 100, 100]           2,888\n",
      "     BatchNorm2d-102         [-1, 38, 100, 100]              76\n",
      "            ReLU-103         [-1, 38, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 38, 200, 200]          36,100\n",
      "   Encode_Decode-105         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 42, 200, 200]              84\n",
      "            ReLU-107         [-1, 42, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]          12,600\n",
      "      conv_layer-109         [-1, 54, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 54, 200, 200]             108\n",
      "            ReLU-111         [-1, 54, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          16,200\n",
      "      conv_layer-113         [-1, 66, 200, 200]               0\n",
      "     Dense_block-114         [-1, 66, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 66, 200, 200]             132\n",
      "            ReLU-116         [-1, 66, 200, 200]               0\n",
      "          Conv2d-117         [-1, 33, 200, 200]           2,178\n",
      "     BatchNorm2d-118         [-1, 33, 200, 200]              66\n",
      "            ReLU-119         [-1, 33, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             528\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 320,257\n",
      "Trainable params: 320,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 409.62\n",
      "Params size (MB): 1.22\n",
      "Estimated Total Size (MB): 411.45\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]          15,876\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           8,820\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]          13,720\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]          17,689\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           9,310\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]          14,210\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]          19,110\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          24,010\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          41,209\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 29, 25, 25]              58\n",
      "             ReLU-91           [-1, 29, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]          14,210\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]          19,110\n",
      "       conv_layer-97           [-1, 49, 25, 25]               0\n",
      "      Dense_block-98           [-1, 49, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 49, 25, 25]              98\n",
      "            ReLU-100           [-1, 49, 25, 25]               0\n",
      "          Conv2d-101           [-1, 24, 25, 25]           1,176\n",
      "     BatchNorm2d-102           [-1, 24, 25, 25]              48\n",
      "            ReLU-103           [-1, 24, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 24, 50, 50]          28,224\n",
      "   Encode_Decode-105           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 40, 50, 50]              80\n",
      "            ReLU-107           [-1, 40, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          19,600\n",
      "      conv_layer-109           [-1, 50, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 50, 50, 50]             100\n",
      "            ReLU-111           [-1, 50, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          24,500\n",
      "      conv_layer-113           [-1, 60, 50, 50]               0\n",
      "     Dense_block-114           [-1, 60, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 60, 50, 50]             120\n",
      "            ReLU-116           [-1, 60, 50, 50]               0\n",
      "          Conv2d-117           [-1, 30, 50, 50]           1,800\n",
      "     BatchNorm2d-118           [-1, 30, 50, 50]              60\n",
      "            ReLU-119           [-1, 30, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 30, 100, 100]          44,100\n",
      "   Encode_Decode-121         [-1, 30, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 30, 100, 100]              60\n",
      "            ReLU-123         [-1, 30, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]          14,700\n",
      "      conv_layer-125         [-1, 40, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 40, 100, 100]              80\n",
      "            ReLU-127         [-1, 40, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          19,600\n",
      "      conv_layer-129         [-1, 50, 100, 100]               0\n",
      "     Dense_block-130         [-1, 50, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 50, 100, 100]             100\n",
      "            ReLU-132         [-1, 50, 100, 100]               0\n",
      "          Conv2d-133         [-1, 25, 100, 100]           1,250\n",
      "     BatchNorm2d-134         [-1, 25, 100, 100]              50\n",
      "            ReLU-135         [-1, 25, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 25, 200, 200]          30,625\n",
      "   Encode_Decode-137         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 29, 200, 200]              58\n",
      "            ReLU-139         [-1, 29, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]          14,210\n",
      "      conv_layer-141         [-1, 39, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 39, 200, 200]              78\n",
      "            ReLU-143         [-1, 39, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]          19,110\n",
      "      conv_layer-145         [-1, 49, 200, 200]               0\n",
      "     Dense_block-146         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 49, 200, 200]              98\n",
      "            ReLU-148         [-1, 49, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,176\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 489,746\n",
      "Trainable params: 489,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 310.51\n",
      "Params size (MB): 1.87\n",
      "Estimated Total Size (MB): 312.99\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,000\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           3,500\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           3,000\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           5,500\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           6,400\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           4,000\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           6,500\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           8,100\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           4,500\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           7,000\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           9,025\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           4,750\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           7,250\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           9,750\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          12,250\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          21,025\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]          11,750\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]          14,250\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]          27,225\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          12,250\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          14,750\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          28,900\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 34, 100, 100]              68\n",
      "            ReLU-123         [-1, 34, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           8,500\n",
      "      conv_layer-125         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 44, 100, 100]              88\n",
      "            ReLU-127         [-1, 44, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          11,000\n",
      "      conv_layer-129         [-1, 54, 100, 100]               0\n",
      "     Dense_block-130         [-1, 54, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 54, 100, 100]             108\n",
      "            ReLU-132         [-1, 54, 100, 100]               0\n",
      "          Conv2d-133         [-1, 27, 100, 100]           1,458\n",
      "     BatchNorm2d-134         [-1, 27, 100, 100]              54\n",
      "            ReLU-135         [-1, 27, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 27, 200, 200]          18,225\n",
      "   Encode_Decode-137         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 31, 200, 200]              62\n",
      "            ReLU-139         [-1, 31, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           7,750\n",
      "      conv_layer-141         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 41, 200, 200]              82\n",
      "            ReLU-143         [-1, 41, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]          10,250\n",
      "      conv_layer-145         [-1, 51, 200, 200]               0\n",
      "     Dense_block-146         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 51, 200, 200]             102\n",
      "            ReLU-148         [-1, 51, 200, 200]               0\n",
      "          Conv2d-149         [-1, 25, 200, 200]           1,275\n",
      "     BatchNorm2d-150         [-1, 25, 200, 200]              50\n",
      "            ReLU-151         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             400\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 296,277\n",
      "Trainable params: 296,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 324.98\n",
      "Params size (MB): 1.13\n",
      "Estimated Total Size (MB): 326.72\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             196\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             245\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             441\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             245\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             294\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             294\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             343\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             784\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             196\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             245\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 6,408\n",
      "Trainable params: 6,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 55.15\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 36, 50, 50]              72\n",
      "             ReLU-43           [-1, 36, 50, 50]               0\n",
      "           Conv2d-44           [-1, 10, 50, 50]          17,640\n",
      "       conv_layer-45           [-1, 46, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 46, 50, 50]              92\n",
      "             ReLU-47           [-1, 46, 50, 50]               0\n",
      "           Conv2d-48           [-1, 10, 50, 50]          22,540\n",
      "       conv_layer-49           [-1, 56, 50, 50]               0\n",
      "      Dense_block-50           [-1, 56, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 56, 50, 50]             112\n",
      "             ReLU-52           [-1, 56, 50, 50]               0\n",
      "           Conv2d-53           [-1, 28, 50, 50]           1,568\n",
      "      BatchNorm2d-54           [-1, 28, 50, 50]              56\n",
      "             ReLU-55           [-1, 28, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 28, 100, 100]          38,416\n",
      "    Encode_Decode-57         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 40, 100, 100]              80\n",
      "             ReLU-59         [-1, 40, 100, 100]               0\n",
      "           Conv2d-60         [-1, 10, 100, 100]          19,600\n",
      "       conv_layer-61         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 50, 100, 100]             100\n",
      "             ReLU-63         [-1, 50, 100, 100]               0\n",
      "           Conv2d-64         [-1, 10, 100, 100]          24,500\n",
      "       conv_layer-65         [-1, 60, 100, 100]               0\n",
      "      Dense_block-66         [-1, 60, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 60, 100, 100]             120\n",
      "             ReLU-68         [-1, 60, 100, 100]               0\n",
      "           Conv2d-69         [-1, 30, 100, 100]           1,800\n",
      "      BatchNorm2d-70         [-1, 30, 100, 100]              60\n",
      "             ReLU-71         [-1, 30, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 30, 200, 200]          44,100\n",
      "    Encode_Decode-73         [-1, 30, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 34, 200, 200]              68\n",
      "             ReLU-75         [-1, 34, 200, 200]               0\n",
      "           Conv2d-76         [-1, 10, 200, 200]          16,660\n",
      "       conv_layer-77         [-1, 44, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 44, 200, 200]              88\n",
      "             ReLU-79         [-1, 44, 200, 200]               0\n",
      "           Conv2d-80         [-1, 10, 200, 200]          21,560\n",
      "       conv_layer-81         [-1, 54, 200, 200]               0\n",
      "      Dense_block-82         [-1, 54, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 54, 200, 200]             108\n",
      "             ReLU-84         [-1, 54, 200, 200]               0\n",
      "           Conv2d-85         [-1, 27, 200, 200]           1,458\n",
      "      BatchNorm2d-86         [-1, 27, 200, 200]              54\n",
      "             ReLU-87         [-1, 27, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             432\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 278,244\n",
      "Trainable params: 278,244\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 327.61\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 329.28\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]           1,176\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           2,940\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           3,136\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           2,352\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           4,116\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           2,940\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           4,704\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           5,929\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           3,234\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           4,998\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           6,762\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           8,526\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]           4,998\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           6,762\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           9,604\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 14, 100, 100]              28\n",
      "             ReLU-91         [-1, 14, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           4,116\n",
      "       conv_layer-93         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 20, 100, 100]              40\n",
      "             ReLU-95         [-1, 20, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           5,880\n",
      "       conv_layer-97         [-1, 26, 100, 100]               0\n",
      "      Dense_block-98         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 26, 100, 100]              52\n",
      "            ReLU-100         [-1, 26, 100, 100]               0\n",
      "          Conv2d-101         [-1, 13, 100, 100]             338\n",
      "     BatchNorm2d-102         [-1, 13, 100, 100]              26\n",
      "            ReLU-103         [-1, 13, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 13, 200, 200]           8,281\n",
      "   Encode_Decode-105         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 13, 200, 200]              26\n",
      "            ReLU-107         [-1, 13, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           3,822\n",
      "      conv_layer-109         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 19, 200, 200]              38\n",
      "            ReLU-111         [-1, 19, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           5,586\n",
      "      conv_layer-113         [-1, 25, 200, 200]               0\n",
      "     Dense_block-114         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 25, 200, 200]              50\n",
      "            ReLU-116         [-1, 25, 200, 200]               0\n",
      "          Conv2d-117         [-1, 12, 200, 200]             300\n",
      "     BatchNorm2d-118         [-1, 12, 200, 200]              24\n",
      "            ReLU-119         [-1, 12, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             192\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 122,480\n",
      "Trainable params: 122,480\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 172.13\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 173.21\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 43, 50, 50]              86\n",
      "             ReLU-43           [-1, 43, 50, 50]               0\n",
      "           Conv2d-44           [-1, 12, 50, 50]          12,900\n",
      "       conv_layer-45           [-1, 55, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 55, 50, 50]             110\n",
      "             ReLU-47           [-1, 55, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 50, 50]          16,500\n",
      "       conv_layer-49           [-1, 67, 50, 50]               0\n",
      "      Dense_block-50           [-1, 67, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 67, 50, 50]             134\n",
      "             ReLU-52           [-1, 67, 50, 50]               0\n",
      "           Conv2d-53           [-1, 33, 50, 50]           2,211\n",
      "      BatchNorm2d-54           [-1, 33, 50, 50]              66\n",
      "             ReLU-55           [-1, 33, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 33, 100, 100]          27,225\n",
      "    Encode_Decode-57         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 33, 100, 100]              66\n",
      "             ReLU-59         [-1, 33, 100, 100]               0\n",
      "           Conv2d-60         [-1, 12, 100, 100]           9,900\n",
      "       conv_layer-61         [-1, 45, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 45, 100, 100]              90\n",
      "             ReLU-63         [-1, 45, 100, 100]               0\n",
      "           Conv2d-64         [-1, 12, 100, 100]          13,500\n",
      "       conv_layer-65         [-1, 57, 100, 100]               0\n",
      "      Dense_block-66         [-1, 57, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 57, 100, 100]             114\n",
      "             ReLU-68         [-1, 57, 100, 100]               0\n",
      "           Conv2d-69         [-1, 28, 100, 100]           1,596\n",
      "      BatchNorm2d-70         [-1, 28, 100, 100]              56\n",
      "             ReLU-71         [-1, 28, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 28, 200, 200]          19,600\n",
      "    Encode_Decode-73         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 28, 200, 200]              56\n",
      "             ReLU-75         [-1, 28, 200, 200]               0\n",
      "           Conv2d-76         [-1, 12, 200, 200]           8,400\n",
      "       conv_layer-77         [-1, 40, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 40, 200, 200]              80\n",
      "             ReLU-79         [-1, 40, 200, 200]               0\n",
      "           Conv2d-80         [-1, 12, 200, 200]          12,000\n",
      "       conv_layer-81         [-1, 52, 200, 200]               0\n",
      "      Dense_block-82         [-1, 52, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 52, 200, 200]             104\n",
      "             ReLU-84         [-1, 52, 200, 200]               0\n",
      "           Conv2d-85         [-1, 26, 200, 200]           1,352\n",
      "      BatchNorm2d-86         [-1, 26, 200, 200]              52\n",
      "             ReLU-87         [-1, 26, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             416\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 175,215\n",
      "Trainable params: 175,215\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 331.23\n",
      "Params size (MB): 0.67\n",
      "Estimated Total Size (MB): 332.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n",
      "=======================================================\n",
      "n_gen |  n_eval |  n_nds  |     eps      |  indicator  \n",
      "=======================================================\n",
      "    1 |      39 |      10 |            - |            -\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             245\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             294\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             441\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 3, 50, 50]               6\n",
      "            ReLU-107            [-1, 3, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             147\n",
      "      conv_layer-109            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 4, 50, 50]               8\n",
      "            ReLU-111            [-1, 4, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             196\n",
      "      conv_layer-113            [-1, 5, 50, 50]               0\n",
      "     Dense_block-114            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 5, 50, 50]              10\n",
      "            ReLU-116            [-1, 5, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]              10\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]             196\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 2, 100, 100]               4\n",
      "            ReLU-123          [-1, 2, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              98\n",
      "      conv_layer-125          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 3, 100, 100]               6\n",
      "            ReLU-127          [-1, 3, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             147\n",
      "      conv_layer-129          [-1, 4, 100, 100]               0\n",
      "     Dense_block-130          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 4, 100, 100]               8\n",
      "            ReLU-132          [-1, 4, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             196\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 6, 200, 200]              12\n",
      "            ReLU-139          [-1, 6, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             294\n",
      "      conv_layer-141          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 7, 200, 200]              14\n",
      "            ReLU-143          [-1, 7, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             343\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 6,664\n",
      "Trainable params: 6,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 56.21\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 56.84\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,000\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           3,500\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           3,000\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           5,500\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           6,400\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           4,000\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           6,500\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           8,100\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           4,500\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           7,000\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 38, 25, 25]              76\n",
      "             ReLU-59           [-1, 38, 25, 25]               0\n",
      "           Conv2d-60           [-1, 10, 25, 25]           9,500\n",
      "       conv_layer-61           [-1, 48, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 48, 25, 25]              96\n",
      "             ReLU-63           [-1, 48, 25, 25]               0\n",
      "           Conv2d-64           [-1, 10, 25, 25]          12,000\n",
      "       conv_layer-65           [-1, 58, 25, 25]               0\n",
      "      Dense_block-66           [-1, 58, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 58, 25, 25]             116\n",
      "             ReLU-68           [-1, 58, 25, 25]               0\n",
      "           Conv2d-69           [-1, 29, 25, 25]           1,682\n",
      "      BatchNorm2d-70           [-1, 29, 25, 25]              58\n",
      "             ReLU-71           [-1, 29, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 29, 50, 50]          21,025\n",
      "    Encode_Decode-73           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 45, 50, 50]              90\n",
      "             ReLU-75           [-1, 45, 50, 50]               0\n",
      "           Conv2d-76           [-1, 10, 50, 50]          11,250\n",
      "       conv_layer-77           [-1, 55, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 55, 50, 50]             110\n",
      "             ReLU-79           [-1, 55, 50, 50]               0\n",
      "           Conv2d-80           [-1, 10, 50, 50]          13,750\n",
      "       conv_layer-81           [-1, 65, 50, 50]               0\n",
      "      Dense_block-82           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 65, 50, 50]             130\n",
      "             ReLU-84           [-1, 65, 50, 50]               0\n",
      "           Conv2d-85           [-1, 32, 50, 50]           2,080\n",
      "      BatchNorm2d-86           [-1, 32, 50, 50]              64\n",
      "             ReLU-87           [-1, 32, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 32, 100, 100]          25,600\n",
      "    Encode_Decode-89         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 44, 100, 100]              88\n",
      "             ReLU-91         [-1, 44, 100, 100]               0\n",
      "           Conv2d-92         [-1, 10, 100, 100]          11,000\n",
      "       conv_layer-93         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 54, 100, 100]             108\n",
      "             ReLU-95         [-1, 54, 100, 100]               0\n",
      "           Conv2d-96         [-1, 10, 100, 100]          13,500\n",
      "       conv_layer-97         [-1, 64, 100, 100]               0\n",
      "      Dense_block-98         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 64, 100, 100]             128\n",
      "            ReLU-100         [-1, 64, 100, 100]               0\n",
      "          Conv2d-101         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-102         [-1, 32, 100, 100]              64\n",
      "            ReLU-103         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 32, 200, 200]          25,600\n",
      "   Encode_Decode-105         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 36, 200, 200]              72\n",
      "            ReLU-107         [-1, 36, 200, 200]               0\n",
      "          Conv2d-108         [-1, 10, 200, 200]           9,000\n",
      "      conv_layer-109         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 46, 200, 200]              92\n",
      "            ReLU-111         [-1, 46, 200, 200]               0\n",
      "          Conv2d-112         [-1, 10, 200, 200]          11,500\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 228,259\n",
      "Trainable params: 228,259\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 348.71\n",
      "Params size (MB): 0.87\n",
      "Estimated Total Size (MB): 350.19\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           2,352\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           9,408\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           9,604\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           8,232\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]          15,288\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]          17,689\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]          11,172\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]          18,228\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          21,609\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]          12,348\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]          19,404\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      Dense_block-58           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 45, 25, 25]              90\n",
      "             ReLU-60           [-1, 45, 25, 25]               0\n",
      "           Conv2d-61           [-1, 22, 25, 25]             990\n",
      "      BatchNorm2d-62           [-1, 22, 25, 25]              44\n",
      "             ReLU-63           [-1, 22, 25, 25]               0\n",
      "           Conv2d-64           [-1, 22, 13, 13]          23,716\n",
      "    Encode_Decode-65           [-1, 22, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 22, 13, 13]              44\n",
      "             ReLU-67           [-1, 22, 13, 13]               0\n",
      "           Conv2d-68           [-1, 12, 13, 13]          12,936\n",
      "       conv_layer-69           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 34, 13, 13]              68\n",
      "             ReLU-71           [-1, 34, 13, 13]               0\n",
      "           Conv2d-72           [-1, 12, 13, 13]          19,992\n",
      "       conv_layer-73           [-1, 46, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 46, 13, 13]              92\n",
      "             ReLU-75           [-1, 46, 13, 13]               0\n",
      "           Conv2d-76           [-1, 12, 13, 13]          27,048\n",
      "       conv_layer-77           [-1, 58, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 58, 13, 13]             116\n",
      "             ReLU-79           [-1, 58, 13, 13]               0\n",
      "           Conv2d-80           [-1, 12, 13, 13]          34,104\n",
      "       conv_layer-81           [-1, 70, 13, 13]               0\n",
      "      Dense_block-82           [-1, 70, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 70, 13, 13]             140\n",
      "             ReLU-84           [-1, 70, 13, 13]               0\n",
      "           Conv2d-85           [-1, 35, 13, 13]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 13, 13]              70\n",
      "             ReLU-87           [-1, 35, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 35, 25, 25]          60,025\n",
      "    Encode_Decode-89           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 35, 25, 25]              70\n",
      "             ReLU-91           [-1, 35, 25, 25]               0\n",
      "           Conv2d-92           [-1, 12, 25, 25]          20,580\n",
      "       conv_layer-93           [-1, 47, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 47, 25, 25]              94\n",
      "             ReLU-95           [-1, 47, 25, 25]               0\n",
      "           Conv2d-96           [-1, 12, 25, 25]          27,636\n",
      "       conv_layer-97           [-1, 59, 25, 25]               0\n",
      "      Dense_block-98           [-1, 59, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 59, 25, 25]             118\n",
      "            ReLU-100           [-1, 59, 25, 25]               0\n",
      "          Conv2d-101           [-1, 29, 25, 25]           1,711\n",
      "     BatchNorm2d-102           [-1, 29, 25, 25]              58\n",
      "            ReLU-103           [-1, 29, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 29, 50, 50]          41,209\n",
      "   Encode_Decode-105           [-1, 29, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 29, 50, 50]              58\n",
      "            ReLU-107           [-1, 29, 50, 50]               0\n",
      "          Conv2d-108           [-1, 12, 50, 50]          17,052\n",
      "      conv_layer-109           [-1, 41, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 41, 50, 50]              82\n",
      "            ReLU-111           [-1, 41, 50, 50]               0\n",
      "          Conv2d-112           [-1, 12, 50, 50]          24,108\n",
      "      conv_layer-113           [-1, 53, 50, 50]               0\n",
      "     Dense_block-114           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 53, 50, 50]             106\n",
      "            ReLU-116           [-1, 53, 50, 50]               0\n",
      "          Conv2d-117           [-1, 26, 50, 50]           1,378\n",
      "     BatchNorm2d-118           [-1, 26, 50, 50]              52\n",
      "            ReLU-119           [-1, 26, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 26, 100, 100]          33,124\n",
      "   Encode_Decode-121         [-1, 26, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 40, 100, 100]              80\n",
      "            ReLU-123         [-1, 40, 100, 100]               0\n",
      "          Conv2d-124         [-1, 12, 100, 100]          23,520\n",
      "      conv_layer-125         [-1, 52, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 52, 100, 100]             104\n",
      "            ReLU-127         [-1, 52, 100, 100]               0\n",
      "          Conv2d-128         [-1, 12, 100, 100]          30,576\n",
      "      conv_layer-129         [-1, 64, 100, 100]               0\n",
      "     Dense_block-130         [-1, 64, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 64, 100, 100]             128\n",
      "            ReLU-132         [-1, 64, 100, 100]               0\n",
      "          Conv2d-133         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-134         [-1, 32, 100, 100]              64\n",
      "            ReLU-135         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 32, 200, 200]          50,176\n",
      "   Encode_Decode-137         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 32, 200, 200]              64\n",
      "            ReLU-139         [-1, 32, 200, 200]               0\n",
      "          Conv2d-140         [-1, 12, 200, 200]          18,816\n",
      "      conv_layer-141         [-1, 44, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 44, 200, 200]              88\n",
      "            ReLU-143         [-1, 44, 200, 200]               0\n",
      "          Conv2d-144         [-1, 12, 200, 200]          25,872\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 651,230\n",
      "Trainable params: 651,230\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 359.47\n",
      "Params size (MB): 2.48\n",
      "Estimated Total Size (MB): 362.56\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 12\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 10, 50, 50]              20\n",
      "             ReLU-75           [-1, 10, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             500\n",
      "       conv_layer-77           [-1, 12, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 12, 50, 50]              24\n",
      "             ReLU-79           [-1, 12, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             600\n",
      "       conv_layer-81           [-1, 14, 50, 50]               0\n",
      "      Dense_block-82           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 14, 50, 50]              28\n",
      "             ReLU-84           [-1, 14, 50, 50]               0\n",
      "           Conv2d-85            [-1, 7, 50, 50]              98\n",
      "      BatchNorm2d-86            [-1, 7, 50, 50]              14\n",
      "             ReLU-87            [-1, 7, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-89          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 11, 100, 100]              22\n",
      "             ReLU-91         [-1, 11, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             550\n",
      "       conv_layer-93         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 13, 100, 100]              26\n",
      "             ReLU-95         [-1, 13, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             650\n",
      "       conv_layer-97         [-1, 15, 100, 100]               0\n",
      "      Dense_block-98         [-1, 15, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 15, 100, 100]              30\n",
      "            ReLU-100         [-1, 15, 100, 100]               0\n",
      "          Conv2d-101          [-1, 7, 100, 100]             105\n",
      "     BatchNorm2d-102          [-1, 7, 100, 100]              14\n",
      "            ReLU-103          [-1, 7, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 7, 200, 200]           1,225\n",
      "   Encode_Decode-105          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 7, 200, 200]              14\n",
      "            ReLU-107          [-1, 7, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             350\n",
      "      conv_layer-109          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 9, 200, 200]              18\n",
      "            ReLU-111          [-1, 9, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             450\n",
      "      conv_layer-113         [-1, 11, 200, 200]               0\n",
      "     Dense_block-114         [-1, 11, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 11, 200, 200]              22\n",
      "            ReLU-116         [-1, 11, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              55\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 11,666\n",
      "Trainable params: 11,666\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 85.90\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 86.55\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             600\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           1,500\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           1,600\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           1,200\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           2,100\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           2,500\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           1,500\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           2,400\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           3,025\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           1,650\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           2,550\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           3,450\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           4,350\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]           2,550\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           3,450\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           3,300\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           4,200\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           7,225\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           2,550\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           3,450\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 71,294\n",
      "Trainable params: 71,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 193.80\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 194.68\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           2,156\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           8,085\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           8,281\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           7,007\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          12,936\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           9,163\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          15,092\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          17,689\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          10,241\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          16,170\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          19,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]          10,780\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]          16,709\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          22,638\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          28,567\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          50,176\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]          17,248\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          23,177\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          35,721\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          23,716\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          29,645\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          53,361\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          24,794\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          30,723\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          56,644\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          18,326\n",
      "      conv_layer-141         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 45, 200, 200]              90\n",
      "            ReLU-143         [-1, 45, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          24,255\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 622,359\n",
      "Trainable params: 622,359\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 361.02\n",
      "Params size (MB): 2.37\n",
      "Estimated Total Size (MB): 364.00\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]          14,994\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]          18,963\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]          33,124\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 26, 50, 50]              52\n",
      "             ReLU-75           [-1, 26, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]          11,466\n",
      "       conv_layer-77           [-1, 35, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 35, 50, 50]              70\n",
      "             ReLU-79           [-1, 35, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]          15,435\n",
      "       conv_layer-81           [-1, 44, 50, 50]               0\n",
      "      Dense_block-82           [-1, 44, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 44, 50, 50]              88\n",
      "             ReLU-84           [-1, 44, 50, 50]               0\n",
      "           Conv2d-85           [-1, 22, 50, 50]             968\n",
      "      BatchNorm2d-86           [-1, 22, 50, 50]              44\n",
      "             ReLU-87           [-1, 22, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 22, 100, 100]          23,716\n",
      "    Encode_Decode-89         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 33, 100, 100]              66\n",
      "             ReLU-91         [-1, 33, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]          14,553\n",
      "       conv_layer-93         [-1, 42, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 42, 100, 100]              84\n",
      "             ReLU-95         [-1, 42, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]          18,522\n",
      "       conv_layer-97         [-1, 51, 100, 100]               0\n",
      "      Dense_block-98         [-1, 51, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 51, 100, 100]             102\n",
      "            ReLU-100         [-1, 51, 100, 100]               0\n",
      "          Conv2d-101         [-1, 25, 100, 100]           1,275\n",
      "     BatchNorm2d-102         [-1, 25, 100, 100]              50\n",
      "            ReLU-103         [-1, 25, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 25, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 29, 200, 200]              58\n",
      "            ReLU-107         [-1, 29, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]          12,789\n",
      "      conv_layer-109         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 38, 200, 200]              76\n",
      "            ReLU-111         [-1, 38, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]          16,758\n",
      "      conv_layer-113         [-1, 47, 200, 200]               0\n",
      "     Dense_block-114         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 47, 200, 200]              94\n",
      "            ReLU-116         [-1, 47, 200, 200]               0\n",
      "          Conv2d-117         [-1, 23, 200, 200]           1,081\n",
      "     BatchNorm2d-118         [-1, 23, 200, 200]              46\n",
      "            ReLU-119         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             368\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 302,576\n",
      "Trainable params: 302,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 292.45\n",
      "Params size (MB): 1.15\n",
      "Estimated Total Size (MB): 294.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]             432\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           1,728\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           1,512\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           2,808\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           3,249\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           2,052\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           3,348\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]           3,969\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           2,268\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           3,564\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      Dense_block-58           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 45, 25, 25]              90\n",
      "             ReLU-60           [-1, 45, 25, 25]               0\n",
      "           Conv2d-61           [-1, 22, 25, 25]             990\n",
      "      BatchNorm2d-62           [-1, 22, 25, 25]              44\n",
      "             ReLU-63           [-1, 22, 25, 25]               0\n",
      "           Conv2d-64           [-1, 22, 13, 13]           4,356\n",
      "    Encode_Decode-65           [-1, 22, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 22, 13, 13]              44\n",
      "             ReLU-67           [-1, 22, 13, 13]               0\n",
      "           Conv2d-68           [-1, 12, 13, 13]           2,376\n",
      "       conv_layer-69           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 34, 13, 13]              68\n",
      "             ReLU-71           [-1, 34, 13, 13]               0\n",
      "           Conv2d-72           [-1, 12, 13, 13]           3,672\n",
      "       conv_layer-73           [-1, 46, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 46, 13, 13]              92\n",
      "             ReLU-75           [-1, 46, 13, 13]               0\n",
      "           Conv2d-76           [-1, 12, 13, 13]           4,968\n",
      "       conv_layer-77           [-1, 58, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 58, 13, 13]             116\n",
      "             ReLU-79           [-1, 58, 13, 13]               0\n",
      "           Conv2d-80           [-1, 12, 13, 13]           6,264\n",
      "       conv_layer-81           [-1, 70, 13, 13]               0\n",
      "      Dense_block-82           [-1, 70, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 70, 13, 13]             140\n",
      "             ReLU-84           [-1, 70, 13, 13]               0\n",
      "           Conv2d-85           [-1, 35, 13, 13]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 13, 13]              70\n",
      "             ReLU-87           [-1, 35, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 35, 25, 25]          11,025\n",
      "    Encode_Decode-89           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 56, 25, 25]             112\n",
      "             ReLU-91           [-1, 56, 25, 25]               0\n",
      "           Conv2d-92           [-1, 12, 25, 25]           6,048\n",
      "       conv_layer-93           [-1, 68, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 68, 25, 25]             136\n",
      "             ReLU-95           [-1, 68, 25, 25]               0\n",
      "           Conv2d-96           [-1, 12, 25, 25]           7,344\n",
      "       conv_layer-97           [-1, 80, 25, 25]               0\n",
      "      Dense_block-98           [-1, 80, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 80, 25, 25]             160\n",
      "            ReLU-100           [-1, 80, 25, 25]               0\n",
      "          Conv2d-101           [-1, 40, 25, 25]           3,200\n",
      "     BatchNorm2d-102           [-1, 40, 25, 25]              80\n",
      "            ReLU-103           [-1, 40, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 40, 50, 50]          14,400\n",
      "   Encode_Decode-105           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 40, 50, 50]              80\n",
      "            ReLU-107           [-1, 40, 50, 50]               0\n",
      "          Conv2d-108           [-1, 12, 50, 50]           4,320\n",
      "      conv_layer-109           [-1, 52, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 52, 50, 50]             104\n",
      "            ReLU-111           [-1, 52, 50, 50]               0\n",
      "          Conv2d-112           [-1, 12, 50, 50]           5,616\n",
      "      conv_layer-113           [-1, 64, 50, 50]               0\n",
      "     Dense_block-114           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 64, 50, 50]             128\n",
      "            ReLU-116           [-1, 64, 50, 50]               0\n",
      "          Conv2d-117           [-1, 32, 50, 50]           2,048\n",
      "     BatchNorm2d-118           [-1, 32, 50, 50]              64\n",
      "            ReLU-119           [-1, 32, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 32, 100, 100]           9,216\n",
      "   Encode_Decode-121         [-1, 32, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 12, 100, 100]           4,968\n",
      "      conv_layer-125         [-1, 58, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 58, 100, 100]             116\n",
      "            ReLU-127         [-1, 58, 100, 100]               0\n",
      "          Conv2d-128         [-1, 12, 100, 100]           6,264\n",
      "      conv_layer-129         [-1, 70, 100, 100]               0\n",
      "     Dense_block-130         [-1, 70, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 70, 100, 100]             140\n",
      "            ReLU-132         [-1, 70, 100, 100]               0\n",
      "          Conv2d-133         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-134         [-1, 35, 100, 100]              70\n",
      "            ReLU-135         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 35, 200, 200]          11,025\n",
      "   Encode_Decode-137         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 35, 200, 200]              70\n",
      "            ReLU-139         [-1, 35, 200, 200]               0\n",
      "          Conv2d-140         [-1, 12, 200, 200]           3,780\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 12, 200, 200]           5,076\n",
      "      conv_layer-145         [-1, 59, 200, 200]               0\n",
      "     Dense_block-146         [-1, 59, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 59, 200, 200]             118\n",
      "            ReLU-148         [-1, 59, 200, 200]               0\n",
      "          Conv2d-149         [-1, 29, 200, 200]           1,711\n",
      "     BatchNorm2d-150         [-1, 29, 200, 200]              58\n",
      "            ReLU-151         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             464\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 155,826\n",
      "Trainable params: 155,826\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 379.89\n",
      "Params size (MB): 0.59\n",
      "Estimated Total Size (MB): 381.09\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]             400\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]             200\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             300\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]             400\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]             500\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]             900\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 6, 25, 25]              12\n",
      "             ReLU-91            [-1, 6, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]             300\n",
      "       conv_layer-93            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 8, 25, 25]              16\n",
      "             ReLU-95            [-1, 8, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]             400\n",
      "       conv_layer-97           [-1, 10, 25, 25]               0\n",
      "      Dense_block-98           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 10, 25, 25]              20\n",
      "            ReLU-100           [-1, 10, 25, 25]               0\n",
      "          Conv2d-101            [-1, 5, 25, 25]              50\n",
      "     BatchNorm2d-102            [-1, 5, 25, 25]              10\n",
      "            ReLU-103            [-1, 5, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 5, 50, 50]             625\n",
      "   Encode_Decode-105            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]             250\n",
      "      conv_layer-109            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 7, 50, 50]              14\n",
      "            ReLU-111            [-1, 7, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]             350\n",
      "      conv_layer-113            [-1, 9, 50, 50]               0\n",
      "     Dense_block-114            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 9, 50, 50]              18\n",
      "            ReLU-116            [-1, 9, 50, 50]               0\n",
      "          Conv2d-117            [-1, 4, 50, 50]              36\n",
      "     BatchNorm2d-118            [-1, 4, 50, 50]               8\n",
      "            ReLU-119            [-1, 4, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 4, 100, 100]             400\n",
      "   Encode_Decode-121          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 4, 100, 100]               8\n",
      "            ReLU-123          [-1, 4, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]             200\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]             300\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]             200\n",
      "      conv_layer-141          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 6, 200, 200]              12\n",
      "            ReLU-143          [-1, 6, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]             300\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 10,647\n",
      "Trainable params: 10,647\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 68.23\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 68.88\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 15, 50, 50]              30\n",
      "             ReLU-43           [-1, 15, 50, 50]               0\n",
      "           Conv2d-44            [-1, 4, 50, 50]           4,860\n",
      "       conv_layer-45           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 50, 50]           6,156\n",
      "       conv_layer-49           [-1, 23, 50, 50]               0\n",
      "      Dense_block-50           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 23, 50, 50]              46\n",
      "             ReLU-52           [-1, 23, 50, 50]               0\n",
      "           Conv2d-53           [-1, 11, 50, 50]             253\n",
      "      BatchNorm2d-54           [-1, 11, 50, 50]              22\n",
      "             ReLU-55           [-1, 11, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-57         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 17, 100, 100]              34\n",
      "             ReLU-59         [-1, 17, 100, 100]               0\n",
      "           Conv2d-60          [-1, 4, 100, 100]           5,508\n",
      "       conv_layer-61         [-1, 21, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 21, 100, 100]              42\n",
      "             ReLU-63         [-1, 21, 100, 100]               0\n",
      "           Conv2d-64          [-1, 4, 100, 100]           6,804\n",
      "       conv_layer-65         [-1, 25, 100, 100]               0\n",
      "      Dense_block-66         [-1, 25, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 25, 100, 100]              50\n",
      "             ReLU-68         [-1, 25, 100, 100]               0\n",
      "           Conv2d-69         [-1, 12, 100, 100]             300\n",
      "      BatchNorm2d-70         [-1, 12, 100, 100]              24\n",
      "             ReLU-71         [-1, 12, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 12, 200, 200]          11,664\n",
      "    Encode_Decode-73         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 16, 200, 200]              32\n",
      "             ReLU-75         [-1, 16, 200, 200]               0\n",
      "           Conv2d-76          [-1, 4, 200, 200]           5,184\n",
      "       conv_layer-77         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 20, 200, 200]              40\n",
      "             ReLU-79         [-1, 20, 200, 200]               0\n",
      "           Conv2d-80          [-1, 4, 200, 200]           6,480\n",
      "       conv_layer-81         [-1, 24, 200, 200]               0\n",
      "      Dense_block-82         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 24, 200, 200]              48\n",
      "             ReLU-84         [-1, 24, 200, 200]               0\n",
      "           Conv2d-85         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-86         [-1, 12, 200, 200]              24\n",
      "             ReLU-87         [-1, 12, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             192\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 80,193\n",
      "Trainable params: 80,193\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 150.60\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 151.52\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             980\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           2,205\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           2,401\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]           1,715\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           2,940\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           3,136\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,960\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           3,185\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           3,969\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           2,205\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           3,430\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]           4,655\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           5,880\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 14, 50, 50]              28\n",
      "             ReLU-75           [-1, 14, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]           3,430\n",
      "       conv_layer-77           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 19, 50, 50]              38\n",
      "             ReLU-79           [-1, 19, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]           4,655\n",
      "       conv_layer-81           [-1, 24, 50, 50]               0\n",
      "      Dense_block-82           [-1, 24, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 24, 50, 50]              48\n",
      "             ReLU-84           [-1, 24, 50, 50]               0\n",
      "           Conv2d-85           [-1, 12, 50, 50]             288\n",
      "      BatchNorm2d-86           [-1, 12, 50, 50]              24\n",
      "             ReLU-87           [-1, 12, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-89         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 12, 100, 100]              24\n",
      "             ReLU-91         [-1, 12, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]           2,940\n",
      "       conv_layer-93         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 17, 100, 100]              34\n",
      "             ReLU-95         [-1, 17, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           4,165\n",
      "       conv_layer-97         [-1, 22, 100, 100]               0\n",
      "      Dense_block-98         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 22, 100, 100]              44\n",
      "            ReLU-100         [-1, 22, 100, 100]               0\n",
      "          Conv2d-101         [-1, 11, 100, 100]             242\n",
      "     BatchNorm2d-102         [-1, 11, 100, 100]              22\n",
      "            ReLU-103         [-1, 11, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 11, 200, 200]           5,929\n",
      "   Encode_Decode-105         [-1, 11, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 11, 200, 200]              22\n",
      "            ReLU-107         [-1, 11, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]           2,695\n",
      "      conv_layer-109         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 16, 200, 200]              32\n",
      "            ReLU-111         [-1, 16, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]           3,920\n",
      "      conv_layer-113         [-1, 21, 200, 200]               0\n",
      "     Dense_block-114         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 21, 200, 200]              42\n",
      "            ReLU-116         [-1, 21, 200, 200]               0\n",
      "          Conv2d-117         [-1, 10, 200, 200]             210\n",
      "     BatchNorm2d-118         [-1, 10, 200, 200]              20\n",
      "            ReLU-119         [-1, 10, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             160\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 85,749\n",
      "Trainable params: 85,749\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 147.16\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 148.09\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 20, 25, 25]              40\n",
      "             ReLU-91           [-1, 20, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]           6,860\n",
      "       conv_layer-93           [-1, 27, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 27, 25, 25]              54\n",
      "             ReLU-95           [-1, 27, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]           9,261\n",
      "       conv_layer-97           [-1, 34, 25, 25]               0\n",
      "      Dense_block-98           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 34, 25, 25]              68\n",
      "            ReLU-100           [-1, 34, 25, 25]               0\n",
      "          Conv2d-101           [-1, 17, 25, 25]             578\n",
      "     BatchNorm2d-102           [-1, 17, 25, 25]              34\n",
      "            ReLU-103           [-1, 17, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 17, 50, 50]          14,161\n",
      "   Encode_Decode-105           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 28, 50, 50]              56\n",
      "            ReLU-107           [-1, 28, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]           9,604\n",
      "      conv_layer-109           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 35, 50, 50]              70\n",
      "            ReLU-111           [-1, 35, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          12,005\n",
      "      conv_layer-113           [-1, 42, 50, 50]               0\n",
      "     Dense_block-114           [-1, 42, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 42, 50, 50]              84\n",
      "            ReLU-116           [-1, 42, 50, 50]               0\n",
      "          Conv2d-117           [-1, 21, 50, 50]             882\n",
      "     BatchNorm2d-118           [-1, 21, 50, 50]              42\n",
      "            ReLU-119           [-1, 21, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 21, 100, 100]          21,609\n",
      "   Encode_Decode-121         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 30, 100, 100]              60\n",
      "            ReLU-123         [-1, 30, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]          10,290\n",
      "      conv_layer-125         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 37, 100, 100]              74\n",
      "            ReLU-127         [-1, 37, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]          12,691\n",
      "      conv_layer-129         [-1, 44, 100, 100]               0\n",
      "     Dense_block-130         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 44, 100, 100]              88\n",
      "            ReLU-132         [-1, 44, 100, 100]               0\n",
      "          Conv2d-133         [-1, 22, 100, 100]             968\n",
      "     BatchNorm2d-134         [-1, 22, 100, 100]              44\n",
      "            ReLU-135         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 22, 200, 200]          23,716\n",
      "   Encode_Decode-137         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 26, 200, 200]              52\n",
      "            ReLU-139         [-1, 26, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           8,918\n",
      "      conv_layer-141         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 33, 200, 200]              66\n",
      "            ReLU-143         [-1, 33, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]          11,319\n",
      "      conv_layer-145         [-1, 40, 200, 200]               0\n",
      "     Dense_block-146         [-1, 40, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 40, 200, 200]              80\n",
      "            ReLU-148         [-1, 40, 200, 200]               0\n",
      "          Conv2d-149         [-1, 20, 200, 200]             800\n",
      "     BatchNorm2d-150         [-1, 20, 200, 200]              40\n",
      "            ReLU-151         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             320\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 259,112\n",
      "Trainable params: 259,112\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 251.18\n",
      "Params size (MB): 0.99\n",
      "Estimated Total Size (MB): 252.78\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 20, 25, 25]              40\n",
      "             ReLU-91           [-1, 20, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]           6,860\n",
      "       conv_layer-93           [-1, 27, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 27, 25, 25]              54\n",
      "             ReLU-95           [-1, 27, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]           9,261\n",
      "       conv_layer-97           [-1, 34, 25, 25]               0\n",
      "      Dense_block-98           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 34, 25, 25]              68\n",
      "            ReLU-100           [-1, 34, 25, 25]               0\n",
      "          Conv2d-101           [-1, 17, 25, 25]             578\n",
      "     BatchNorm2d-102           [-1, 17, 25, 25]              34\n",
      "            ReLU-103           [-1, 17, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 17, 50, 50]          14,161\n",
      "   Encode_Decode-105           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 28, 50, 50]              56\n",
      "            ReLU-107           [-1, 28, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]           9,604\n",
      "      conv_layer-109           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 35, 50, 50]              70\n",
      "            ReLU-111           [-1, 35, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          12,005\n",
      "      conv_layer-113           [-1, 42, 50, 50]               0\n",
      "     Dense_block-114           [-1, 42, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 42, 50, 50]              84\n",
      "            ReLU-116           [-1, 42, 50, 50]               0\n",
      "          Conv2d-117           [-1, 21, 50, 50]             882\n",
      "     BatchNorm2d-118           [-1, 21, 50, 50]              42\n",
      "            ReLU-119           [-1, 21, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 21, 100, 100]          21,609\n",
      "   Encode_Decode-121         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 21, 100, 100]              42\n",
      "            ReLU-123         [-1, 21, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]           7,203\n",
      "      conv_layer-125         [-1, 28, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 28, 100, 100]              56\n",
      "            ReLU-127         [-1, 28, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]           9,604\n",
      "      conv_layer-129         [-1, 35, 100, 100]               0\n",
      "     Dense_block-130         [-1, 35, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 35, 100, 100]              70\n",
      "            ReLU-132         [-1, 35, 100, 100]               0\n",
      "          Conv2d-133         [-1, 17, 100, 100]             595\n",
      "     BatchNorm2d-134         [-1, 17, 100, 100]              34\n",
      "            ReLU-135         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 17, 200, 200]          14,161\n",
      "   Encode_Decode-137         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 17, 200, 200]              34\n",
      "            ReLU-139         [-1, 17, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           5,831\n",
      "      conv_layer-141         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 24, 200, 200]              48\n",
      "            ReLU-143         [-1, 24, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]           8,232\n",
      "      conv_layer-145         [-1, 31, 200, 200]               0\n",
      "     Dense_block-146         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 31, 200, 200]              62\n",
      "            ReLU-148         [-1, 31, 200, 200]               0\n",
      "          Conv2d-149         [-1, 15, 200, 200]             465\n",
      "     BatchNorm2d-150         [-1, 15, 200, 200]              30\n",
      "            ReLU-151         [-1, 15, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             240\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 236,293\n",
      "Trainable params: 236,293\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 211.51\n",
      "Params size (MB): 0.90\n",
      "Estimated Total Size (MB): 213.02\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             800\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           2,400\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           2,500\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           2,000\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           3,600\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           4,225\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           2,600\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           4,200\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 29, 50, 50]              58\n",
      "             ReLU-43           [-1, 29, 50, 50]               0\n",
      "           Conv2d-44            [-1, 8, 50, 50]           5,800\n",
      "       conv_layer-45           [-1, 37, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 37, 50, 50]              74\n",
      "             ReLU-47           [-1, 37, 50, 50]               0\n",
      "           Conv2d-48            [-1, 8, 50, 50]           7,400\n",
      "       conv_layer-49           [-1, 45, 50, 50]               0\n",
      "      Dense_block-50           [-1, 45, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 45, 50, 50]              90\n",
      "             ReLU-52           [-1, 45, 50, 50]               0\n",
      "           Conv2d-53           [-1, 22, 50, 50]             990\n",
      "      BatchNorm2d-54           [-1, 22, 50, 50]              44\n",
      "             ReLU-55           [-1, 22, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 22, 100, 100]          12,100\n",
      "    Encode_Decode-57         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 22, 100, 100]              44\n",
      "             ReLU-59         [-1, 22, 100, 100]               0\n",
      "           Conv2d-60          [-1, 8, 100, 100]           4,400\n",
      "       conv_layer-61         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 30, 100, 100]              60\n",
      "             ReLU-63         [-1, 30, 100, 100]               0\n",
      "           Conv2d-64          [-1, 8, 100, 100]           6,000\n",
      "       conv_layer-65         [-1, 38, 100, 100]               0\n",
      "      Dense_block-66         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 38, 100, 100]              76\n",
      "             ReLU-68         [-1, 38, 100, 100]               0\n",
      "           Conv2d-69         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-70         [-1, 19, 100, 100]              38\n",
      "             ReLU-71         [-1, 19, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 19, 200, 200]           9,025\n",
      "    Encode_Decode-73         [-1, 19, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 23, 200, 200]              46\n",
      "             ReLU-75         [-1, 23, 200, 200]               0\n",
      "           Conv2d-76          [-1, 8, 200, 200]           4,600\n",
      "       conv_layer-77         [-1, 31, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 31, 200, 200]              62\n",
      "             ReLU-79         [-1, 31, 200, 200]               0\n",
      "           Conv2d-80          [-1, 8, 200, 200]           6,200\n",
      "       conv_layer-81         [-1, 39, 200, 200]               0\n",
      "      Dense_block-82         [-1, 39, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 39, 200, 200]              78\n",
      "             ReLU-84         [-1, 39, 200, 200]               0\n",
      "           Conv2d-85         [-1, 19, 200, 200]             741\n",
      "      BatchNorm2d-86         [-1, 19, 200, 200]              38\n",
      "             ReLU-87         [-1, 19, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             304\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 82,291\n",
      "Trainable params: 82,291\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 240.76\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 241.69\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             196\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             245\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             441\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             245\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             294\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             294\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             343\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             784\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 8, 200, 200]              16\n",
      "            ReLU-107          [-1, 8, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             392\n",
      "      conv_layer-109          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 9, 200, 200]              18\n",
      "            ReLU-111          [-1, 9, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             441\n",
      "      conv_layer-113         [-1, 10, 200, 200]               0\n",
      "     Dense_block-114         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 10, 200, 200]              20\n",
      "            ReLU-116         [-1, 10, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 6,892\n",
      "Trainable params: 6,892\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.33\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 67.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 38, 100, 100]              76\n",
      "             ReLU-91         [-1, 38, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          11,400\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          15,000\n",
      "       conv_layer-97         [-1, 62, 100, 100]               0\n",
      "      Dense_block-98         [-1, 62, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 62, 100, 100]             124\n",
      "            ReLU-100         [-1, 62, 100, 100]               0\n",
      "          Conv2d-101         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-102         [-1, 31, 100, 100]              62\n",
      "            ReLU-103         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 31, 200, 200]          24,025\n",
      "   Encode_Decode-105         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 31, 200, 200]              62\n",
      "            ReLU-107         [-1, 31, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]           9,300\n",
      "      conv_layer-109         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 43, 200, 200]              86\n",
      "            ReLU-111         [-1, 43, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          12,900\n",
      "      conv_layer-113         [-1, 55, 200, 200]               0\n",
      "     Dense_block-114         [-1, 55, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 55, 200, 200]             110\n",
      "            ReLU-116         [-1, 55, 200, 200]               0\n",
      "          Conv2d-117         [-1, 27, 200, 200]           1,485\n",
      "     BatchNorm2d-118         [-1, 27, 200, 200]              54\n",
      "            ReLU-119         [-1, 27, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             432\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 291,251\n",
      "Trainable params: 291,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 358.42\n",
      "Params size (MB): 1.11\n",
      "Estimated Total Size (MB): 360.15\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             180\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]             405\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             315\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]             540\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]             576\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]             360\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]             585\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 18, 50, 50]              36\n",
      "             ReLU-43           [-1, 18, 50, 50]               0\n",
      "           Conv2d-44            [-1, 5, 50, 50]             810\n",
      "       conv_layer-45           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 23, 50, 50]              46\n",
      "             ReLU-47           [-1, 23, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 50, 50]           1,035\n",
      "       conv_layer-49           [-1, 28, 50, 50]               0\n",
      "      Dense_block-50           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 28, 50, 50]              56\n",
      "             ReLU-52           [-1, 28, 50, 50]               0\n",
      "           Conv2d-53           [-1, 14, 50, 50]             392\n",
      "      BatchNorm2d-54           [-1, 14, 50, 50]              28\n",
      "             ReLU-55           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-57         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 14, 100, 100]              28\n",
      "             ReLU-59         [-1, 14, 100, 100]               0\n",
      "           Conv2d-60          [-1, 5, 100, 100]             630\n",
      "       conv_layer-61         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 19, 100, 100]              38\n",
      "             ReLU-63         [-1, 19, 100, 100]               0\n",
      "           Conv2d-64          [-1, 5, 100, 100]             855\n",
      "       conv_layer-65         [-1, 24, 100, 100]               0\n",
      "      Dense_block-66         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 24, 100, 100]              48\n",
      "             ReLU-68         [-1, 24, 100, 100]               0\n",
      "           Conv2d-69         [-1, 12, 100, 100]             288\n",
      "      BatchNorm2d-70         [-1, 12, 100, 100]              24\n",
      "             ReLU-71         [-1, 12, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 12, 200, 200]           1,296\n",
      "    Encode_Decode-73         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 12, 200, 200]              24\n",
      "             ReLU-75         [-1, 12, 200, 200]               0\n",
      "           Conv2d-76          [-1, 5, 200, 200]             540\n",
      "       conv_layer-77         [-1, 17, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 17, 200, 200]              34\n",
      "             ReLU-79         [-1, 17, 200, 200]               0\n",
      "           Conv2d-80          [-1, 5, 200, 200]             765\n",
      "       conv_layer-81         [-1, 22, 200, 200]               0\n",
      "      Dense_block-82         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 22, 200, 200]              44\n",
      "             ReLU-84         [-1, 22, 200, 200]               0\n",
      "           Conv2d-85         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-86         [-1, 11, 200, 200]              22\n",
      "             ReLU-87         [-1, 11, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             176\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 13,199\n",
      "Trainable params: 13,199\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 150.22\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 150.88\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 3, 200, 200]               6\n",
      "            ReLU-107          [-1, 3, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              75\n",
      "      conv_layer-109          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 4, 200, 200]               8\n",
      "            ReLU-111          [-1, 4, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             100\n",
      "      conv_layer-113          [-1, 5, 200, 200]               0\n",
      "     Dense_block-114          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 5, 200, 200]              10\n",
      "            ReLU-116          [-1, 5, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]              10\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,976\n",
      "Trainable params: 2,976\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 48.78\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 49.40\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          13,200\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          16,225\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          30,625\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          13,200\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          16,225\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 39, 200, 200]              78\n",
      "            ReLU-107         [-1, 39, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]          10,725\n",
      "      conv_layer-109         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 50, 200, 200]             100\n",
      "            ReLU-111         [-1, 50, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          13,750\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 269,061\n",
      "Trainable params: 269,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 378.22\n",
      "Params size (MB): 1.03\n",
      "Estimated Total Size (MB): 379.85\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             150\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             175\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 8, 200, 200]              16\n",
      "            ReLU-107          [-1, 8, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             200\n",
      "      conv_layer-109          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 9, 200, 200]              18\n",
      "            ReLU-111          [-1, 9, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             225\n",
      "      conv_layer-113         [-1, 10, 200, 200]               0\n",
      "     Dense_block-114         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 10, 200, 200]              20\n",
      "            ReLU-116         [-1, 10, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,844\n",
      "Trainable params: 3,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.33\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 67.96\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |      59 |      12 |  0.017007098 |        ideal\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]             400\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]             800\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]             900\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]             600\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           1,000\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           1,225\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]             700\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           1,100\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      Dense_block-42           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 15, 50, 50]              30\n",
      "             ReLU-44           [-1, 15, 50, 50]               0\n",
      "           Conv2d-45            [-1, 7, 50, 50]             105\n",
      "      BatchNorm2d-46            [-1, 7, 50, 50]              14\n",
      "             ReLU-47            [-1, 7, 50, 50]               0\n",
      "           Conv2d-48            [-1, 7, 25, 25]           1,225\n",
      "    Encode_Decode-49            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 7, 25, 25]              14\n",
      "             ReLU-51            [-1, 7, 25, 25]               0\n",
      "           Conv2d-52            [-1, 4, 25, 25]             700\n",
      "       conv_layer-53           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 11, 25, 25]              22\n",
      "             ReLU-55           [-1, 11, 25, 25]               0\n",
      "           Conv2d-56            [-1, 4, 25, 25]           1,100\n",
      "       conv_layer-57           [-1, 15, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 15, 25, 25]              30\n",
      "             ReLU-59           [-1, 15, 25, 25]               0\n",
      "           Conv2d-60            [-1, 4, 25, 25]           1,500\n",
      "       conv_layer-61           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 25, 25]           1,900\n",
      "       conv_layer-65           [-1, 23, 25, 25]               0\n",
      "      Dense_block-66           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 23, 25, 25]              46\n",
      "             ReLU-68           [-1, 23, 25, 25]               0\n",
      "           Conv2d-69           [-1, 11, 25, 25]             253\n",
      "      BatchNorm2d-70           [-1, 11, 25, 25]              22\n",
      "             ReLU-71           [-1, 11, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 11, 50, 50]           3,025\n",
      "    Encode_Decode-73           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 18, 50, 50]              36\n",
      "             ReLU-75           [-1, 18, 50, 50]               0\n",
      "           Conv2d-76            [-1, 4, 50, 50]           1,800\n",
      "       conv_layer-77           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 22, 50, 50]              44\n",
      "             ReLU-79           [-1, 22, 50, 50]               0\n",
      "           Conv2d-80            [-1, 4, 50, 50]           2,200\n",
      "       conv_layer-81           [-1, 26, 50, 50]               0\n",
      "      Dense_block-82           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 26, 50, 50]              52\n",
      "             ReLU-84           [-1, 26, 50, 50]               0\n",
      "           Conv2d-85           [-1, 13, 50, 50]             338\n",
      "      BatchNorm2d-86           [-1, 13, 50, 50]              26\n",
      "             ReLU-87           [-1, 13, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-89         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 19, 100, 100]              38\n",
      "             ReLU-91         [-1, 19, 100, 100]               0\n",
      "           Conv2d-92          [-1, 4, 100, 100]           1,900\n",
      "       conv_layer-93         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 23, 100, 100]              46\n",
      "             ReLU-95         [-1, 23, 100, 100]               0\n",
      "           Conv2d-96          [-1, 4, 100, 100]           2,300\n",
      "       conv_layer-97         [-1, 27, 100, 100]               0\n",
      "      Dense_block-98         [-1, 27, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 27, 100, 100]              54\n",
      "            ReLU-100         [-1, 27, 100, 100]               0\n",
      "          Conv2d-101         [-1, 13, 100, 100]             351\n",
      "     BatchNorm2d-102         [-1, 13, 100, 100]              26\n",
      "            ReLU-103         [-1, 13, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 13, 200, 200]           4,225\n",
      "   Encode_Decode-105         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 4, 200, 200]           1,700\n",
      "      conv_layer-109         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 21, 200, 200]              42\n",
      "            ReLU-111         [-1, 21, 200, 200]               0\n",
      "          Conv2d-112          [-1, 4, 200, 200]           2,100\n",
      "      conv_layer-113         [-1, 25, 200, 200]               0\n",
      "     Dense_block-114         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 25, 200, 200]              50\n",
      "            ReLU-116         [-1, 25, 200, 200]               0\n",
      "          Conv2d-117         [-1, 12, 200, 200]             300\n",
      "     BatchNorm2d-118         [-1, 12, 200, 200]              24\n",
      "            ReLU-119         [-1, 12, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             192\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 39,336\n",
      "Trainable params: 39,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 159.63\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 160.39\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 36, 50, 50]              72\n",
      "             ReLU-43           [-1, 36, 50, 50]               0\n",
      "           Conv2d-44           [-1, 10, 50, 50]          17,640\n",
      "       conv_layer-45           [-1, 46, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 46, 50, 50]              92\n",
      "             ReLU-47           [-1, 46, 50, 50]               0\n",
      "           Conv2d-48           [-1, 10, 50, 50]          22,540\n",
      "       conv_layer-49           [-1, 56, 50, 50]               0\n",
      "      Dense_block-50           [-1, 56, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 56, 50, 50]             112\n",
      "             ReLU-52           [-1, 56, 50, 50]               0\n",
      "           Conv2d-53           [-1, 28, 50, 50]           1,568\n",
      "      BatchNorm2d-54           [-1, 28, 50, 50]              56\n",
      "             ReLU-55           [-1, 28, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 28, 100, 100]          38,416\n",
      "    Encode_Decode-57         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 28, 100, 100]              56\n",
      "             ReLU-59         [-1, 28, 100, 100]               0\n",
      "           Conv2d-60         [-1, 10, 100, 100]          13,720\n",
      "       conv_layer-61         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 38, 100, 100]              76\n",
      "             ReLU-63         [-1, 38, 100, 100]               0\n",
      "           Conv2d-64         [-1, 10, 100, 100]          18,620\n",
      "       conv_layer-65         [-1, 48, 100, 100]               0\n",
      "      Dense_block-66         [-1, 48, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 48, 100, 100]              96\n",
      "             ReLU-68         [-1, 48, 100, 100]               0\n",
      "           Conv2d-69         [-1, 24, 100, 100]           1,152\n",
      "      BatchNorm2d-70         [-1, 24, 100, 100]              48\n",
      "             ReLU-71         [-1, 24, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 24, 200, 200]          28,224\n",
      "    Encode_Decode-73         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 28, 200, 200]              56\n",
      "             ReLU-75         [-1, 28, 200, 200]               0\n",
      "           Conv2d-76         [-1, 10, 200, 200]          13,720\n",
      "       conv_layer-77         [-1, 38, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 38, 200, 200]              76\n",
      "             ReLU-79         [-1, 38, 200, 200]               0\n",
      "           Conv2d-80         [-1, 10, 200, 200]          18,620\n",
      "       conv_layer-81         [-1, 48, 200, 200]               0\n",
      "      Dense_block-82         [-1, 48, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 48, 200, 200]              96\n",
      "             ReLU-84         [-1, 48, 200, 200]               0\n",
      "           Conv2d-85         [-1, 24, 200, 200]           1,152\n",
      "      BatchNorm2d-86         [-1, 24, 200, 200]              48\n",
      "             ReLU-87         [-1, 24, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             384\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 243,600\n",
      "Trainable params: 243,600\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 295.10\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 296.64\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           2,156\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           8,085\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           8,281\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           7,007\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          12,936\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           9,163\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          15,092\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          17,689\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          10,241\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          16,170\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          22,099\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          28,028\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          47,089\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          16,709\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          22,638\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]          33,124\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          21,021\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          26,950\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]          44,100\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 34, 200, 200]              68\n",
      "            ReLU-107         [-1, 34, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]          18,326\n",
      "      conv_layer-109         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 45, 200, 200]              90\n",
      "            ReLU-111         [-1, 45, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          24,255\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 436,277\n",
      "Trainable params: 436,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 347.47\n",
      "Params size (MB): 1.66\n",
      "Estimated Total Size (MB): 349.75\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             100\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              50\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              75\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             100\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             125\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             225\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              75\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             100\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             100\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             100\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             125\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             225\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 3, 100, 100]               6\n",
      "            ReLU-123          [-1, 3, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              75\n",
      "      conv_layer-125          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 4, 100, 100]               8\n",
      "            ReLU-127          [-1, 4, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             100\n",
      "      conv_layer-129          [-1, 5, 100, 100]               0\n",
      "     Dense_block-130          [-1, 5, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 5, 100, 100]              10\n",
      "            ReLU-132          [-1, 5, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 6, 200, 200]              12\n",
      "            ReLU-139          [-1, 6, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             150\n",
      "      conv_layer-141          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 7, 200, 200]              14\n",
      "            ReLU-143          [-1, 7, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             175\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,711\n",
      "Trainable params: 3,711\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 57.14\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 57.76\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]           2,592\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           7,776\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           8,100\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           6,480\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]          11,664\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]          13,689\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           8,424\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]          13,608\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]          15,876\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           9,072\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]          14,256\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]          18,225\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           9,720\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]          14,904\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]          20,088\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]          25,272\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]          42,849\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 37, 25, 25]              74\n",
      "             ReLU-91           [-1, 37, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]          23,976\n",
      "       conv_layer-93           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 45, 25, 25]              90\n",
      "             ReLU-95           [-1, 45, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]          29,160\n",
      "       conv_layer-97           [-1, 53, 25, 25]               0\n",
      "      Dense_block-98           [-1, 53, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 53, 25, 25]             106\n",
      "            ReLU-100           [-1, 53, 25, 25]               0\n",
      "          Conv2d-101           [-1, 26, 25, 25]           1,378\n",
      "     BatchNorm2d-102           [-1, 26, 25, 25]              52\n",
      "            ReLU-103           [-1, 26, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 26, 50, 50]          54,756\n",
      "   Encode_Decode-105           [-1, 26, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 39, 50, 50]              78\n",
      "            ReLU-107           [-1, 39, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]          25,272\n",
      "      conv_layer-109           [-1, 47, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 47, 50, 50]              94\n",
      "            ReLU-111           [-1, 47, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]          30,456\n",
      "      conv_layer-113           [-1, 55, 50, 50]               0\n",
      "     Dense_block-114           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 55, 50, 50]             110\n",
      "            ReLU-116           [-1, 55, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,485\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          59,049\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 37, 100, 100]              74\n",
      "            ReLU-123         [-1, 37, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]          23,976\n",
      "      conv_layer-125         [-1, 45, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 45, 100, 100]              90\n",
      "            ReLU-127         [-1, 45, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]          29,160\n",
      "      conv_layer-129         [-1, 53, 100, 100]               0\n",
      "     Dense_block-130         [-1, 53, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 53, 100, 100]             106\n",
      "            ReLU-132         [-1, 53, 100, 100]               0\n",
      "          Conv2d-133         [-1, 26, 100, 100]           1,378\n",
      "     BatchNorm2d-134         [-1, 26, 100, 100]              52\n",
      "            ReLU-135         [-1, 26, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 26, 200, 200]          54,756\n",
      "   Encode_Decode-137         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]          19,440\n",
      "      conv_layer-141         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 38, 200, 200]              76\n",
      "            ReLU-143         [-1, 38, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]          24,624\n",
      "      conv_layer-145         [-1, 46, 200, 200]               0\n",
      "     Dense_block-146         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 46, 200, 200]              92\n",
      "            ReLU-148         [-1, 46, 200, 200]               0\n",
      "          Conv2d-149         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-150         [-1, 23, 200, 200]              46\n",
      "            ReLU-151         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             368\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 627,658\n",
      "Trainable params: 627,658\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 290.97\n",
      "Params size (MB): 2.39\n",
      "Estimated Total Size (MB): 293.98\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           4,230\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           5,130\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]           9,801\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           4,410\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           5,310\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          10,404\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           4,140\n",
      "      conv_layer-125         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 56, 100, 100]             112\n",
      "            ReLU-127         [-1, 56, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           5,040\n",
      "      conv_layer-129         [-1, 66, 100, 100]               0\n",
      "     Dense_block-130         [-1, 66, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 66, 100, 100]             132\n",
      "            ReLU-132         [-1, 66, 100, 100]               0\n",
      "          Conv2d-133         [-1, 33, 100, 100]           2,178\n",
      "     BatchNorm2d-134         [-1, 33, 100, 100]              66\n",
      "            ReLU-135         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 33, 200, 200]           9,801\n",
      "   Encode_Decode-137         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 33, 200, 200]              66\n",
      "            ReLU-139         [-1, 33, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           2,970\n",
      "      conv_layer-141         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 43, 200, 200]              86\n",
      "            ReLU-143         [-1, 43, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           3,870\n",
      "      conv_layer-145         [-1, 53, 200, 200]               0\n",
      "     Dense_block-146         [-1, 53, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 53, 200, 200]             106\n",
      "            ReLU-148         [-1, 53, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,378\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 122,494\n",
      "Trainable params: 122,494\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 344.66\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 345.74\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]              72\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             108\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             144\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]              72\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             108\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             144\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]              72\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             108\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             144\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]              72\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             108\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]             144\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]              72\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             108\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]             144\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]             180\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]             324\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 6, 25, 25]              12\n",
      "             ReLU-91            [-1, 6, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]             108\n",
      "       conv_layer-93            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 8, 25, 25]              16\n",
      "             ReLU-95            [-1, 8, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]             144\n",
      "       conv_layer-97           [-1, 10, 25, 25]               0\n",
      "      Dense_block-98           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 10, 25, 25]              20\n",
      "            ReLU-100           [-1, 10, 25, 25]               0\n",
      "          Conv2d-101            [-1, 5, 25, 25]              50\n",
      "     BatchNorm2d-102            [-1, 5, 25, 25]              10\n",
      "            ReLU-103            [-1, 5, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 5, 50, 50]             225\n",
      "   Encode_Decode-105            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]              90\n",
      "      conv_layer-109            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 7, 50, 50]              14\n",
      "            ReLU-111            [-1, 7, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]             126\n",
      "      conv_layer-113            [-1, 9, 50, 50]               0\n",
      "     Dense_block-114            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 9, 50, 50]              18\n",
      "            ReLU-116            [-1, 9, 50, 50]               0\n",
      "          Conv2d-117            [-1, 4, 50, 50]              36\n",
      "     BatchNorm2d-118            [-1, 4, 50, 50]               8\n",
      "            ReLU-119            [-1, 4, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 4, 100, 100]             144\n",
      "   Encode_Decode-121          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 4, 100, 100]               8\n",
      "            ReLU-123          [-1, 4, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]              72\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]             108\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             144\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]              72\n",
      "      conv_layer-141          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 6, 200, 200]              12\n",
      "            ReLU-143          [-1, 6, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]             108\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 4,487\n",
      "Trainable params: 4,487\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 68.23\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 68.86\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          14,161\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           7,497\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          11,466\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          15,435\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          19,404\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          33,124\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          11,466\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          15,435\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          23,716\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          15,876\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          19,845\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          35,721\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 38, 100, 100]              76\n",
      "            ReLU-123         [-1, 38, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          16,758\n",
      "      conv_layer-125         [-1, 47, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 47, 100, 100]              94\n",
      "            ReLU-127         [-1, 47, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          20,727\n",
      "      conv_layer-129         [-1, 56, 100, 100]               0\n",
      "     Dense_block-130         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 56, 100, 100]             112\n",
      "            ReLU-132         [-1, 56, 100, 100]               0\n",
      "          Conv2d-133         [-1, 28, 100, 100]           1,568\n",
      "     BatchNorm2d-134         [-1, 28, 100, 100]              56\n",
      "            ReLU-135         [-1, 28, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 28, 200, 200]          38,416\n",
      "   Encode_Decode-137         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 32, 200, 200]              64\n",
      "            ReLU-139         [-1, 32, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          14,112\n",
      "      conv_layer-141         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 41, 200, 200]              82\n",
      "            ReLU-143         [-1, 41, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          18,081\n",
      "      conv_layer-145         [-1, 50, 200, 200]               0\n",
      "     Dense_block-146         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 50, 200, 200]             100\n",
      "            ReLU-148         [-1, 50, 200, 200]               0\n",
      "          Conv2d-149         [-1, 25, 200, 200]           1,250\n",
      "     BatchNorm2d-150         [-1, 25, 200, 200]              50\n",
      "            ReLU-151         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             400\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 426,003\n",
      "Trainable params: 426,003\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 312.58\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 314.82\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             288\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]             864\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]             900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]             720\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           1,296\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           1,521\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]             936\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           1,512\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           1,764\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           1,008\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           1,584\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 30, 25, 25]              60\n",
      "             ReLU-59           [-1, 30, 25, 25]               0\n",
      "           Conv2d-60            [-1, 8, 25, 25]           2,160\n",
      "       conv_layer-61           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 38, 25, 25]              76\n",
      "             ReLU-63           [-1, 38, 25, 25]               0\n",
      "           Conv2d-64            [-1, 8, 25, 25]           2,736\n",
      "       conv_layer-65           [-1, 46, 25, 25]               0\n",
      "      Dense_block-66           [-1, 46, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 46, 25, 25]              92\n",
      "             ReLU-68           [-1, 46, 25, 25]               0\n",
      "           Conv2d-69           [-1, 23, 25, 25]           1,058\n",
      "      BatchNorm2d-70           [-1, 23, 25, 25]              46\n",
      "             ReLU-71           [-1, 23, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 23, 50, 50]           4,761\n",
      "    Encode_Decode-73           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 36, 50, 50]              72\n",
      "             ReLU-75           [-1, 36, 50, 50]               0\n",
      "           Conv2d-76            [-1, 8, 50, 50]           2,592\n",
      "       conv_layer-77           [-1, 44, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 44, 50, 50]              88\n",
      "             ReLU-79           [-1, 44, 50, 50]               0\n",
      "           Conv2d-80            [-1, 8, 50, 50]           3,168\n",
      "       conv_layer-81           [-1, 52, 50, 50]               0\n",
      "      Dense_block-82           [-1, 52, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 52, 50, 50]             104\n",
      "             ReLU-84           [-1, 52, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,352\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]           6,084\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 26, 100, 100]              52\n",
      "             ReLU-91         [-1, 26, 100, 100]               0\n",
      "           Conv2d-92          [-1, 8, 100, 100]           1,872\n",
      "       conv_layer-93         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 34, 100, 100]              68\n",
      "             ReLU-95         [-1, 34, 100, 100]               0\n",
      "           Conv2d-96          [-1, 8, 100, 100]           2,448\n",
      "       conv_layer-97         [-1, 42, 100, 100]               0\n",
      "      Dense_block-98         [-1, 42, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 42, 100, 100]              84\n",
      "            ReLU-100         [-1, 42, 100, 100]               0\n",
      "          Conv2d-101         [-1, 21, 100, 100]             882\n",
      "     BatchNorm2d-102         [-1, 21, 100, 100]              42\n",
      "            ReLU-103         [-1, 21, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 21, 200, 200]           3,969\n",
      "   Encode_Decode-105         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 21, 200, 200]              42\n",
      "            ReLU-107         [-1, 21, 200, 200]               0\n",
      "          Conv2d-108          [-1, 8, 200, 200]           1,512\n",
      "      conv_layer-109         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 29, 200, 200]              58\n",
      "            ReLU-111         [-1, 29, 200, 200]               0\n",
      "          Conv2d-112          [-1, 8, 200, 200]           2,088\n",
      "      conv_layer-113         [-1, 37, 200, 200]               0\n",
      "     Dense_block-114         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 37, 200, 200]              74\n",
      "            ReLU-116         [-1, 37, 200, 200]               0\n",
      "          Conv2d-117         [-1, 18, 200, 200]             666\n",
      "     BatchNorm2d-118         [-1, 18, 200, 200]              36\n",
      "            ReLU-119         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             288\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 52,615\n",
      "Trainable params: 52,615\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 247.07\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 247.88\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             324\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             405\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             729\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             243\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             324\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             324\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]             162\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             243\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             324\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]             162\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             243\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             324\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]             162\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             243\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             324\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             405\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             729\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             405\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             486\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             729\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             405\n",
      "      conv_layer-109            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 6, 50, 50]              12\n",
      "            ReLU-111            [-1, 6, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             486\n",
      "      conv_layer-113            [-1, 7, 50, 50]               0\n",
      "     Dense_block-114            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 7, 50, 50]              14\n",
      "            ReLU-116            [-1, 7, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              21\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             729\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             486\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             567\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]           1,296\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 8, 200, 200]              16\n",
      "            ReLU-139          [-1, 8, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             648\n",
      "      conv_layer-141          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 9, 200, 200]              18\n",
      "            ReLU-143          [-1, 9, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             729\n",
      "      conv_layer-145         [-1, 10, 200, 200]               0\n",
      "     Dense_block-146         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 10, 200, 200]              20\n",
      "            ReLU-148         [-1, 10, 200, 200]               0\n",
      "          Conv2d-149          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-150          [-1, 5, 200, 200]              10\n",
      "            ReLU-151          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              80\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 13,398\n",
      "Trainable params: 13,398\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.60\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 68.26\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             800\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           2,400\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           2,500\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           2,000\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           3,600\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           4,225\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           2,600\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           4,200\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           4,900\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           2,800\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           4,400\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]           5,625\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           3,000\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           4,600\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]           6,200\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]           7,800\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]          13,225\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 23, 25, 25]              46\n",
      "             ReLU-91           [-1, 23, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]           4,600\n",
      "       conv_layer-93           [-1, 31, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 31, 25, 25]              62\n",
      "             ReLU-95           [-1, 31, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]           6,200\n",
      "       conv_layer-97           [-1, 39, 25, 25]               0\n",
      "      Dense_block-98           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 39, 25, 25]              78\n",
      "            ReLU-100           [-1, 39, 25, 25]               0\n",
      "          Conv2d-101           [-1, 19, 25, 25]             741\n",
      "     BatchNorm2d-102           [-1, 19, 25, 25]              38\n",
      "            ReLU-103           [-1, 19, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 19, 50, 50]           9,025\n",
      "   Encode_Decode-105           [-1, 19, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 19, 50, 50]              38\n",
      "            ReLU-107           [-1, 19, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]           3,800\n",
      "      conv_layer-109           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 27, 50, 50]              54\n",
      "            ReLU-111           [-1, 27, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]           5,400\n",
      "      conv_layer-113           [-1, 35, 50, 50]               0\n",
      "     Dense_block-114           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 35, 50, 50]              70\n",
      "            ReLU-116           [-1, 35, 50, 50]               0\n",
      "          Conv2d-117           [-1, 17, 50, 50]             595\n",
      "     BatchNorm2d-118           [-1, 17, 50, 50]              34\n",
      "            ReLU-119           [-1, 17, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 17, 100, 100]           7,225\n",
      "   Encode_Decode-121         [-1, 17, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 17, 100, 100]              34\n",
      "            ReLU-123         [-1, 17, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]           3,400\n",
      "      conv_layer-125         [-1, 25, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 25, 100, 100]              50\n",
      "            ReLU-127         [-1, 25, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]           5,000\n",
      "      conv_layer-129         [-1, 33, 100, 100]               0\n",
      "     Dense_block-130         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 33, 100, 100]              66\n",
      "            ReLU-132         [-1, 33, 100, 100]               0\n",
      "          Conv2d-133         [-1, 16, 100, 100]             528\n",
      "     BatchNorm2d-134         [-1, 16, 100, 100]              32\n",
      "            ReLU-135         [-1, 16, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 16, 200, 200]           6,400\n",
      "   Encode_Decode-137         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 16, 200, 200]              32\n",
      "            ReLU-139         [-1, 16, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]           3,200\n",
      "      conv_layer-141         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 24, 200, 200]              48\n",
      "            ReLU-143         [-1, 24, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]           4,800\n",
      "      conv_layer-145         [-1, 32, 200, 200]               0\n",
      "     Dense_block-146         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 32, 200, 200]              64\n",
      "            ReLU-148         [-1, 32, 200, 200]               0\n",
      "          Conv2d-149         [-1, 16, 200, 200]             512\n",
      "     BatchNorm2d-150         [-1, 16, 200, 200]              32\n",
      "            ReLU-151         [-1, 16, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             256\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 140,852\n",
      "Trainable params: 140,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 217.49\n",
      "Params size (MB): 0.54\n",
      "Estimated Total Size (MB): 218.64\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             245\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             294\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             441\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             245\n",
      "      conv_layer-109            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 6, 50, 50]              12\n",
      "            ReLU-111            [-1, 6, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             294\n",
      "      conv_layer-113            [-1, 7, 50, 50]               0\n",
      "     Dense_block-114            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 7, 50, 50]              14\n",
      "            ReLU-116            [-1, 7, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              21\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             441\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 3, 100, 100]               6\n",
      "            ReLU-123          [-1, 3, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             147\n",
      "      conv_layer-125          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 4, 100, 100]               8\n",
      "            ReLU-127          [-1, 4, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             196\n",
      "      conv_layer-129          [-1, 5, 100, 100]               0\n",
      "     Dense_block-130          [-1, 5, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 5, 100, 100]              10\n",
      "            ReLU-132          [-1, 5, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             196\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 6, 200, 200]              12\n",
      "            ReLU-139          [-1, 6, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             294\n",
      "      conv_layer-141          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 7, 200, 200]              14\n",
      "            ReLU-143          [-1, 7, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             343\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 7,236\n",
      "Trainable params: 7,236\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 57.45\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 58.09\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]             432\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           1,728\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           1,512\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           2,808\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           3,249\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           2,052\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           3,348\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]           3,969\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           2,268\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           3,564\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]           4,860\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]           6,156\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          10,404\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]           5,724\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]           7,020\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          12,996\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 38, 100, 100]              76\n",
      "             ReLU-91         [-1, 38, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]           4,104\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]           5,400\n",
      "       conv_layer-97         [-1, 62, 100, 100]               0\n",
      "      Dense_block-98         [-1, 62, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 62, 100, 100]             124\n",
      "            ReLU-100         [-1, 62, 100, 100]               0\n",
      "          Conv2d-101         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-102         [-1, 31, 100, 100]              62\n",
      "            ReLU-103         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 31, 200, 200]           8,649\n",
      "   Encode_Decode-105         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 35, 200, 200]              70\n",
      "            ReLU-107         [-1, 35, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]           3,780\n",
      "      conv_layer-109         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 47, 200, 200]              94\n",
      "            ReLU-111         [-1, 47, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]           5,076\n",
      "      conv_layer-113         [-1, 59, 200, 200]               0\n",
      "     Dense_block-114         [-1, 59, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 59, 200, 200]             118\n",
      "            ReLU-116         [-1, 59, 200, 200]               0\n",
      "          Conv2d-117         [-1, 29, 200, 200]           1,711\n",
      "     BatchNorm2d-118         [-1, 29, 200, 200]              58\n",
      "            ReLU-119         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             464\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 114,625\n",
      "Trainable params: 114,625\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 371.24\n",
      "Params size (MB): 0.44\n",
      "Estimated Total Size (MB): 372.29\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 38, 100, 100]              76\n",
      "             ReLU-91         [-1, 38, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          11,400\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          15,000\n",
      "       conv_layer-97         [-1, 62, 100, 100]               0\n",
      "      Dense_block-98         [-1, 62, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 62, 100, 100]             124\n",
      "            ReLU-100         [-1, 62, 100, 100]               0\n",
      "          Conv2d-101         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-102         [-1, 31, 100, 100]              62\n",
      "            ReLU-103         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 31, 200, 200]          24,025\n",
      "   Encode_Decode-105         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 35, 200, 200]              70\n",
      "            ReLU-107         [-1, 35, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]          10,500\n",
      "      conv_layer-109         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 47, 200, 200]              94\n",
      "            ReLU-111         [-1, 47, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          14,100\n",
      "      conv_layer-113         [-1, 59, 200, 200]               0\n",
      "     Dense_block-114         [-1, 59, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 59, 200, 200]             118\n",
      "            ReLU-116         [-1, 59, 200, 200]               0\n",
      "          Conv2d-117         [-1, 29, 200, 200]           1,711\n",
      "     BatchNorm2d-118         [-1, 29, 200, 200]              58\n",
      "            ReLU-119         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             464\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 293,937\n",
      "Trainable params: 293,937\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 371.24\n",
      "Params size (MB): 1.12\n",
      "Estimated Total Size (MB): 372.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             196\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             245\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             294\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             343\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             784\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             196\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             245\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 4,894\n",
      "Trainable params: 4,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 54.13\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 26, 25, 25]              52\n",
      "             ReLU-59           [-1, 26, 25, 25]               0\n",
      "           Conv2d-60            [-1, 7, 25, 25]           8,918\n",
      "       conv_layer-61           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 33, 25, 25]              66\n",
      "             ReLU-63           [-1, 33, 25, 25]               0\n",
      "           Conv2d-64            [-1, 7, 25, 25]          11,319\n",
      "       conv_layer-65           [-1, 40, 25, 25]               0\n",
      "      Dense_block-66           [-1, 40, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 40, 25, 25]              80\n",
      "             ReLU-68           [-1, 40, 25, 25]               0\n",
      "           Conv2d-69           [-1, 20, 25, 25]             800\n",
      "      BatchNorm2d-70           [-1, 20, 25, 25]              40\n",
      "             ReLU-71           [-1, 20, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 20, 50, 50]          19,600\n",
      "    Encode_Decode-73           [-1, 20, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 20, 50, 50]              40\n",
      "             ReLU-75           [-1, 20, 50, 50]               0\n",
      "           Conv2d-76            [-1, 7, 50, 50]           6,860\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 7, 50, 50]           9,261\n",
      "       conv_layer-81           [-1, 34, 50, 50]               0\n",
      "      Dense_block-82           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 34, 50, 50]              68\n",
      "             ReLU-84           [-1, 34, 50, 50]               0\n",
      "           Conv2d-85           [-1, 17, 50, 50]             578\n",
      "      BatchNorm2d-86           [-1, 17, 50, 50]              34\n",
      "             ReLU-87           [-1, 17, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 17, 100, 100]          14,161\n",
      "    Encode_Decode-89         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 26, 100, 100]              52\n",
      "             ReLU-91         [-1, 26, 100, 100]               0\n",
      "           Conv2d-92          [-1, 7, 100, 100]           8,918\n",
      "       conv_layer-93         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 33, 100, 100]              66\n",
      "             ReLU-95         [-1, 33, 100, 100]               0\n",
      "           Conv2d-96          [-1, 7, 100, 100]          11,319\n",
      "       conv_layer-97         [-1, 40, 100, 100]               0\n",
      "      Dense_block-98         [-1, 40, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 40, 100, 100]              80\n",
      "            ReLU-100         [-1, 40, 100, 100]               0\n",
      "          Conv2d-101         [-1, 20, 100, 100]             800\n",
      "     BatchNorm2d-102         [-1, 20, 100, 100]              40\n",
      "            ReLU-103         [-1, 20, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 20, 200, 200]          19,600\n",
      "   Encode_Decode-105         [-1, 20, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 24, 200, 200]              48\n",
      "            ReLU-107         [-1, 24, 200, 200]               0\n",
      "          Conv2d-108          [-1, 7, 200, 200]           8,232\n",
      "      conv_layer-109         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 31, 200, 200]              62\n",
      "            ReLU-111         [-1, 31, 200, 200]               0\n",
      "          Conv2d-112          [-1, 7, 200, 200]          10,633\n",
      "      conv_layer-113         [-1, 38, 200, 200]               0\n",
      "     Dense_block-114         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 38, 200, 200]              76\n",
      "            ReLU-116         [-1, 38, 200, 200]               0\n",
      "          Conv2d-117         [-1, 19, 200, 200]             722\n",
      "     BatchNorm2d-118         [-1, 19, 200, 200]              38\n",
      "            ReLU-119         [-1, 19, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             304\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 185,430\n",
      "Trainable params: 185,430\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 237.09\n",
      "Params size (MB): 0.71\n",
      "Estimated Total Size (MB): 238.41\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           7,225\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           3,825\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           5,850\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           7,875\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           9,900\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          16,900\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           9,450\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          11,475\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]          22,500\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           9,900\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          11,925\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]          24,025\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 31, 100, 100]              62\n",
      "            ReLU-123         [-1, 31, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           6,975\n",
      "      conv_layer-125         [-1, 40, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 40, 100, 100]              80\n",
      "            ReLU-127         [-1, 40, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]           9,000\n",
      "      conv_layer-129         [-1, 49, 100, 100]               0\n",
      "     Dense_block-130         [-1, 49, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 49, 100, 100]              98\n",
      "            ReLU-132         [-1, 49, 100, 100]               0\n",
      "          Conv2d-133         [-1, 24, 100, 100]           1,176\n",
      "     BatchNorm2d-134         [-1, 24, 100, 100]              48\n",
      "            ReLU-135         [-1, 24, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 24, 200, 200]          14,400\n",
      "   Encode_Decode-137         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 24, 200, 200]              48\n",
      "            ReLU-139         [-1, 24, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           5,400\n",
      "      conv_layer-141         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 33, 200, 200]              66\n",
      "            ReLU-143         [-1, 33, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           7,425\n",
      "      conv_layer-145         [-1, 42, 200, 200]               0\n",
      "     Dense_block-146         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 42, 200, 200]              84\n",
      "            ReLU-148         [-1, 42, 200, 200]               0\n",
      "          Conv2d-149         [-1, 21, 200, 200]             882\n",
      "     BatchNorm2d-150         [-1, 21, 200, 200]              42\n",
      "            ReLU-151         [-1, 21, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             336\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 238,379\n",
      "Trainable params: 238,379\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 282.10\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 283.62\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           1,566\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]             918\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           1,242\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           1,188\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           1,512\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           2,601\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]             918\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           1,242\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 28,238\n",
      "Trainable params: 28,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 193.80\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 194.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             288\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]             864\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]             900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]             720\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           1,296\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           1,521\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]             936\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           1,512\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           1,764\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           1,008\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           1,584\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]           2,025\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           1,080\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           1,656\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]           2,232\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]           2,808\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]           4,761\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 37, 25, 25]              74\n",
      "             ReLU-91           [-1, 37, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]           2,664\n",
      "       conv_layer-93           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 45, 25, 25]              90\n",
      "             ReLU-95           [-1, 45, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]           3,240\n",
      "       conv_layer-97           [-1, 53, 25, 25]               0\n",
      "      Dense_block-98           [-1, 53, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 53, 25, 25]             106\n",
      "            ReLU-100           [-1, 53, 25, 25]               0\n",
      "          Conv2d-101           [-1, 26, 25, 25]           1,378\n",
      "     BatchNorm2d-102           [-1, 26, 25, 25]              52\n",
      "            ReLU-103           [-1, 26, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 26, 50, 50]           6,084\n",
      "   Encode_Decode-105           [-1, 26, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 39, 50, 50]              78\n",
      "            ReLU-107           [-1, 39, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]           2,808\n",
      "      conv_layer-109           [-1, 47, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 47, 50, 50]              94\n",
      "            ReLU-111           [-1, 47, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]           3,384\n",
      "      conv_layer-113           [-1, 55, 50, 50]               0\n",
      "     Dense_block-114           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 55, 50, 50]             110\n",
      "            ReLU-116           [-1, 55, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,485\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]           6,561\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 37, 100, 100]              74\n",
      "            ReLU-123         [-1, 37, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]           2,664\n",
      "      conv_layer-125         [-1, 45, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 45, 100, 100]              90\n",
      "            ReLU-127         [-1, 45, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]           3,240\n",
      "      conv_layer-129         [-1, 53, 100, 100]               0\n",
      "     Dense_block-130         [-1, 53, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 53, 100, 100]             106\n",
      "            ReLU-132         [-1, 53, 100, 100]               0\n",
      "          Conv2d-133         [-1, 26, 100, 100]           1,378\n",
      "     BatchNorm2d-134         [-1, 26, 100, 100]              52\n",
      "            ReLU-135         [-1, 26, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 26, 200, 200]           6,084\n",
      "   Encode_Decode-137         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]           2,160\n",
      "      conv_layer-141         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 38, 200, 200]              76\n",
      "            ReLU-143         [-1, 38, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]           2,736\n",
      "      conv_layer-145         [-1, 46, 200, 200]               0\n",
      "     Dense_block-146         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 46, 200, 200]              92\n",
      "            ReLU-148         [-1, 46, 200, 200]               0\n",
      "          Conv2d-149         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-150         [-1, 23, 200, 200]              46\n",
      "            ReLU-151         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             368\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 79,018\n",
      "Trainable params: 79,018\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 290.97\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 291.89\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]           7,650\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]           9,675\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]          16,900\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 40, 50, 50]              80\n",
      "             ReLU-75           [-1, 40, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]           9,000\n",
      "       conv_layer-77           [-1, 49, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 49, 50, 50]              98\n",
      "             ReLU-79           [-1, 49, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]          11,025\n",
      "       conv_layer-81           [-1, 58, 50, 50]               0\n",
      "      Dense_block-82           [-1, 58, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 58, 50, 50]             116\n",
      "             ReLU-84           [-1, 58, 50, 50]               0\n",
      "           Conv2d-85           [-1, 29, 50, 50]           1,682\n",
      "      BatchNorm2d-86           [-1, 29, 50, 50]              58\n",
      "             ReLU-87           [-1, 29, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 29, 100, 100]          21,025\n",
      "    Encode_Decode-89         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 29, 100, 100]              58\n",
      "             ReLU-91         [-1, 29, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]           6,525\n",
      "       conv_layer-93         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 38, 100, 100]              76\n",
      "             ReLU-95         [-1, 38, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]           8,550\n",
      "       conv_layer-97         [-1, 47, 100, 100]               0\n",
      "      Dense_block-98         [-1, 47, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 47, 100, 100]              94\n",
      "            ReLU-100         [-1, 47, 100, 100]               0\n",
      "          Conv2d-101         [-1, 23, 100, 100]           1,081\n",
      "     BatchNorm2d-102         [-1, 23, 100, 100]              46\n",
      "            ReLU-103         [-1, 23, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 23, 200, 200]          13,225\n",
      "   Encode_Decode-105         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 23, 200, 200]              46\n",
      "            ReLU-107         [-1, 23, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]           5,175\n",
      "      conv_layer-109         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 32, 200, 200]              64\n",
      "            ReLU-111         [-1, 32, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]           7,200\n",
      "      conv_layer-113         [-1, 41, 200, 200]               0\n",
      "     Dense_block-114         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 41, 200, 200]              82\n",
      "            ReLU-116         [-1, 41, 200, 200]               0\n",
      "          Conv2d-117         [-1, 20, 200, 200]             820\n",
      "     BatchNorm2d-118         [-1, 20, 200, 200]              40\n",
      "            ReLU-119         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             320\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 166,852\n",
      "Trainable params: 166,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 272.67\n",
      "Params size (MB): 0.64\n",
      "Estimated Total Size (MB): 273.92\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |      79 |      15 |  0.031074922 |            f\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             288\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]             864\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]             900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]             720\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           1,296\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           1,521\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]             936\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           1,512\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           1,764\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           1,008\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           1,584\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 30, 25, 25]              60\n",
      "             ReLU-59           [-1, 30, 25, 25]               0\n",
      "           Conv2d-60            [-1, 8, 25, 25]           2,160\n",
      "       conv_layer-61           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 38, 25, 25]              76\n",
      "             ReLU-63           [-1, 38, 25, 25]               0\n",
      "           Conv2d-64            [-1, 8, 25, 25]           2,736\n",
      "       conv_layer-65           [-1, 46, 25, 25]               0\n",
      "      Dense_block-66           [-1, 46, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 46, 25, 25]              92\n",
      "             ReLU-68           [-1, 46, 25, 25]               0\n",
      "           Conv2d-69           [-1, 23, 25, 25]           1,058\n",
      "      BatchNorm2d-70           [-1, 23, 25, 25]              46\n",
      "             ReLU-71           [-1, 23, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 23, 50, 50]           4,761\n",
      "    Encode_Decode-73           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 36, 50, 50]              72\n",
      "             ReLU-75           [-1, 36, 50, 50]               0\n",
      "           Conv2d-76            [-1, 8, 50, 50]           2,592\n",
      "       conv_layer-77           [-1, 44, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 44, 50, 50]              88\n",
      "             ReLU-79           [-1, 44, 50, 50]               0\n",
      "           Conv2d-80            [-1, 8, 50, 50]           3,168\n",
      "       conv_layer-81           [-1, 52, 50, 50]               0\n",
      "      Dense_block-82           [-1, 52, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 52, 50, 50]             104\n",
      "             ReLU-84           [-1, 52, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,352\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]           6,084\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 26, 100, 100]              52\n",
      "             ReLU-91         [-1, 26, 100, 100]               0\n",
      "           Conv2d-92          [-1, 8, 100, 100]           1,872\n",
      "       conv_layer-93         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 34, 100, 100]              68\n",
      "             ReLU-95         [-1, 34, 100, 100]               0\n",
      "           Conv2d-96          [-1, 8, 100, 100]           2,448\n",
      "       conv_layer-97         [-1, 42, 100, 100]               0\n",
      "      Dense_block-98         [-1, 42, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 42, 100, 100]              84\n",
      "            ReLU-100         [-1, 42, 100, 100]               0\n",
      "          Conv2d-101         [-1, 21, 100, 100]             882\n",
      "     BatchNorm2d-102         [-1, 21, 100, 100]              42\n",
      "            ReLU-103         [-1, 21, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 21, 200, 200]           3,969\n",
      "   Encode_Decode-105         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 21, 200, 200]              42\n",
      "            ReLU-107         [-1, 21, 200, 200]               0\n",
      "          Conv2d-108          [-1, 8, 200, 200]           1,512\n",
      "      conv_layer-109         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 29, 200, 200]              58\n",
      "            ReLU-111         [-1, 29, 200, 200]               0\n",
      "          Conv2d-112          [-1, 8, 200, 200]           2,088\n",
      "      conv_layer-113         [-1, 37, 200, 200]               0\n",
      "     Dense_block-114         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 37, 200, 200]              74\n",
      "            ReLU-116         [-1, 37, 200, 200]               0\n",
      "          Conv2d-117         [-1, 18, 200, 200]             666\n",
      "     BatchNorm2d-118         [-1, 18, 200, 200]              36\n",
      "            ReLU-119         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             288\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 52,615\n",
      "Trainable params: 52,615\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 247.07\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 247.88\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      Dense_block-42           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 15, 50, 50]              30\n",
      "             ReLU-44           [-1, 15, 50, 50]               0\n",
      "           Conv2d-45            [-1, 7, 50, 50]             105\n",
      "      BatchNorm2d-46            [-1, 7, 50, 50]              14\n",
      "             ReLU-47            [-1, 7, 50, 50]               0\n",
      "           Conv2d-48            [-1, 7, 25, 25]           3,969\n",
      "    Encode_Decode-49            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 7, 25, 25]              14\n",
      "             ReLU-51            [-1, 7, 25, 25]               0\n",
      "           Conv2d-52            [-1, 4, 25, 25]           2,268\n",
      "       conv_layer-53           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 11, 25, 25]              22\n",
      "             ReLU-55           [-1, 11, 25, 25]               0\n",
      "           Conv2d-56            [-1, 4, 25, 25]           3,564\n",
      "       conv_layer-57           [-1, 15, 25, 25]               0\n",
      "      Dense_block-58           [-1, 15, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 15, 25, 25]              30\n",
      "             ReLU-60           [-1, 15, 25, 25]               0\n",
      "           Conv2d-61            [-1, 7, 25, 25]             105\n",
      "      BatchNorm2d-62            [-1, 7, 25, 25]              14\n",
      "             ReLU-63            [-1, 7, 25, 25]               0\n",
      "           Conv2d-64            [-1, 7, 13, 13]           3,969\n",
      "    Encode_Decode-65            [-1, 7, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 7, 13, 13]              14\n",
      "             ReLU-67            [-1, 7, 13, 13]               0\n",
      "           Conv2d-68            [-1, 4, 13, 13]           2,268\n",
      "       conv_layer-69           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 11, 13, 13]              22\n",
      "             ReLU-71           [-1, 11, 13, 13]               0\n",
      "           Conv2d-72            [-1, 4, 13, 13]           3,564\n",
      "       conv_layer-73           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 15, 13, 13]              30\n",
      "             ReLU-75           [-1, 15, 13, 13]               0\n",
      "           Conv2d-76            [-1, 4, 13, 13]           4,860\n",
      "       conv_layer-77           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 19, 13, 13]              38\n",
      "             ReLU-79           [-1, 19, 13, 13]               0\n",
      "           Conv2d-80            [-1, 4, 13, 13]           6,156\n",
      "       conv_layer-81           [-1, 23, 13, 13]               0\n",
      "      Dense_block-82           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 23, 13, 13]              46\n",
      "             ReLU-84           [-1, 23, 13, 13]               0\n",
      "           Conv2d-85           [-1, 11, 13, 13]             253\n",
      "      BatchNorm2d-86           [-1, 11, 13, 13]              22\n",
      "             ReLU-87           [-1, 11, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 11, 25, 25]           9,801\n",
      "    Encode_Decode-89           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 18, 25, 25]              36\n",
      "             ReLU-91           [-1, 18, 25, 25]               0\n",
      "           Conv2d-92            [-1, 4, 25, 25]           5,832\n",
      "       conv_layer-93           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 22, 25, 25]              44\n",
      "             ReLU-95           [-1, 22, 25, 25]               0\n",
      "           Conv2d-96            [-1, 4, 25, 25]           7,128\n",
      "       conv_layer-97           [-1, 26, 25, 25]               0\n",
      "      Dense_block-98           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 26, 25, 25]              52\n",
      "            ReLU-100           [-1, 26, 25, 25]               0\n",
      "          Conv2d-101           [-1, 13, 25, 25]             338\n",
      "     BatchNorm2d-102           [-1, 13, 25, 25]              26\n",
      "            ReLU-103           [-1, 13, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 13, 50, 50]          13,689\n",
      "   Encode_Decode-105           [-1, 13, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 20, 50, 50]              40\n",
      "            ReLU-107           [-1, 20, 50, 50]               0\n",
      "          Conv2d-108            [-1, 4, 50, 50]           6,480\n",
      "      conv_layer-109           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 24, 50, 50]              48\n",
      "            ReLU-111           [-1, 24, 50, 50]               0\n",
      "          Conv2d-112            [-1, 4, 50, 50]           7,776\n",
      "      conv_layer-113           [-1, 28, 50, 50]               0\n",
      "     Dense_block-114           [-1, 28, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 28, 50, 50]              56\n",
      "            ReLU-116           [-1, 28, 50, 50]               0\n",
      "          Conv2d-117           [-1, 14, 50, 50]             392\n",
      "     BatchNorm2d-118           [-1, 14, 50, 50]              28\n",
      "            ReLU-119           [-1, 14, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 14, 100, 100]          15,876\n",
      "   Encode_Decode-121         [-1, 14, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 14, 100, 100]              28\n",
      "            ReLU-123         [-1, 14, 100, 100]               0\n",
      "          Conv2d-124          [-1, 4, 100, 100]           4,536\n",
      "      conv_layer-125         [-1, 18, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 18, 100, 100]              36\n",
      "            ReLU-127         [-1, 18, 100, 100]               0\n",
      "          Conv2d-128          [-1, 4, 100, 100]           5,832\n",
      "      conv_layer-129         [-1, 22, 100, 100]               0\n",
      "     Dense_block-130         [-1, 22, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 22, 100, 100]              44\n",
      "            ReLU-132         [-1, 22, 100, 100]               0\n",
      "          Conv2d-133         [-1, 11, 100, 100]             242\n",
      "     BatchNorm2d-134         [-1, 11, 100, 100]              22\n",
      "            ReLU-135         [-1, 11, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 11, 200, 200]           9,801\n",
      "   Encode_Decode-137         [-1, 11, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 11, 200, 200]              22\n",
      "            ReLU-139         [-1, 11, 200, 200]               0\n",
      "          Conv2d-140          [-1, 4, 200, 200]           3,564\n",
      "      conv_layer-141         [-1, 15, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 15, 200, 200]              30\n",
      "            ReLU-143         [-1, 15, 200, 200]               0\n",
      "          Conv2d-144          [-1, 4, 200, 200]           4,860\n",
      "      conv_layer-145         [-1, 19, 200, 200]               0\n",
      "     Dense_block-146         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 19, 200, 200]              38\n",
      "            ReLU-148         [-1, 19, 200, 200]               0\n",
      "          Conv2d-149          [-1, 9, 200, 200]             171\n",
      "     BatchNorm2d-150          [-1, 9, 200, 200]              18\n",
      "            ReLU-151          [-1, 9, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             144\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 150,680\n",
      "Trainable params: 150,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 136.89\n",
      "Params size (MB): 0.57\n",
      "Estimated Total Size (MB): 138.07\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           8,525\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          11,550\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]          16,900\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          10,725\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          13,750\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]          22,500\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 34, 200, 200]              68\n",
      "            ReLU-107         [-1, 34, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           9,350\n",
      "      conv_layer-109         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 45, 200, 200]              90\n",
      "            ReLU-111         [-1, 45, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          12,375\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 227,957\n",
      "Trainable params: 227,957\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 347.47\n",
      "Params size (MB): 0.87\n",
      "Estimated Total Size (MB): 348.95\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 51, 25, 25]             102\n",
      "             ReLU-91           [-1, 51, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           5,049\n",
      "       conv_layer-93           [-1, 62, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 62, 25, 25]             124\n",
      "             ReLU-95           [-1, 62, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           6,138\n",
      "       conv_layer-97           [-1, 73, 25, 25]               0\n",
      "      Dense_block-98           [-1, 73, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 73, 25, 25]             146\n",
      "            ReLU-100           [-1, 73, 25, 25]               0\n",
      "          Conv2d-101           [-1, 36, 25, 25]           2,628\n",
      "     BatchNorm2d-102           [-1, 36, 25, 25]              72\n",
      "            ReLU-103           [-1, 36, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 36, 50, 50]          11,664\n",
      "   Encode_Decode-105           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 53, 50, 50]             106\n",
      "            ReLU-107           [-1, 53, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           5,247\n",
      "      conv_layer-109           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 64, 50, 50]             128\n",
      "            ReLU-111           [-1, 64, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           6,336\n",
      "      conv_layer-113           [-1, 75, 50, 50]               0\n",
      "     Dense_block-114           [-1, 75, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 75, 50, 50]             150\n",
      "            ReLU-116           [-1, 75, 50, 50]               0\n",
      "          Conv2d-117           [-1, 37, 50, 50]           2,775\n",
      "     BatchNorm2d-118           [-1, 37, 50, 50]              74\n",
      "            ReLU-119           [-1, 37, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 37, 100, 100]          12,321\n",
      "   Encode_Decode-121         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 50, 100, 100]             100\n",
      "            ReLU-123         [-1, 50, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,950\n",
      "      conv_layer-125         [-1, 61, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 61, 100, 100]             122\n",
      "            ReLU-127         [-1, 61, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           6,039\n",
      "      conv_layer-129         [-1, 72, 100, 100]               0\n",
      "     Dense_block-130         [-1, 72, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 72, 100, 100]             144\n",
      "            ReLU-132         [-1, 72, 100, 100]               0\n",
      "          Conv2d-133         [-1, 36, 100, 100]           2,592\n",
      "     BatchNorm2d-134         [-1, 36, 100, 100]              72\n",
      "            ReLU-135         [-1, 36, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 36, 200, 200]          11,664\n",
      "   Encode_Decode-137         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 36, 200, 200]              72\n",
      "            ReLU-139         [-1, 36, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,564\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           4,653\n",
      "      conv_layer-145         [-1, 58, 200, 200]               0\n",
      "     Dense_block-146         [-1, 58, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 58, 200, 200]             116\n",
      "            ReLU-148         [-1, 58, 200, 200]               0\n",
      "          Conv2d-149         [-1, 29, 200, 200]           1,682\n",
      "     BatchNorm2d-150         [-1, 29, 200, 200]              58\n",
      "            ReLU-151         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             464\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 144,827\n",
      "Trainable params: 144,827\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 375.52\n",
      "Params size (MB): 0.55\n",
      "Estimated Total Size (MB): 376.69\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           2,916\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           9,477\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           8,019\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]          14,580\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]          15,876\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]          10,206\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          16,767\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          20,736\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]          11,664\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          18,225\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          23,409\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]          12,393\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          18,954\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          25,515\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          32,076\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          54,756\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          18,954\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          25,515\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          39,204\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          26,244\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          32,805\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          59,049\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 27, 100, 100]              54\n",
      "            ReLU-123         [-1, 27, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          19,683\n",
      "      conv_layer-125         [-1, 36, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 36, 100, 100]              72\n",
      "            ReLU-127         [-1, 36, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          26,244\n",
      "      conv_layer-129         [-1, 45, 100, 100]               0\n",
      "     Dense_block-130         [-1, 45, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 45, 100, 100]              90\n",
      "            ReLU-132         [-1, 45, 100, 100]               0\n",
      "          Conv2d-133         [-1, 22, 100, 100]             990\n",
      "     BatchNorm2d-134         [-1, 22, 100, 100]              44\n",
      "            ReLU-135         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 22, 200, 200]          39,204\n",
      "   Encode_Decode-137         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 26, 200, 200]              52\n",
      "            ReLU-139         [-1, 26, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          18,954\n",
      "      conv_layer-141         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 35, 200, 200]              70\n",
      "            ReLU-143         [-1, 35, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          25,515\n",
      "      conv_layer-145         [-1, 44, 200, 200]               0\n",
      "     Dense_block-146         [-1, 44, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 44, 200, 200]              88\n",
      "            ReLU-148         [-1, 44, 200, 200]               0\n",
      "          Conv2d-149         [-1, 22, 200, 200]             968\n",
      "     BatchNorm2d-150         [-1, 22, 200, 200]              44\n",
      "            ReLU-151         [-1, 22, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             352\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 646,833\n",
      "Trainable params: 646,833\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 280.77\n",
      "Params size (MB): 2.47\n",
      "Estimated Total Size (MB): 283.84\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]          14,994\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]          18,963\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]          33,124\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 26, 50, 50]              52\n",
      "             ReLU-75           [-1, 26, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]          11,466\n",
      "       conv_layer-77           [-1, 35, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 35, 50, 50]              70\n",
      "             ReLU-79           [-1, 35, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]          15,435\n",
      "       conv_layer-81           [-1, 44, 50, 50]               0\n",
      "      Dense_block-82           [-1, 44, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 44, 50, 50]              88\n",
      "             ReLU-84           [-1, 44, 50, 50]               0\n",
      "           Conv2d-85           [-1, 22, 50, 50]             968\n",
      "      BatchNorm2d-86           [-1, 22, 50, 50]              44\n",
      "             ReLU-87           [-1, 22, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 22, 100, 100]          23,716\n",
      "    Encode_Decode-89         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 33, 100, 100]              66\n",
      "             ReLU-91         [-1, 33, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]          14,553\n",
      "       conv_layer-93         [-1, 42, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 42, 100, 100]              84\n",
      "             ReLU-95         [-1, 42, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]          18,522\n",
      "       conv_layer-97         [-1, 51, 100, 100]               0\n",
      "      Dense_block-98         [-1, 51, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 51, 100, 100]             102\n",
      "            ReLU-100         [-1, 51, 100, 100]               0\n",
      "          Conv2d-101         [-1, 25, 100, 100]           1,275\n",
      "     BatchNorm2d-102         [-1, 25, 100, 100]              50\n",
      "            ReLU-103         [-1, 25, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 25, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 29, 200, 200]              58\n",
      "            ReLU-107         [-1, 29, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]          12,789\n",
      "      conv_layer-109         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 38, 200, 200]              76\n",
      "            ReLU-111         [-1, 38, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]          16,758\n",
      "      conv_layer-113         [-1, 47, 200, 200]               0\n",
      "     Dense_block-114         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 47, 200, 200]              94\n",
      "            ReLU-116         [-1, 47, 200, 200]               0\n",
      "          Conv2d-117         [-1, 23, 200, 200]           1,081\n",
      "     BatchNorm2d-118         [-1, 23, 200, 200]              46\n",
      "            ReLU-119         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             368\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 302,576\n",
      "Trainable params: 302,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 292.45\n",
      "Params size (MB): 1.15\n",
      "Estimated Total Size (MB): 294.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,000\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           3,500\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           3,600\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           3,000\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           5,500\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           6,400\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           4,000\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           6,500\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 36, 50, 50]              72\n",
      "             ReLU-43           [-1, 36, 50, 50]               0\n",
      "           Conv2d-44           [-1, 10, 50, 50]           9,000\n",
      "       conv_layer-45           [-1, 46, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 46, 50, 50]              92\n",
      "             ReLU-47           [-1, 46, 50, 50]               0\n",
      "           Conv2d-48           [-1, 10, 50, 50]          11,500\n",
      "       conv_layer-49           [-1, 56, 50, 50]               0\n",
      "      Dense_block-50           [-1, 56, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 56, 50, 50]             112\n",
      "             ReLU-52           [-1, 56, 50, 50]               0\n",
      "           Conv2d-53           [-1, 28, 50, 50]           1,568\n",
      "      BatchNorm2d-54           [-1, 28, 50, 50]              56\n",
      "             ReLU-55           [-1, 28, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 28, 100, 100]          19,600\n",
      "    Encode_Decode-57         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 28, 100, 100]              56\n",
      "             ReLU-59         [-1, 28, 100, 100]               0\n",
      "           Conv2d-60         [-1, 10, 100, 100]           7,000\n",
      "       conv_layer-61         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 38, 100, 100]              76\n",
      "             ReLU-63         [-1, 38, 100, 100]               0\n",
      "           Conv2d-64         [-1, 10, 100, 100]           9,500\n",
      "       conv_layer-65         [-1, 48, 100, 100]               0\n",
      "      Dense_block-66         [-1, 48, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 48, 100, 100]              96\n",
      "             ReLU-68         [-1, 48, 100, 100]               0\n",
      "           Conv2d-69         [-1, 24, 100, 100]           1,152\n",
      "      BatchNorm2d-70         [-1, 24, 100, 100]              48\n",
      "             ReLU-71         [-1, 24, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 24, 200, 200]          14,400\n",
      "    Encode_Decode-73         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 28, 200, 200]              56\n",
      "             ReLU-75         [-1, 28, 200, 200]               0\n",
      "           Conv2d-76         [-1, 10, 200, 200]           7,000\n",
      "       conv_layer-77         [-1, 38, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 38, 200, 200]              76\n",
      "             ReLU-79         [-1, 38, 200, 200]               0\n",
      "           Conv2d-80         [-1, 10, 200, 200]           9,500\n",
      "       conv_layer-81         [-1, 48, 200, 200]               0\n",
      "      Dense_block-82         [-1, 48, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 48, 200, 200]              96\n",
      "             ReLU-84         [-1, 48, 200, 200]               0\n",
      "           Conv2d-85         [-1, 24, 200, 200]           1,152\n",
      "      BatchNorm2d-86         [-1, 24, 200, 200]              48\n",
      "             ReLU-87         [-1, 24, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             384\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 127,440\n",
      "Trainable params: 127,440\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 295.10\n",
      "Params size (MB): 0.49\n",
      "Estimated Total Size (MB): 296.20\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             100\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             125\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             150\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             175\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             400\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             100\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             125\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,734\n",
      "Trainable params: 2,734\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 54.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]          15,876\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           8,820\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]          13,720\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]          17,689\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           9,310\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]          14,210\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]          19,110\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          24,010\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          41,209\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 29, 25, 25]              58\n",
      "             ReLU-91           [-1, 29, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]          14,210\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]          19,110\n",
      "       conv_layer-97           [-1, 49, 25, 25]               0\n",
      "      Dense_block-98           [-1, 49, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 49, 25, 25]              98\n",
      "            ReLU-100           [-1, 49, 25, 25]               0\n",
      "          Conv2d-101           [-1, 24, 25, 25]           1,176\n",
      "     BatchNorm2d-102           [-1, 24, 25, 25]              48\n",
      "            ReLU-103           [-1, 24, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 24, 50, 50]          28,224\n",
      "   Encode_Decode-105           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 40, 50, 50]              80\n",
      "            ReLU-107           [-1, 40, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          19,600\n",
      "      conv_layer-109           [-1, 50, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 50, 50, 50]             100\n",
      "            ReLU-111           [-1, 50, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          24,500\n",
      "      conv_layer-113           [-1, 60, 50, 50]               0\n",
      "     Dense_block-114           [-1, 60, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 60, 50, 50]             120\n",
      "            ReLU-116           [-1, 60, 50, 50]               0\n",
      "          Conv2d-117           [-1, 30, 50, 50]           1,800\n",
      "     BatchNorm2d-118           [-1, 30, 50, 50]              60\n",
      "            ReLU-119           [-1, 30, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 30, 100, 100]          44,100\n",
      "   Encode_Decode-121         [-1, 30, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]          20,580\n",
      "      conv_layer-125         [-1, 52, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 52, 100, 100]             104\n",
      "            ReLU-127         [-1, 52, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          25,480\n",
      "      conv_layer-129         [-1, 62, 100, 100]               0\n",
      "     Dense_block-130         [-1, 62, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 62, 100, 100]             124\n",
      "            ReLU-132         [-1, 62, 100, 100]               0\n",
      "          Conv2d-133         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-134         [-1, 31, 100, 100]              62\n",
      "            ReLU-135         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 31, 200, 200]          47,089\n",
      "   Encode_Decode-137         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 31, 200, 200]              62\n",
      "            ReLU-139         [-1, 31, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]          15,190\n",
      "      conv_layer-141         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 41, 200, 200]              82\n",
      "            ReLU-143         [-1, 41, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]          20,090\n",
      "      conv_layer-145         [-1, 51, 200, 200]               0\n",
      "     Dense_block-146         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 51, 200, 200]             102\n",
      "            ReLU-148         [-1, 51, 200, 200]               0\n",
      "          Conv2d-149         [-1, 25, 200, 200]           1,275\n",
      "     BatchNorm2d-150         [-1, 25, 200, 200]              50\n",
      "            ReLU-151         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             400\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 520,815\n",
      "Trainable params: 520,815\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 330.20\n",
      "Params size (MB): 1.99\n",
      "Estimated Total Size (MB): 332.80\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             100\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              50\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              75\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             100\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             125\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             225\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             125\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             150\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             225\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             125\n",
      "      conv_layer-109            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 6, 50, 50]              12\n",
      "            ReLU-111            [-1, 6, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             150\n",
      "      conv_layer-113            [-1, 7, 50, 50]               0\n",
      "     Dense_block-114            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 7, 50, 50]              14\n",
      "            ReLU-116            [-1, 7, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              21\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             225\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             150\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             175\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 8, 200, 200]              16\n",
      "            ReLU-139          [-1, 8, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             200\n",
      "      conv_layer-141          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 9, 200, 200]              18\n",
      "            ReLU-143          [-1, 9, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             225\n",
      "      conv_layer-145         [-1, 10, 200, 200]               0\n",
      "     Dense_block-146         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 10, 200, 200]              20\n",
      "            ReLU-148         [-1, 10, 200, 200]               0\n",
      "          Conv2d-149          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-150          [-1, 5, 200, 200]              10\n",
      "            ReLU-151          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              80\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 4,662\n",
      "Trainable params: 4,662\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.60\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 68.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             600\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           1,500\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           1,600\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           1,200\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           2,100\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           2,500\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           1,500\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           2,400\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           3,025\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           1,650\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           2,550\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           3,450\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           4,350\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 27, 50, 50]              54\n",
      "             ReLU-75           [-1, 27, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]           4,050\n",
      "       conv_layer-77           [-1, 33, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 33, 50, 50]              66\n",
      "             ReLU-79           [-1, 33, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           4,950\n",
      "       conv_layer-81           [-1, 39, 50, 50]               0\n",
      "      Dense_block-82           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 39, 50, 50]              78\n",
      "             ReLU-84           [-1, 39, 50, 50]               0\n",
      "           Conv2d-85           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-86           [-1, 19, 50, 50]              38\n",
      "             ReLU-87           [-1, 19, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 19, 100, 100]           9,025\n",
      "    Encode_Decode-89         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 27, 100, 100]              54\n",
      "             ReLU-91         [-1, 27, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           4,050\n",
      "       conv_layer-93         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 33, 100, 100]              66\n",
      "             ReLU-95         [-1, 33, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           4,950\n",
      "       conv_layer-97         [-1, 39, 100, 100]               0\n",
      "      Dense_block-98         [-1, 39, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 39, 100, 100]              78\n",
      "            ReLU-100         [-1, 39, 100, 100]               0\n",
      "          Conv2d-101         [-1, 19, 100, 100]             741\n",
      "     BatchNorm2d-102         [-1, 19, 100, 100]              38\n",
      "            ReLU-103         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 19, 200, 200]           9,025\n",
      "   Encode_Decode-105         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 23, 200, 200]              46\n",
      "            ReLU-107         [-1, 23, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           3,450\n",
      "      conv_layer-109         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 29, 200, 200]              58\n",
      "            ReLU-111         [-1, 29, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           4,350\n",
      "      conv_layer-113         [-1, 35, 200, 200]               0\n",
      "     Dense_block-114         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 35, 200, 200]              70\n",
      "            ReLU-116         [-1, 35, 200, 200]               0\n",
      "          Conv2d-117         [-1, 17, 200, 200]             595\n",
      "     BatchNorm2d-118         [-1, 17, 200, 200]              34\n",
      "            ReLU-119         [-1, 17, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             272\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 84,400\n",
      "Trainable params: 84,400\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 220.90\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 221.83\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 6\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           3,564\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]          13,365\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]          13,689\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]          11,583\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          21,384\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          23,409\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]          15,147\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          24,948\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          29,241\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          16,929\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          26,730\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          32,400\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]          17,820\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]          27,621\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          37,422\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          47,223\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          82,944\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]          28,512\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          38,313\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          59,049\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          39,204\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          49,005\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          88,209\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 33, 100, 100]              66\n",
      "            ReLU-123         [-1, 33, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          29,403\n",
      "      conv_layer-125         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 44, 100, 100]              88\n",
      "            ReLU-127         [-1, 44, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          39,204\n",
      "      conv_layer-129         [-1, 55, 100, 100]               0\n",
      "     Dense_block-130         [-1, 55, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 55, 100, 100]             110\n",
      "            ReLU-132         [-1, 55, 100, 100]               0\n",
      "          Conv2d-133         [-1, 27, 100, 100]           1,485\n",
      "     BatchNorm2d-134         [-1, 27, 100, 100]              54\n",
      "            ReLU-135         [-1, 27, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 27, 200, 200]          59,049\n",
      "   Encode_Decode-137         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 27, 200, 200]              54\n",
      "            ReLU-139         [-1, 27, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          24,057\n",
      "      conv_layer-141         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 38, 200, 200]              76\n",
      "            ReLU-143         [-1, 38, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          33,858\n",
      "      conv_layer-145         [-1, 49, 200, 200]               0\n",
      "     Dense_block-146         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 49, 200, 200]              98\n",
      "            ReLU-148         [-1, 49, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,176\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 947,155\n",
      "Trainable params: 947,155\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 323.33\n",
      "Params size (MB): 3.61\n",
      "Estimated Total Size (MB): 327.55\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           4,230\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           5,130\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]           9,801\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           4,410\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           5,310\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          10,404\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           4,140\n",
      "      conv_layer-125         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 56, 100, 100]             112\n",
      "            ReLU-127         [-1, 56, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           5,040\n",
      "      conv_layer-129         [-1, 66, 100, 100]               0\n",
      "     Dense_block-130         [-1, 66, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 66, 100, 100]             132\n",
      "            ReLU-132         [-1, 66, 100, 100]               0\n",
      "          Conv2d-133         [-1, 33, 100, 100]           2,178\n",
      "     BatchNorm2d-134         [-1, 33, 100, 100]              66\n",
      "            ReLU-135         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 33, 200, 200]           9,801\n",
      "   Encode_Decode-137         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 37, 200, 200]              74\n",
      "            ReLU-139         [-1, 37, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           3,330\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           4,230\n",
      "      conv_layer-145         [-1, 57, 200, 200]               0\n",
      "     Dense_block-146         [-1, 57, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 57, 200, 200]             114\n",
      "            ReLU-148         [-1, 57, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,596\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 123,492\n",
      "Trainable params: 123,492\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 357.48\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 358.56\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]           4,059\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]           5,148\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]           8,649\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           3,069\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]           4,158\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]           6,084\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]           3,861\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]           4,950\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]           8,100\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 30, 200, 200]              60\n",
      "            ReLU-107         [-1, 30, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           2,970\n",
      "      conv_layer-109         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 41, 200, 200]              82\n",
      "            ReLU-111         [-1, 41, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]           4,059\n",
      "      conv_layer-113         [-1, 52, 200, 200]               0\n",
      "     Dense_block-114         [-1, 52, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 52, 200, 200]             104\n",
      "            ReLU-116         [-1, 52, 200, 200]               0\n",
      "          Conv2d-117         [-1, 26, 200, 200]           1,352\n",
      "     BatchNorm2d-118         [-1, 26, 200, 200]              52\n",
      "            ReLU-119         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             416\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 88,009\n",
      "Trainable params: 88,009\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 334.65\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 335.60\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           7,225\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           3,825\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           5,850\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           7,875\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           9,900\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          16,900\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           9,450\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          11,475\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]          22,500\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           9,900\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          11,925\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]          24,025\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           9,450\n",
      "      conv_layer-125         [-1, 51, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 51, 100, 100]             102\n",
      "            ReLU-127         [-1, 51, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          11,475\n",
      "      conv_layer-129         [-1, 60, 100, 100]               0\n",
      "     Dense_block-130         [-1, 60, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 60, 100, 100]             120\n",
      "            ReLU-132         [-1, 60, 100, 100]               0\n",
      "          Conv2d-133         [-1, 30, 100, 100]           1,800\n",
      "     BatchNorm2d-134         [-1, 30, 100, 100]              60\n",
      "            ReLU-135         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 30, 200, 200]          22,500\n",
      "   Encode_Decode-137         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           6,750\n",
      "      conv_layer-141         [-1, 39, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 39, 200, 200]              78\n",
      "            ReLU-143         [-1, 39, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           8,775\n",
      "      conv_layer-145         [-1, 48, 200, 200]               0\n",
      "     Dense_block-146         [-1, 48, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 48, 200, 200]              96\n",
      "            ReLU-148         [-1, 48, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,152\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 255,191\n",
      "Trainable params: 255,191\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 313.91\n",
      "Params size (MB): 0.97\n",
      "Estimated Total Size (MB): 315.50\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 38, 100, 100]              76\n",
      "             ReLU-91         [-1, 38, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          11,400\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          15,000\n",
      "       conv_layer-97         [-1, 62, 100, 100]               0\n",
      "      Dense_block-98         [-1, 62, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 62, 100, 100]             124\n",
      "            ReLU-100         [-1, 62, 100, 100]               0\n",
      "          Conv2d-101         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-102         [-1, 31, 100, 100]              62\n",
      "            ReLU-103         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 31, 200, 200]          24,025\n",
      "   Encode_Decode-105         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 35, 200, 200]              70\n",
      "            ReLU-107         [-1, 35, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]          10,500\n",
      "      conv_layer-109         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 47, 200, 200]              94\n",
      "            ReLU-111         [-1, 47, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          14,100\n",
      "      conv_layer-113         [-1, 59, 200, 200]               0\n",
      "     Dense_block-114         [-1, 59, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 59, 200, 200]             118\n",
      "            ReLU-116         [-1, 59, 200, 200]               0\n",
      "          Conv2d-117         [-1, 29, 200, 200]           1,711\n",
      "     BatchNorm2d-118         [-1, 29, 200, 200]              58\n",
      "            ReLU-119         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             464\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 293,937\n",
      "Trainable params: 293,937\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 371.24\n",
      "Params size (MB): 1.12\n",
      "Estimated Total Size (MB): 372.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           2,916\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           9,477\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           8,019\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]          14,580\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]          15,876\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]          10,206\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          16,767\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          20,736\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]          11,664\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          18,225\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          23,409\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]          12,393\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          18,954\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          25,515\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          32,076\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          54,756\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          30,618\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          37,179\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]          72,900\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          32,076\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          38,637\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]          77,841\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          30,618\n",
      "      conv_layer-125         [-1, 51, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 51, 100, 100]             102\n",
      "            ReLU-127         [-1, 51, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          37,179\n",
      "      conv_layer-129         [-1, 60, 100, 100]               0\n",
      "     Dense_block-130         [-1, 60, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 60, 100, 100]             120\n",
      "            ReLU-132         [-1, 60, 100, 100]               0\n",
      "          Conv2d-133         [-1, 30, 100, 100]           1,800\n",
      "     BatchNorm2d-134         [-1, 30, 100, 100]              60\n",
      "            ReLU-135         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 30, 200, 200]          72,900\n",
      "   Encode_Decode-137         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          21,870\n",
      "      conv_layer-141         [-1, 39, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 39, 200, 200]              78\n",
      "            ReLU-143         [-1, 39, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          28,431\n",
      "      conv_layer-145         [-1, 48, 200, 200]               0\n",
      "     Dense_block-146         [-1, 48, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 48, 200, 200]              96\n",
      "            ReLU-148         [-1, 48, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,152\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 798,335\n",
      "Trainable params: 798,335\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 313.91\n",
      "Params size (MB): 3.05\n",
      "Estimated Total Size (MB): 317.57\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 6, 200, 200]              12\n",
      "             ReLU-75          [-1, 6, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              54\n",
      "       conv_layer-77          [-1, 7, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 7, 200, 200]              14\n",
      "             ReLU-79          [-1, 7, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              63\n",
      "       conv_layer-81          [-1, 8, 200, 200]               0\n",
      "      Dense_block-82          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 8, 200, 200]              16\n",
      "             ReLU-84          [-1, 8, 200, 200]               0\n",
      "           Conv2d-85          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-86          [-1, 4, 200, 200]               8\n",
      "             ReLU-87          [-1, 4, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              64\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,168\n",
      "Trainable params: 1,168\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 56.17\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 56.79\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             500\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           1,125\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             875\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           1,500\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           1,600\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,000\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           1,625\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           2,025\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           1,125\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           1,750\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]           2,375\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           3,000\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 22, 50, 50]              44\n",
      "             ReLU-75           [-1, 22, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]           2,750\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]           3,375\n",
      "       conv_layer-81           [-1, 32, 50, 50]               0\n",
      "      Dense_block-82           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 32, 50, 50]              64\n",
      "             ReLU-84           [-1, 32, 50, 50]               0\n",
      "           Conv2d-85           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-86           [-1, 16, 50, 50]              32\n",
      "             ReLU-87           [-1, 16, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 16, 100, 100]           6,400\n",
      "    Encode_Decode-89         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 23, 100, 100]              46\n",
      "             ReLU-91         [-1, 23, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]           2,875\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           3,500\n",
      "       conv_layer-97         [-1, 33, 100, 100]               0\n",
      "      Dense_block-98         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 33, 100, 100]              66\n",
      "            ReLU-100         [-1, 33, 100, 100]               0\n",
      "          Conv2d-101         [-1, 16, 100, 100]             528\n",
      "     BatchNorm2d-102         [-1, 16, 100, 100]              32\n",
      "            ReLU-103         [-1, 16, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 16, 200, 200]           6,400\n",
      "   Encode_Decode-105         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 16, 200, 200]              32\n",
      "            ReLU-107         [-1, 16, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]           2,000\n",
      "      conv_layer-109         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 21, 200, 200]              42\n",
      "            ReLU-111         [-1, 21, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]           2,625\n",
      "      conv_layer-113         [-1, 26, 200, 200]               0\n",
      "     Dense_block-114         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 26, 200, 200]              52\n",
      "            ReLU-116         [-1, 26, 200, 200]               0\n",
      "          Conv2d-117         [-1, 13, 200, 200]             338\n",
      "     BatchNorm2d-118         [-1, 13, 200, 200]              26\n",
      "            ReLU-119         [-1, 13, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             208\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 58,098\n",
      "Trainable params: 58,098\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 177.60\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 178.43\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 5\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             100\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              50\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              75\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             100\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             125\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             225\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              75\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             100\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             100\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 2, 50, 50]               4\n",
      "            ReLU-107            [-1, 2, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              50\n",
      "      conv_layer-109            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 3, 50, 50]               6\n",
      "            ReLU-111            [-1, 3, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]              75\n",
      "      conv_layer-113            [-1, 4, 50, 50]               0\n",
      "     Dense_block-114            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 4, 50, 50]               8\n",
      "            ReLU-116            [-1, 4, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]               8\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]             100\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 2, 100, 100]               4\n",
      "            ReLU-123          [-1, 2, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              50\n",
      "      conv_layer-125          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 3, 100, 100]               6\n",
      "            ReLU-127          [-1, 3, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]              75\n",
      "      conv_layer-129          [-1, 4, 100, 100]               0\n",
      "     Dense_block-130          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 4, 100, 100]               8\n",
      "            ReLU-132          [-1, 4, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 2, 200, 200]               4\n",
      "            ReLU-139          [-1, 2, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              50\n",
      "      conv_layer-141          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 3, 200, 200]               6\n",
      "            ReLU-143          [-1, 3, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              75\n",
      "      conv_layer-145          [-1, 4, 200, 200]               0\n",
      "     Dense_block-146          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 4, 200, 200]               8\n",
      "            ReLU-148          [-1, 4, 200, 200]               0\n",
      "          Conv2d-149          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-150          [-1, 2, 200, 200]               4\n",
      "            ReLU-151          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              32\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,120\n",
      "Trainable params: 3,120\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.08\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 43.70\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |      99 |      15 |  0.008036765 |            f\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           3,168\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           4,257\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]           6,561\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           4,356\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           5,445\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]           9,801\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 33, 100, 100]              66\n",
      "            ReLU-123         [-1, 33, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           3,267\n",
      "      conv_layer-125         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 44, 100, 100]              88\n",
      "            ReLU-127         [-1, 44, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           4,356\n",
      "      conv_layer-129         [-1, 55, 100, 100]               0\n",
      "     Dense_block-130         [-1, 55, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 55, 100, 100]             110\n",
      "            ReLU-132         [-1, 55, 100, 100]               0\n",
      "          Conv2d-133         [-1, 27, 100, 100]           1,485\n",
      "     BatchNorm2d-134         [-1, 27, 100, 100]              54\n",
      "            ReLU-135         [-1, 27, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 27, 200, 200]           6,561\n",
      "   Encode_Decode-137         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 27, 200, 200]              54\n",
      "            ReLU-139         [-1, 27, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           2,673\n",
      "      conv_layer-141         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 38, 200, 200]              76\n",
      "            ReLU-143         [-1, 38, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           3,762\n",
      "      conv_layer-145         [-1, 49, 200, 200]               0\n",
      "     Dense_block-146         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 49, 200, 200]              98\n",
      "            ReLU-148         [-1, 49, 200, 200]               0\n",
      "          Conv2d-149         [-1, 24, 200, 200]           1,176\n",
      "     BatchNorm2d-150         [-1, 24, 200, 200]              48\n",
      "            ReLU-151         [-1, 24, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             384\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 117,571\n",
      "Trainable params: 117,571\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 323.33\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 324.39\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             500\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           1,125\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             875\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           1,500\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           1,600\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,000\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           1,625\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           2,025\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           1,125\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           1,750\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      Dense_block-58           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 19, 25, 25]              38\n",
      "             ReLU-60           [-1, 19, 25, 25]               0\n",
      "           Conv2d-61            [-1, 9, 25, 25]             171\n",
      "      BatchNorm2d-62            [-1, 9, 25, 25]              18\n",
      "             ReLU-63            [-1, 9, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 13, 13]           2,025\n",
      "    Encode_Decode-65            [-1, 9, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 9, 13, 13]              18\n",
      "             ReLU-67            [-1, 9, 13, 13]               0\n",
      "           Conv2d-68            [-1, 5, 13, 13]           1,125\n",
      "       conv_layer-69           [-1, 14, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 14, 13, 13]              28\n",
      "             ReLU-71           [-1, 14, 13, 13]               0\n",
      "           Conv2d-72            [-1, 5, 13, 13]           1,750\n",
      "       conv_layer-73           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 19, 13, 13]              38\n",
      "             ReLU-75           [-1, 19, 13, 13]               0\n",
      "           Conv2d-76            [-1, 5, 13, 13]           2,375\n",
      "       conv_layer-77           [-1, 24, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 24, 13, 13]              48\n",
      "             ReLU-79           [-1, 24, 13, 13]               0\n",
      "           Conv2d-80            [-1, 5, 13, 13]           3,000\n",
      "       conv_layer-81           [-1, 29, 13, 13]               0\n",
      "      Dense_block-82           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 29, 13, 13]              58\n",
      "             ReLU-84           [-1, 29, 13, 13]               0\n",
      "           Conv2d-85           [-1, 14, 13, 13]             406\n",
      "      BatchNorm2d-86           [-1, 14, 13, 13]              28\n",
      "             ReLU-87           [-1, 14, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 14, 25, 25]           4,900\n",
      "    Encode_Decode-89           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 14, 25, 25]              28\n",
      "             ReLU-91           [-1, 14, 25, 25]               0\n",
      "           Conv2d-92            [-1, 5, 25, 25]           1,750\n",
      "       conv_layer-93           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 19, 25, 25]              38\n",
      "             ReLU-95           [-1, 19, 25, 25]               0\n",
      "           Conv2d-96            [-1, 5, 25, 25]           2,375\n",
      "       conv_layer-97           [-1, 24, 25, 25]               0\n",
      "      Dense_block-98           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 24, 25, 25]              48\n",
      "            ReLU-100           [-1, 24, 25, 25]               0\n",
      "          Conv2d-101           [-1, 12, 25, 25]             288\n",
      "     BatchNorm2d-102           [-1, 12, 25, 25]              24\n",
      "            ReLU-103           [-1, 12, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 12, 50, 50]           3,600\n",
      "   Encode_Decode-105           [-1, 12, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 20, 50, 50]              40\n",
      "            ReLU-107           [-1, 20, 50, 50]               0\n",
      "          Conv2d-108            [-1, 5, 50, 50]           2,500\n",
      "      conv_layer-109           [-1, 25, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 25, 50, 50]              50\n",
      "            ReLU-111           [-1, 25, 50, 50]               0\n",
      "          Conv2d-112            [-1, 5, 50, 50]           3,125\n",
      "      conv_layer-113           [-1, 30, 50, 50]               0\n",
      "     Dense_block-114           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 30, 50, 50]              60\n",
      "            ReLU-116           [-1, 30, 50, 50]               0\n",
      "          Conv2d-117           [-1, 15, 50, 50]             450\n",
      "     BatchNorm2d-118           [-1, 15, 50, 50]              30\n",
      "            ReLU-119           [-1, 15, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 15, 100, 100]           5,625\n",
      "   Encode_Decode-121         [-1, 15, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 15, 100, 100]              30\n",
      "            ReLU-123         [-1, 15, 100, 100]               0\n",
      "          Conv2d-124          [-1, 5, 100, 100]           1,875\n",
      "      conv_layer-125         [-1, 20, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 20, 100, 100]              40\n",
      "            ReLU-127         [-1, 20, 100, 100]               0\n",
      "          Conv2d-128          [-1, 5, 100, 100]           2,500\n",
      "      conv_layer-129         [-1, 25, 100, 100]               0\n",
      "     Dense_block-130         [-1, 25, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 25, 100, 100]              50\n",
      "            ReLU-132         [-1, 25, 100, 100]               0\n",
      "          Conv2d-133         [-1, 12, 100, 100]             300\n",
      "     BatchNorm2d-134         [-1, 12, 100, 100]              24\n",
      "            ReLU-135         [-1, 12, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 12, 200, 200]           3,600\n",
      "   Encode_Decode-137         [-1, 12, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 16, 200, 200]              32\n",
      "            ReLU-139         [-1, 16, 200, 200]               0\n",
      "          Conv2d-140          [-1, 5, 200, 200]           2,000\n",
      "      conv_layer-141         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 21, 200, 200]              42\n",
      "            ReLU-143         [-1, 21, 200, 200]               0\n",
      "          Conv2d-144          [-1, 5, 200, 200]           2,625\n",
      "      conv_layer-145         [-1, 26, 200, 200]               0\n",
      "     Dense_block-146         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 26, 200, 200]              52\n",
      "            ReLU-148         [-1, 26, 200, 200]               0\n",
      "          Conv2d-149         [-1, 13, 200, 200]             338\n",
      "     BatchNorm2d-150         [-1, 13, 200, 200]              26\n",
      "            ReLU-151         [-1, 13, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             208\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 64,987\n",
      "Trainable params: 64,987\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 168.91\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 169.76\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]           4,059\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]           5,148\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]           8,649\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           4,752\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]           5,841\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          11,025\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]           4,752\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]           5,841\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          11,025\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 39, 200, 200]              78\n",
      "            ReLU-107         [-1, 39, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           3,861\n",
      "      conv_layer-109         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 50, 200, 200]             100\n",
      "            ReLU-111         [-1, 50, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]           4,950\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 105,285\n",
      "Trainable params: 105,285\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 378.22\n",
      "Params size (MB): 0.40\n",
      "Estimated Total Size (MB): 379.23\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      Dense_block-42           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 15, 50, 50]              30\n",
      "             ReLU-44           [-1, 15, 50, 50]               0\n",
      "           Conv2d-45            [-1, 7, 50, 50]             105\n",
      "      BatchNorm2d-46            [-1, 7, 50, 50]              14\n",
      "             ReLU-47            [-1, 7, 50, 50]               0\n",
      "           Conv2d-48            [-1, 7, 25, 25]           3,969\n",
      "    Encode_Decode-49            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 7, 25, 25]              14\n",
      "             ReLU-51            [-1, 7, 25, 25]               0\n",
      "           Conv2d-52            [-1, 4, 25, 25]           2,268\n",
      "       conv_layer-53           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 11, 25, 25]              22\n",
      "             ReLU-55           [-1, 11, 25, 25]               0\n",
      "           Conv2d-56            [-1, 4, 25, 25]           3,564\n",
      "       conv_layer-57           [-1, 15, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 15, 25, 25]              30\n",
      "             ReLU-59           [-1, 15, 25, 25]               0\n",
      "           Conv2d-60            [-1, 4, 25, 25]           4,860\n",
      "       conv_layer-61           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 25, 25]           6,156\n",
      "       conv_layer-65           [-1, 23, 25, 25]               0\n",
      "      Dense_block-66           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 23, 25, 25]              46\n",
      "             ReLU-68           [-1, 23, 25, 25]               0\n",
      "           Conv2d-69           [-1, 11, 25, 25]             253\n",
      "      BatchNorm2d-70           [-1, 11, 25, 25]              22\n",
      "             ReLU-71           [-1, 11, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 11, 50, 50]           9,801\n",
      "    Encode_Decode-73           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 18, 50, 50]              36\n",
      "             ReLU-75           [-1, 18, 50, 50]               0\n",
      "           Conv2d-76            [-1, 4, 50, 50]           5,832\n",
      "       conv_layer-77           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 22, 50, 50]              44\n",
      "             ReLU-79           [-1, 22, 50, 50]               0\n",
      "           Conv2d-80            [-1, 4, 50, 50]           7,128\n",
      "       conv_layer-81           [-1, 26, 50, 50]               0\n",
      "      Dense_block-82           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 26, 50, 50]              52\n",
      "             ReLU-84           [-1, 26, 50, 50]               0\n",
      "           Conv2d-85           [-1, 13, 50, 50]             338\n",
      "      BatchNorm2d-86           [-1, 13, 50, 50]              26\n",
      "             ReLU-87           [-1, 13, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 13, 100, 100]          13,689\n",
      "    Encode_Decode-89         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 19, 100, 100]              38\n",
      "             ReLU-91         [-1, 19, 100, 100]               0\n",
      "           Conv2d-92          [-1, 4, 100, 100]           6,156\n",
      "       conv_layer-93         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 23, 100, 100]              46\n",
      "             ReLU-95         [-1, 23, 100, 100]               0\n",
      "           Conv2d-96          [-1, 4, 100, 100]           7,452\n",
      "       conv_layer-97         [-1, 27, 100, 100]               0\n",
      "      Dense_block-98         [-1, 27, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 27, 100, 100]              54\n",
      "            ReLU-100         [-1, 27, 100, 100]               0\n",
      "          Conv2d-101         [-1, 13, 100, 100]             351\n",
      "     BatchNorm2d-102         [-1, 13, 100, 100]              26\n",
      "            ReLU-103         [-1, 13, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 13, 200, 200]          13,689\n",
      "   Encode_Decode-105         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 13, 200, 200]              26\n",
      "            ReLU-107         [-1, 13, 200, 200]               0\n",
      "          Conv2d-108          [-1, 4, 200, 200]           4,212\n",
      "      conv_layer-109         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 17, 200, 200]              34\n",
      "            ReLU-111         [-1, 17, 200, 200]               0\n",
      "          Conv2d-112          [-1, 4, 200, 200]           5,508\n",
      "      conv_layer-113         [-1, 21, 200, 200]               0\n",
      "     Dense_block-114         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 21, 200, 200]              42\n",
      "            ReLU-116         [-1, 21, 200, 200]               0\n",
      "          Conv2d-117         [-1, 10, 200, 200]             210\n",
      "     BatchNorm2d-118         [-1, 10, 200, 200]              20\n",
      "            ReLU-119         [-1, 10, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             160\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 118,634\n",
      "Trainable params: 118,634\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 146.81\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 147.87\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 29, 25, 25]              58\n",
      "             ReLU-91           [-1, 29, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           2,610\n",
      "       conv_layer-93           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 39, 25, 25]              78\n",
      "             ReLU-95           [-1, 39, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           3,510\n",
      "       conv_layer-97           [-1, 49, 25, 25]               0\n",
      "      Dense_block-98           [-1, 49, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 49, 25, 25]              98\n",
      "            ReLU-100           [-1, 49, 25, 25]               0\n",
      "          Conv2d-101           [-1, 24, 25, 25]           1,176\n",
      "     BatchNorm2d-102           [-1, 24, 25, 25]              48\n",
      "            ReLU-103           [-1, 24, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 24, 50, 50]           5,184\n",
      "   Encode_Decode-105           [-1, 24, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 40, 50, 50]              80\n",
      "            ReLU-107           [-1, 40, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           3,600\n",
      "      conv_layer-109           [-1, 50, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 50, 50, 50]             100\n",
      "            ReLU-111           [-1, 50, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           4,500\n",
      "      conv_layer-113           [-1, 60, 50, 50]               0\n",
      "     Dense_block-114           [-1, 60, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 60, 50, 50]             120\n",
      "            ReLU-116           [-1, 60, 50, 50]               0\n",
      "          Conv2d-117           [-1, 30, 50, 50]           1,800\n",
      "     BatchNorm2d-118           [-1, 30, 50, 50]              60\n",
      "            ReLU-119           [-1, 30, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 30, 100, 100]           8,100\n",
      "   Encode_Decode-121         [-1, 30, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           3,780\n",
      "      conv_layer-125         [-1, 52, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 52, 100, 100]             104\n",
      "            ReLU-127         [-1, 52, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           4,680\n",
      "      conv_layer-129         [-1, 62, 100, 100]               0\n",
      "     Dense_block-130         [-1, 62, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 62, 100, 100]             124\n",
      "            ReLU-132         [-1, 62, 100, 100]               0\n",
      "          Conv2d-133         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-134         [-1, 31, 100, 100]              62\n",
      "            ReLU-135         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 31, 200, 200]           8,649\n",
      "   Encode_Decode-137         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 35, 200, 200]              70\n",
      "            ReLU-139         [-1, 35, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           3,150\n",
      "      conv_layer-141         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 45, 200, 200]              90\n",
      "            ReLU-143         [-1, 45, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           4,050\n",
      "      conv_layer-145         [-1, 55, 200, 200]               0\n",
      "     Dense_block-146         [-1, 55, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 55, 200, 200]             110\n",
      "            ReLU-148         [-1, 55, 200, 200]               0\n",
      "          Conv2d-149         [-1, 27, 200, 200]           1,485\n",
      "     BatchNorm2d-150         [-1, 27, 200, 200]              54\n",
      "            ReLU-151         [-1, 27, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             432\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 107,285\n",
      "Trainable params: 107,285\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 343.02\n",
      "Params size (MB): 0.41\n",
      "Estimated Total Size (MB): 344.04\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           3,168\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           4,257\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]           6,561\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           4,356\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           5,445\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]           9,801\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,554\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           5,643\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          10,404\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 38, 200, 200]              76\n",
      "            ReLU-139         [-1, 38, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,762\n",
      "      conv_layer-141         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 49, 200, 200]              98\n",
      "            ReLU-143         [-1, 49, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           4,851\n",
      "      conv_layer-145         [-1, 60, 200, 200]               0\n",
      "     Dense_block-146         [-1, 60, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 60, 200, 200]             120\n",
      "            ReLU-148         [-1, 60, 200, 200]               0\n",
      "          Conv2d-149         [-1, 30, 200, 200]           1,800\n",
      "     BatchNorm2d-150         [-1, 30, 200, 200]              60\n",
      "            ReLU-151         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             480\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 127,883\n",
      "Trainable params: 127,883\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 373.84\n",
      "Params size (MB): 0.49\n",
      "Estimated Total Size (MB): 374.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 20, 25, 25]              40\n",
      "             ReLU-91           [-1, 20, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]           6,860\n",
      "       conv_layer-93           [-1, 27, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 27, 25, 25]              54\n",
      "             ReLU-95           [-1, 27, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]           9,261\n",
      "       conv_layer-97           [-1, 34, 25, 25]               0\n",
      "      Dense_block-98           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 34, 25, 25]              68\n",
      "            ReLU-100           [-1, 34, 25, 25]               0\n",
      "          Conv2d-101           [-1, 17, 25, 25]             578\n",
      "     BatchNorm2d-102           [-1, 17, 25, 25]              34\n",
      "            ReLU-103           [-1, 17, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 17, 50, 50]          14,161\n",
      "   Encode_Decode-105           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 28, 50, 50]              56\n",
      "            ReLU-107           [-1, 28, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]           9,604\n",
      "      conv_layer-109           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 35, 50, 50]              70\n",
      "            ReLU-111           [-1, 35, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          12,005\n",
      "      conv_layer-113           [-1, 42, 50, 50]               0\n",
      "     Dense_block-114           [-1, 42, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 42, 50, 50]              84\n",
      "            ReLU-116           [-1, 42, 50, 50]               0\n",
      "          Conv2d-117           [-1, 21, 50, 50]             882\n",
      "     BatchNorm2d-118           [-1, 21, 50, 50]              42\n",
      "            ReLU-119           [-1, 21, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 21, 100, 100]          21,609\n",
      "   Encode_Decode-121         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 21, 100, 100]              42\n",
      "            ReLU-123         [-1, 21, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]           7,203\n",
      "      conv_layer-125         [-1, 28, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 28, 100, 100]              56\n",
      "            ReLU-127         [-1, 28, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]           9,604\n",
      "      conv_layer-129         [-1, 35, 100, 100]               0\n",
      "     Dense_block-130         [-1, 35, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 35, 100, 100]              70\n",
      "            ReLU-132         [-1, 35, 100, 100]               0\n",
      "          Conv2d-133         [-1, 17, 100, 100]             595\n",
      "     BatchNorm2d-134         [-1, 17, 100, 100]              34\n",
      "            ReLU-135         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 17, 200, 200]          14,161\n",
      "   Encode_Decode-137         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 21, 200, 200]              42\n",
      "            ReLU-139         [-1, 21, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           7,203\n",
      "      conv_layer-141         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 28, 200, 200]              56\n",
      "            ReLU-143         [-1, 28, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]           9,604\n",
      "      conv_layer-145         [-1, 35, 200, 200]               0\n",
      "     Dense_block-146         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 35, 200, 200]              70\n",
      "            ReLU-148         [-1, 35, 200, 200]               0\n",
      "          Conv2d-149         [-1, 17, 200, 200]             595\n",
      "     BatchNorm2d-150         [-1, 17, 200, 200]              34\n",
      "            ReLU-151         [-1, 17, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             272\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 239,227\n",
      "Trainable params: 239,227\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 224.32\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 225.85\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              36\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              45\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,294\n",
      "Trainable params: 1,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 54.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 2, 100, 100]               4\n",
      "             ReLU-91          [-1, 2, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              50\n",
      "       conv_layer-93          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 3, 100, 100]               6\n",
      "             ReLU-95          [-1, 3, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              75\n",
      "       conv_layer-97          [-1, 4, 100, 100]               0\n",
      "      Dense_block-98          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 4, 100, 100]               8\n",
      "            ReLU-100          [-1, 4, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 2, 200, 200]               4\n",
      "            ReLU-107          [-1, 2, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              50\n",
      "      conv_layer-109          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 3, 200, 200]               6\n",
      "            ReLU-111          [-1, 3, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              75\n",
      "      conv_layer-113          [-1, 4, 200, 200]               0\n",
      "     Dense_block-114          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 4, 200, 200]               8\n",
      "            ReLU-116          [-1, 4, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,610\n",
      "Trainable params: 2,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.13\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 43.75\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 8, 50, 50]              16\n",
      "             ReLU-43            [-1, 8, 50, 50]               0\n",
      "           Conv2d-44            [-1, 2, 50, 50]             400\n",
      "       conv_layer-45           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 10, 50, 50]              20\n",
      "             ReLU-47           [-1, 10, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 50, 50]             500\n",
      "       conv_layer-49           [-1, 12, 50, 50]               0\n",
      "      Dense_block-50           [-1, 12, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 12, 50, 50]              24\n",
      "             ReLU-52           [-1, 12, 50, 50]               0\n",
      "           Conv2d-53            [-1, 6, 50, 50]              72\n",
      "      BatchNorm2d-54            [-1, 6, 50, 50]              12\n",
      "             ReLU-55            [-1, 6, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 6, 100, 100]             900\n",
      "    Encode_Decode-57          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 10, 100, 100]              20\n",
      "             ReLU-59         [-1, 10, 100, 100]               0\n",
      "           Conv2d-60          [-1, 2, 100, 100]             500\n",
      "       conv_layer-61         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 12, 100, 100]              24\n",
      "             ReLU-63         [-1, 12, 100, 100]               0\n",
      "           Conv2d-64          [-1, 2, 100, 100]             600\n",
      "       conv_layer-65         [-1, 14, 100, 100]               0\n",
      "      Dense_block-66         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 14, 100, 100]              28\n",
      "             ReLU-68         [-1, 14, 100, 100]               0\n",
      "           Conv2d-69          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-70          [-1, 7, 100, 100]              14\n",
      "             ReLU-71          [-1, 7, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 7, 200, 200]           1,225\n",
      "    Encode_Decode-73          [-1, 7, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 11, 200, 200]              22\n",
      "             ReLU-75         [-1, 11, 200, 200]               0\n",
      "           Conv2d-76          [-1, 2, 200, 200]             550\n",
      "       conv_layer-77         [-1, 13, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 13, 200, 200]              26\n",
      "             ReLU-79         [-1, 13, 200, 200]               0\n",
      "           Conv2d-80          [-1, 2, 200, 200]             650\n",
      "       conv_layer-81         [-1, 15, 200, 200]               0\n",
      "      Dense_block-82         [-1, 15, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 15, 200, 200]              30\n",
      "             ReLU-84         [-1, 15, 200, 200]               0\n",
      "           Conv2d-85          [-1, 7, 200, 200]             105\n",
      "      BatchNorm2d-86          [-1, 7, 200, 200]              14\n",
      "             ReLU-87          [-1, 7, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             112\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 8,578\n",
      "Trainable params: 8,578\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 95.79\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 96.43\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              72\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              81\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,458\n",
      "Trainable params: 1,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 66.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             147\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             196\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             196\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 2, 50, 50]               4\n",
      "            ReLU-107            [-1, 2, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              98\n",
      "      conv_layer-109            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 3, 50, 50]               6\n",
      "            ReLU-111            [-1, 3, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             147\n",
      "      conv_layer-113            [-1, 4, 50, 50]               0\n",
      "     Dense_block-114            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 4, 50, 50]               8\n",
      "            ReLU-116            [-1, 4, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]               8\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]             196\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 5, 100, 100]              10\n",
      "            ReLU-123          [-1, 5, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             245\n",
      "      conv_layer-125          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 6, 100, 100]              12\n",
      "            ReLU-127          [-1, 6, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             294\n",
      "      conv_layer-129          [-1, 7, 100, 100]               0\n",
      "     Dense_block-130          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 7, 100, 100]              14\n",
      "            ReLU-132          [-1, 7, 100, 100]               0\n",
      "          Conv2d-133          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-134          [-1, 3, 100, 100]               6\n",
      "            ReLU-135          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 3, 200, 200]             441\n",
      "   Encode_Decode-137          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 3, 200, 200]               6\n",
      "            ReLU-139          [-1, 3, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             147\n",
      "      conv_layer-141          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 4, 200, 200]               8\n",
      "            ReLU-143          [-1, 4, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             196\n",
      "      conv_layer-145          [-1, 5, 200, 200]               0\n",
      "     Dense_block-146          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 5, 200, 200]              10\n",
      "            ReLU-148          [-1, 5, 200, 200]               0\n",
      "          Conv2d-149          [-1, 2, 200, 200]              10\n",
      "     BatchNorm2d-150          [-1, 2, 200, 200]               4\n",
      "            ReLU-151          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              32\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 6,294\n",
      "Trainable params: 6,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 48.73\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 49.36\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 7, 200, 200]              14\n",
      "            ReLU-107          [-1, 7, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             175\n",
      "      conv_layer-109          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 8, 200, 200]              16\n",
      "            ReLU-111          [-1, 8, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             200\n",
      "      conv_layer-113          [-1, 9, 200, 200]               0\n",
      "     Dense_block-114          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 9, 200, 200]              18\n",
      "            ReLU-116          [-1, 9, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,262\n",
      "Trainable params: 3,262\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 61.59\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 62.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          10,000\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           5,500\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           8,525\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          11,550\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          14,575\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          25,600\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           8,800\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          11,825\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          18,225\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          12,100\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          15,125\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          27,225\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 33, 100, 100]              66\n",
      "            ReLU-123         [-1, 33, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           9,075\n",
      "      conv_layer-125         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 44, 100, 100]              88\n",
      "            ReLU-127         [-1, 44, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          12,100\n",
      "      conv_layer-129         [-1, 55, 100, 100]               0\n",
      "     Dense_block-130         [-1, 55, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 55, 100, 100]             110\n",
      "            ReLU-132         [-1, 55, 100, 100]               0\n",
      "          Conv2d-133         [-1, 27, 100, 100]           1,485\n",
      "     BatchNorm2d-134         [-1, 27, 100, 100]              54\n",
      "            ReLU-135         [-1, 27, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 27, 200, 200]          18,225\n",
      "   Encode_Decode-137         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 31, 200, 200]              62\n",
      "            ReLU-139         [-1, 31, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           8,525\n",
      "      conv_layer-141         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 42, 200, 200]              84\n",
      "            ReLU-143         [-1, 42, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          11,550\n",
      "      conv_layer-145         [-1, 53, 200, 200]               0\n",
      "     Dense_block-146         [-1, 53, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 53, 200, 200]             106\n",
      "            ReLU-148         [-1, 53, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,378\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 304,385\n",
      "Trainable params: 304,385\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 336.15\n",
      "Params size (MB): 1.16\n",
      "Estimated Total Size (MB): 337.92\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 38, 25, 25]              76\n",
      "             ReLU-59           [-1, 38, 25, 25]               0\n",
      "           Conv2d-60           [-1, 10, 25, 25]           3,420\n",
      "       conv_layer-61           [-1, 48, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 48, 25, 25]              96\n",
      "             ReLU-63           [-1, 48, 25, 25]               0\n",
      "           Conv2d-64           [-1, 10, 25, 25]           4,320\n",
      "       conv_layer-65           [-1, 58, 25, 25]               0\n",
      "      Dense_block-66           [-1, 58, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 58, 25, 25]             116\n",
      "             ReLU-68           [-1, 58, 25, 25]               0\n",
      "           Conv2d-69           [-1, 29, 25, 25]           1,682\n",
      "      BatchNorm2d-70           [-1, 29, 25, 25]              58\n",
      "             ReLU-71           [-1, 29, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 29, 50, 50]           7,569\n",
      "    Encode_Decode-73           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 45, 50, 50]              90\n",
      "             ReLU-75           [-1, 45, 50, 50]               0\n",
      "           Conv2d-76           [-1, 10, 50, 50]           4,050\n",
      "       conv_layer-77           [-1, 55, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 55, 50, 50]             110\n",
      "             ReLU-79           [-1, 55, 50, 50]               0\n",
      "           Conv2d-80           [-1, 10, 50, 50]           4,950\n",
      "       conv_layer-81           [-1, 65, 50, 50]               0\n",
      "      Dense_block-82           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 65, 50, 50]             130\n",
      "             ReLU-84           [-1, 65, 50, 50]               0\n",
      "           Conv2d-85           [-1, 32, 50, 50]           2,080\n",
      "      BatchNorm2d-86           [-1, 32, 50, 50]              64\n",
      "             ReLU-87           [-1, 32, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 32, 100, 100]           9,216\n",
      "    Encode_Decode-89         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 44, 100, 100]              88\n",
      "             ReLU-91         [-1, 44, 100, 100]               0\n",
      "           Conv2d-92         [-1, 10, 100, 100]           3,960\n",
      "       conv_layer-93         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 54, 100, 100]             108\n",
      "             ReLU-95         [-1, 54, 100, 100]               0\n",
      "           Conv2d-96         [-1, 10, 100, 100]           4,860\n",
      "       conv_layer-97         [-1, 64, 100, 100]               0\n",
      "      Dense_block-98         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 64, 100, 100]             128\n",
      "            ReLU-100         [-1, 64, 100, 100]               0\n",
      "          Conv2d-101         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-102         [-1, 32, 100, 100]              64\n",
      "            ReLU-103         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 32, 200, 200]           9,216\n",
      "   Encode_Decode-105         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 36, 200, 200]              72\n",
      "            ReLU-107         [-1, 36, 200, 200]               0\n",
      "          Conv2d-108         [-1, 10, 200, 200]           3,240\n",
      "      conv_layer-109         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 46, 200, 200]              92\n",
      "            ReLU-111         [-1, 46, 200, 200]               0\n",
      "          Conv2d-112         [-1, 10, 200, 200]           4,140\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 89,491\n",
      "Trainable params: 89,491\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 348.71\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 349.66\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 3, 200, 200]               6\n",
      "            ReLU-107          [-1, 3, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              75\n",
      "      conv_layer-109          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 4, 200, 200]               8\n",
      "            ReLU-111          [-1, 4, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             100\n",
      "      conv_layer-113          [-1, 5, 200, 200]               0\n",
      "     Dense_block-114          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 5, 200, 200]              10\n",
      "            ReLU-116          [-1, 5, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]              10\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,976\n",
      "Trainable params: 2,976\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 48.78\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 49.40\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             147\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             196\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             196\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             196\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             245\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             441\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             294\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             343\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             784\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             196\n",
      "      conv_layer-141          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 5, 200, 200]              10\n",
      "            ReLU-143          [-1, 5, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             245\n",
      "      conv_layer-145          [-1, 6, 200, 200]               0\n",
      "     Dense_block-146          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 6, 200, 200]              12\n",
      "            ReLU-148          [-1, 6, 200, 200]               0\n",
      "          Conv2d-149          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-150          [-1, 3, 200, 200]               6\n",
      "            ReLU-151          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              48\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 7,349\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.47\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 55.11\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          14,161\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           7,497\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          11,466\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          15,435\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          19,404\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          33,124\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          11,466\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          15,435\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          23,716\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          15,876\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          19,845\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          35,721\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 38, 100, 100]              76\n",
      "            ReLU-123         [-1, 38, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          16,758\n",
      "      conv_layer-125         [-1, 47, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 47, 100, 100]              94\n",
      "            ReLU-127         [-1, 47, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          20,727\n",
      "      conv_layer-129         [-1, 56, 100, 100]               0\n",
      "     Dense_block-130         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 56, 100, 100]             112\n",
      "            ReLU-132         [-1, 56, 100, 100]               0\n",
      "          Conv2d-133         [-1, 28, 100, 100]           1,568\n",
      "     BatchNorm2d-134         [-1, 28, 100, 100]              56\n",
      "            ReLU-135         [-1, 28, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 28, 200, 200]          38,416\n",
      "   Encode_Decode-137         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 28, 200, 200]              56\n",
      "            ReLU-139         [-1, 28, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          12,348\n",
      "      conv_layer-141         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 37, 200, 200]              74\n",
      "            ReLU-143         [-1, 37, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          16,317\n",
      "      conv_layer-145         [-1, 46, 200, 200]               0\n",
      "     Dense_block-146         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 46, 200, 200]              92\n",
      "            ReLU-148         [-1, 46, 200, 200]               0\n",
      "          Conv2d-149         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-150         [-1, 23, 200, 200]              46\n",
      "            ReLU-151         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             368\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 422,223\n",
      "Trainable params: 422,223\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 299.76\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 301.98\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          13,200\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          16,225\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          30,625\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          13,200\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          16,225\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 39, 200, 200]              78\n",
      "            ReLU-107         [-1, 39, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]          10,725\n",
      "      conv_layer-109         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 50, 200, 200]             100\n",
      "            ReLU-111         [-1, 50, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          13,750\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 269,061\n",
      "Trainable params: 269,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 378.22\n",
      "Params size (MB): 1.03\n",
      "Estimated Total Size (MB): 379.85\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 6, 50, 50]              12\n",
      "             ReLU-75            [-1, 6, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             300\n",
      "       conv_layer-77            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 8, 50, 50]              16\n",
      "             ReLU-79            [-1, 8, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             400\n",
      "       conv_layer-81           [-1, 10, 50, 50]               0\n",
      "      Dense_block-82           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 10, 50, 50]              20\n",
      "             ReLU-84           [-1, 10, 50, 50]               0\n",
      "           Conv2d-85            [-1, 5, 50, 50]              50\n",
      "      BatchNorm2d-86            [-1, 5, 50, 50]              10\n",
      "             ReLU-87            [-1, 5, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 5, 100, 100]             625\n",
      "    Encode_Decode-89          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 9, 100, 100]              18\n",
      "             ReLU-91          [-1, 9, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             450\n",
      "       conv_layer-93         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 11, 100, 100]              22\n",
      "             ReLU-95         [-1, 11, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             550\n",
      "       conv_layer-97         [-1, 13, 100, 100]               0\n",
      "      Dense_block-98         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 13, 100, 100]              26\n",
      "            ReLU-100         [-1, 13, 100, 100]               0\n",
      "          Conv2d-101          [-1, 6, 100, 100]              78\n",
      "     BatchNorm2d-102          [-1, 6, 100, 100]              12\n",
      "            ReLU-103          [-1, 6, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 6, 200, 200]             900\n",
      "   Encode_Decode-105          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 6, 200, 200]              12\n",
      "            ReLU-107          [-1, 6, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             300\n",
      "      conv_layer-109          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 8, 200, 200]              16\n",
      "            ReLU-111          [-1, 8, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             400\n",
      "      conv_layer-113         [-1, 10, 200, 200]               0\n",
      "     Dense_block-114         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 10, 200, 200]              20\n",
      "            ReLU-116         [-1, 10, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 9,913\n",
      "Trainable params: 9,913\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 79.83\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 80.48\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |     119 |      18 |  0.007124120 |            f\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]              72\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             108\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             144\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]              72\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             108\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             144\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]              72\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             108\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             144\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]              72\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             108\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]             144\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]              72\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             108\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]             144\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]             180\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]             324\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 6, 25, 25]              12\n",
      "             ReLU-91            [-1, 6, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]             108\n",
      "       conv_layer-93            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 8, 25, 25]              16\n",
      "             ReLU-95            [-1, 8, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]             144\n",
      "       conv_layer-97           [-1, 10, 25, 25]               0\n",
      "      Dense_block-98           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 10, 25, 25]              20\n",
      "            ReLU-100           [-1, 10, 25, 25]               0\n",
      "          Conv2d-101            [-1, 5, 25, 25]              50\n",
      "     BatchNorm2d-102            [-1, 5, 25, 25]              10\n",
      "            ReLU-103            [-1, 5, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 5, 50, 50]             225\n",
      "   Encode_Decode-105            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 9, 50, 50]              18\n",
      "            ReLU-107            [-1, 9, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]             162\n",
      "      conv_layer-109           [-1, 11, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 11, 50, 50]              22\n",
      "            ReLU-111           [-1, 11, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]             198\n",
      "      conv_layer-113           [-1, 13, 50, 50]               0\n",
      "     Dense_block-114           [-1, 13, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 13, 50, 50]              26\n",
      "            ReLU-116           [-1, 13, 50, 50]               0\n",
      "          Conv2d-117            [-1, 6, 50, 50]              78\n",
      "     BatchNorm2d-118            [-1, 6, 50, 50]              12\n",
      "            ReLU-119            [-1, 6, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 6, 100, 100]             324\n",
      "   Encode_Decode-121          [-1, 6, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 10, 100, 100]              20\n",
      "            ReLU-123         [-1, 10, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]             180\n",
      "      conv_layer-125         [-1, 12, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 12, 100, 100]              24\n",
      "            ReLU-127         [-1, 12, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]             216\n",
      "      conv_layer-129         [-1, 14, 100, 100]               0\n",
      "     Dense_block-130         [-1, 14, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 14, 100, 100]              28\n",
      "            ReLU-132         [-1, 14, 100, 100]               0\n",
      "          Conv2d-133          [-1, 7, 100, 100]              98\n",
      "     BatchNorm2d-134          [-1, 7, 100, 100]              14\n",
      "            ReLU-135          [-1, 7, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 7, 200, 200]             441\n",
      "   Encode_Decode-137          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 11, 200, 200]              22\n",
      "            ReLU-139         [-1, 11, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]             198\n",
      "      conv_layer-141         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 13, 200, 200]              26\n",
      "            ReLU-143         [-1, 13, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]             234\n",
      "      conv_layer-145         [-1, 15, 200, 200]               0\n",
      "     Dense_block-146         [-1, 15, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 15, 200, 200]              30\n",
      "            ReLU-148         [-1, 15, 200, 200]               0\n",
      "          Conv2d-149          [-1, 7, 200, 200]             105\n",
      "     BatchNorm2d-150          [-1, 7, 200, 200]              14\n",
      "            ReLU-151          [-1, 7, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             112\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 5,923\n",
      "Trainable params: 5,923\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 97.95\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 98.58\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             150\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             175\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             100\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             125\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,552\n",
      "Trainable params: 3,552\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.14\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 7, 200, 200]              14\n",
      "            ReLU-107          [-1, 7, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             175\n",
      "      conv_layer-109          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 8, 200, 200]              16\n",
      "            ReLU-111          [-1, 8, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             200\n",
      "      conv_layer-113          [-1, 9, 200, 200]               0\n",
      "     Dense_block-114          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 9, 200, 200]              18\n",
      "            ReLU-116          [-1, 9, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,262\n",
      "Trainable params: 3,262\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 61.59\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 62.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             324\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           1,053\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           1,089\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]             891\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           1,620\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           1,764\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           1,134\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           1,863\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           2,304\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           1,296\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           2,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           2,601\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           1,377\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           2,106\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           2,835\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           3,564\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]           6,084\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 42, 25, 25]              84\n",
      "             ReLU-91           [-1, 42, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           3,402\n",
      "       conv_layer-93           [-1, 51, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 51, 25, 25]             102\n",
      "             ReLU-95           [-1, 51, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]           4,131\n",
      "       conv_layer-97           [-1, 60, 25, 25]               0\n",
      "      Dense_block-98           [-1, 60, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 60, 25, 25]             120\n",
      "            ReLU-100           [-1, 60, 25, 25]               0\n",
      "          Conv2d-101           [-1, 30, 25, 25]           1,800\n",
      "     BatchNorm2d-102           [-1, 30, 25, 25]              60\n",
      "            ReLU-103           [-1, 30, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 30, 50, 50]           8,100\n",
      "   Encode_Decode-105           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           3,564\n",
      "      conv_layer-109           [-1, 53, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 53, 50, 50]             106\n",
      "            ReLU-111           [-1, 53, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]           4,293\n",
      "      conv_layer-113           [-1, 62, 50, 50]               0\n",
      "     Dense_block-114           [-1, 62, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 62, 50, 50]             124\n",
      "            ReLU-116           [-1, 62, 50, 50]               0\n",
      "          Conv2d-117           [-1, 31, 50, 50]           1,922\n",
      "     BatchNorm2d-118           [-1, 31, 50, 50]              62\n",
      "            ReLU-119           [-1, 31, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 31, 100, 100]           8,649\n",
      "   Encode_Decode-121         [-1, 31, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 42, 100, 100]              84\n",
      "            ReLU-123         [-1, 42, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           3,402\n",
      "      conv_layer-125         [-1, 51, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 51, 100, 100]             102\n",
      "            ReLU-127         [-1, 51, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]           4,131\n",
      "      conv_layer-129         [-1, 60, 100, 100]               0\n",
      "     Dense_block-130         [-1, 60, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 60, 100, 100]             120\n",
      "            ReLU-132         [-1, 60, 100, 100]               0\n",
      "          Conv2d-133         [-1, 30, 100, 100]           1,800\n",
      "     BatchNorm2d-134         [-1, 30, 100, 100]              60\n",
      "            ReLU-135         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 30, 200, 200]           8,100\n",
      "   Encode_Decode-137         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           2,754\n",
      "      conv_layer-141         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 43, 200, 200]              86\n",
      "            ReLU-143         [-1, 43, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           3,483\n",
      "      conv_layer-145         [-1, 52, 200, 200]               0\n",
      "     Dense_block-146         [-1, 52, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 52, 200, 200]             104\n",
      "            ReLU-148         [-1, 52, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,352\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 100,915\n",
      "Trainable params: 100,915\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 326.73\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 327.73\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 2, 200, 200]               4\n",
      "             ReLU-75          [-1, 2, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              18\n",
      "       conv_layer-77          [-1, 3, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 3, 200, 200]               6\n",
      "             ReLU-79          [-1, 3, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              27\n",
      "       conv_layer-81          [-1, 4, 200, 200]               0\n",
      "      Dense_block-82          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 4, 200, 200]               8\n",
      "             ReLU-84          [-1, 4, 200, 200]               0\n",
      "           Conv2d-85          [-1, 2, 200, 200]               8\n",
      "      BatchNorm2d-86          [-1, 2, 200, 200]               4\n",
      "             ReLU-87          [-1, 2, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              32\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,012\n",
      "Trainable params: 1,012\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.35\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 43.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 2, 100, 100]               4\n",
      "             ReLU-91          [-1, 2, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              50\n",
      "       conv_layer-93          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 3, 100, 100]               6\n",
      "             ReLU-95          [-1, 3, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              75\n",
      "       conv_layer-97          [-1, 4, 100, 100]               0\n",
      "      Dense_block-98          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 4, 100, 100]               8\n",
      "            ReLU-100          [-1, 4, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 6, 200, 200]              12\n",
      "            ReLU-107          [-1, 6, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             150\n",
      "      conv_layer-109          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 7, 200, 200]              14\n",
      "            ReLU-111          [-1, 7, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             175\n",
      "      conv_layer-113          [-1, 8, 200, 200]               0\n",
      "     Dense_block-114          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 8, 200, 200]              16\n",
      "            ReLU-116          [-1, 8, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,894\n",
      "Trainable params: 2,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 55.95\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 56.57\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             180\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]             405\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             315\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]             540\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]             576\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]             360\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]             585\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]             729\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]             405\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]             630\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]             855\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           1,080\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           1,764\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 14, 50, 50]              28\n",
      "             ReLU-75           [-1, 14, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]             630\n",
      "       conv_layer-77           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 19, 50, 50]              38\n",
      "             ReLU-79           [-1, 19, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]             855\n",
      "       conv_layer-81           [-1, 24, 50, 50]               0\n",
      "      Dense_block-82           [-1, 24, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 24, 50, 50]              48\n",
      "             ReLU-84           [-1, 24, 50, 50]               0\n",
      "           Conv2d-85           [-1, 12, 50, 50]             288\n",
      "      BatchNorm2d-86           [-1, 12, 50, 50]              24\n",
      "             ReLU-87           [-1, 12, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-89         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 19, 100, 100]              38\n",
      "             ReLU-91         [-1, 19, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]             855\n",
      "       conv_layer-93         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 24, 100, 100]              48\n",
      "             ReLU-95         [-1, 24, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           1,080\n",
      "       conv_layer-97         [-1, 29, 100, 100]               0\n",
      "      Dense_block-98         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 29, 100, 100]              58\n",
      "            ReLU-100         [-1, 29, 100, 100]               0\n",
      "          Conv2d-101         [-1, 14, 100, 100]             406\n",
      "     BatchNorm2d-102         [-1, 14, 100, 100]              28\n",
      "            ReLU-103         [-1, 14, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 14, 200, 200]           1,764\n",
      "   Encode_Decode-105         [-1, 14, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 14, 200, 200]              28\n",
      "            ReLU-107         [-1, 14, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]             630\n",
      "      conv_layer-109         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 19, 200, 200]              38\n",
      "            ReLU-111         [-1, 19, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]             855\n",
      "      conv_layer-113         [-1, 24, 200, 200]               0\n",
      "     Dense_block-114         [-1, 24, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 24, 200, 200]              48\n",
      "            ReLU-116         [-1, 24, 200, 200]               0\n",
      "          Conv2d-117         [-1, 12, 200, 200]             288\n",
      "     BatchNorm2d-118         [-1, 12, 200, 200]              24\n",
      "            ReLU-119         [-1, 12, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             192\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 19,868\n",
      "Trainable params: 19,868\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 164.55\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 165.24\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          13,200\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          16,225\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          30,625\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          13,200\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          16,225\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          30,625\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 35, 200, 200]              70\n",
      "            ReLU-107         [-1, 35, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           9,625\n",
      "      conv_layer-109         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 46, 200, 200]              92\n",
      "            ReLU-111         [-1, 46, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          12,650\n",
      "      conv_layer-113         [-1, 57, 200, 200]               0\n",
      "     Dense_block-114         [-1, 57, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 57, 200, 200]             114\n",
      "            ReLU-116         [-1, 57, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,596\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 266,567\n",
      "Trainable params: 266,567\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 365.40\n",
      "Params size (MB): 1.02\n",
      "Estimated Total Size (MB): 367.03\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]           1,568\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           4,704\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           3,920\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           7,056\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           8,281\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           5,096\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           8,232\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           9,604\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           5,488\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           8,624\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]          11,025\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           5,880\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           9,016\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]          12,152\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]          15,288\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]          25,921\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 23, 25, 25]              46\n",
      "             ReLU-91           [-1, 23, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]           9,016\n",
      "       conv_layer-93           [-1, 31, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 31, 25, 25]              62\n",
      "             ReLU-95           [-1, 31, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]          12,152\n",
      "       conv_layer-97           [-1, 39, 25, 25]               0\n",
      "      Dense_block-98           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 39, 25, 25]              78\n",
      "            ReLU-100           [-1, 39, 25, 25]               0\n",
      "          Conv2d-101           [-1, 19, 25, 25]             741\n",
      "     BatchNorm2d-102           [-1, 19, 25, 25]              38\n",
      "            ReLU-103           [-1, 19, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 19, 50, 50]          17,689\n",
      "   Encode_Decode-105           [-1, 19, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 32, 50, 50]              64\n",
      "            ReLU-107           [-1, 32, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]          12,544\n",
      "      conv_layer-109           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 40, 50, 50]              80\n",
      "            ReLU-111           [-1, 40, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]          15,680\n",
      "      conv_layer-113           [-1, 48, 50, 50]               0\n",
      "     Dense_block-114           [-1, 48, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 48, 50, 50]              96\n",
      "            ReLU-116           [-1, 48, 50, 50]               0\n",
      "          Conv2d-117           [-1, 24, 50, 50]           1,152\n",
      "     BatchNorm2d-118           [-1, 24, 50, 50]              48\n",
      "            ReLU-119           [-1, 24, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 24, 100, 100]          28,224\n",
      "   Encode_Decode-121         [-1, 24, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 34, 100, 100]              68\n",
      "            ReLU-123         [-1, 34, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]          13,328\n",
      "      conv_layer-125         [-1, 42, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 42, 100, 100]              84\n",
      "            ReLU-127         [-1, 42, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]          16,464\n",
      "      conv_layer-129         [-1, 50, 100, 100]               0\n",
      "     Dense_block-130         [-1, 50, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 50, 100, 100]             100\n",
      "            ReLU-132         [-1, 50, 100, 100]               0\n",
      "          Conv2d-133         [-1, 25, 100, 100]           1,250\n",
      "     BatchNorm2d-134         [-1, 25, 100, 100]              50\n",
      "            ReLU-135         [-1, 25, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 25, 200, 200]          30,625\n",
      "   Encode_Decode-137         [-1, 25, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 29, 200, 200]              58\n",
      "            ReLU-139         [-1, 29, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]          11,368\n",
      "      conv_layer-141         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 37, 200, 200]              74\n",
      "            ReLU-143         [-1, 37, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]          14,504\n",
      "      conv_layer-145         [-1, 45, 200, 200]               0\n",
      "     Dense_block-146         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 45, 200, 200]              90\n",
      "            ReLU-148         [-1, 45, 200, 200]               0\n",
      "          Conv2d-149         [-1, 22, 200, 200]             990\n",
      "     BatchNorm2d-150         [-1, 22, 200, 200]              44\n",
      "            ReLU-151         [-1, 22, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             352\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 337,431\n",
      "Trainable params: 337,431\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 281.61\n",
      "Params size (MB): 1.29\n",
      "Estimated Total Size (MB): 283.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 6, 50, 50]              12\n",
      "             ReLU-75            [-1, 6, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             300\n",
      "       conv_layer-77            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 8, 50, 50]              16\n",
      "             ReLU-79            [-1, 8, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             400\n",
      "       conv_layer-81           [-1, 10, 50, 50]               0\n",
      "      Dense_block-82           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 10, 50, 50]              20\n",
      "             ReLU-84           [-1, 10, 50, 50]               0\n",
      "           Conv2d-85            [-1, 5, 50, 50]              50\n",
      "      BatchNorm2d-86            [-1, 5, 50, 50]              10\n",
      "             ReLU-87            [-1, 5, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 5, 100, 100]             625\n",
      "    Encode_Decode-89          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 9, 100, 100]              18\n",
      "             ReLU-91          [-1, 9, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             450\n",
      "       conv_layer-93         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 11, 100, 100]              22\n",
      "             ReLU-95         [-1, 11, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             550\n",
      "       conv_layer-97         [-1, 13, 100, 100]               0\n",
      "      Dense_block-98         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 13, 100, 100]              26\n",
      "            ReLU-100         [-1, 13, 100, 100]               0\n",
      "          Conv2d-101          [-1, 6, 100, 100]              78\n",
      "     BatchNorm2d-102          [-1, 6, 100, 100]              12\n",
      "            ReLU-103          [-1, 6, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 6, 200, 200]             900\n",
      "   Encode_Decode-105          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 10, 200, 200]              20\n",
      "            ReLU-107         [-1, 10, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             500\n",
      "      conv_layer-109         [-1, 12, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 12, 200, 200]              24\n",
      "            ReLU-111         [-1, 12, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             600\n",
      "      conv_layer-113         [-1, 14, 200, 200]               0\n",
      "     Dense_block-114         [-1, 14, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 14, 200, 200]              28\n",
      "            ReLU-116         [-1, 14, 200, 200]               0\n",
      "          Conv2d-117          [-1, 7, 200, 200]              98\n",
      "     BatchNorm2d-118          [-1, 7, 200, 200]              14\n",
      "            ReLU-119          [-1, 7, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             112\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 10,421\n",
      "Trainable params: 10,421\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 92.65\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 93.30\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 39, 50, 50]              78\n",
      "             ReLU-43           [-1, 39, 50, 50]               0\n",
      "           Conv2d-44           [-1, 11, 50, 50]           3,861\n",
      "       conv_layer-45           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 50, 50, 50]             100\n",
      "             ReLU-47           [-1, 50, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 50, 50]           4,950\n",
      "       conv_layer-49           [-1, 61, 50, 50]               0\n",
      "      Dense_block-50           [-1, 61, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 61, 50, 50]             122\n",
      "             ReLU-52           [-1, 61, 50, 50]               0\n",
      "           Conv2d-53           [-1, 30, 50, 50]           1,830\n",
      "      BatchNorm2d-54           [-1, 30, 50, 50]              60\n",
      "             ReLU-55           [-1, 30, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 30, 100, 100]           8,100\n",
      "    Encode_Decode-57         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 43, 100, 100]              86\n",
      "             ReLU-59         [-1, 43, 100, 100]               0\n",
      "           Conv2d-60         [-1, 11, 100, 100]           4,257\n",
      "       conv_layer-61         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 54, 100, 100]             108\n",
      "             ReLU-63         [-1, 54, 100, 100]               0\n",
      "           Conv2d-64         [-1, 11, 100, 100]           5,346\n",
      "       conv_layer-65         [-1, 65, 100, 100]               0\n",
      "      Dense_block-66         [-1, 65, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 65, 100, 100]             130\n",
      "             ReLU-68         [-1, 65, 100, 100]               0\n",
      "           Conv2d-69         [-1, 32, 100, 100]           2,080\n",
      "      BatchNorm2d-70         [-1, 32, 100, 100]              64\n",
      "             ReLU-71         [-1, 32, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 32, 200, 200]           9,216\n",
      "    Encode_Decode-73         [-1, 32, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 32, 200, 200]              64\n",
      "             ReLU-75         [-1, 32, 200, 200]               0\n",
      "           Conv2d-76         [-1, 11, 200, 200]           3,168\n",
      "       conv_layer-77         [-1, 43, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 43, 200, 200]              86\n",
      "             ReLU-79         [-1, 43, 200, 200]               0\n",
      "           Conv2d-80         [-1, 11, 200, 200]           4,257\n",
      "       conv_layer-81         [-1, 54, 200, 200]               0\n",
      "      Dense_block-82         [-1, 54, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 54, 200, 200]             108\n",
      "             ReLU-84         [-1, 54, 200, 200]               0\n",
      "           Conv2d-85         [-1, 27, 200, 200]           1,458\n",
      "      BatchNorm2d-86         [-1, 27, 200, 200]              54\n",
      "             ReLU-87         [-1, 27, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             432\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 65,597\n",
      "Trainable params: 65,597\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 339.22\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 340.08\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]             252\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]             693\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]             729\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]             567\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           1,008\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           1,089\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]             693\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           1,134\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           1,296\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]             756\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           1,197\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 26, 25, 25]              52\n",
      "             ReLU-59           [-1, 26, 25, 25]               0\n",
      "           Conv2d-60            [-1, 7, 25, 25]           1,638\n",
      "       conv_layer-61           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 33, 25, 25]              66\n",
      "             ReLU-63           [-1, 33, 25, 25]               0\n",
      "           Conv2d-64            [-1, 7, 25, 25]           2,079\n",
      "       conv_layer-65           [-1, 40, 25, 25]               0\n",
      "      Dense_block-66           [-1, 40, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 40, 25, 25]              80\n",
      "             ReLU-68           [-1, 40, 25, 25]               0\n",
      "           Conv2d-69           [-1, 20, 25, 25]             800\n",
      "      BatchNorm2d-70           [-1, 20, 25, 25]              40\n",
      "             ReLU-71           [-1, 20, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 20, 50, 50]           3,600\n",
      "    Encode_Decode-73           [-1, 20, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 20, 50, 50]              40\n",
      "             ReLU-75           [-1, 20, 50, 50]               0\n",
      "           Conv2d-76            [-1, 7, 50, 50]           1,260\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 7, 50, 50]           1,701\n",
      "       conv_layer-81           [-1, 34, 50, 50]               0\n",
      "      Dense_block-82           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 34, 50, 50]              68\n",
      "             ReLU-84           [-1, 34, 50, 50]               0\n",
      "           Conv2d-85           [-1, 17, 50, 50]             578\n",
      "      BatchNorm2d-86           [-1, 17, 50, 50]              34\n",
      "             ReLU-87           [-1, 17, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 17, 100, 100]           2,601\n",
      "    Encode_Decode-89         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 26, 100, 100]              52\n",
      "             ReLU-91         [-1, 26, 100, 100]               0\n",
      "           Conv2d-92          [-1, 7, 100, 100]           1,638\n",
      "       conv_layer-93         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 33, 100, 100]              66\n",
      "             ReLU-95         [-1, 33, 100, 100]               0\n",
      "           Conv2d-96          [-1, 7, 100, 100]           2,079\n",
      "       conv_layer-97         [-1, 40, 100, 100]               0\n",
      "      Dense_block-98         [-1, 40, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 40, 100, 100]              80\n",
      "            ReLU-100         [-1, 40, 100, 100]               0\n",
      "          Conv2d-101         [-1, 20, 100, 100]             800\n",
      "     BatchNorm2d-102         [-1, 20, 100, 100]              40\n",
      "            ReLU-103         [-1, 20, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 20, 200, 200]           3,600\n",
      "   Encode_Decode-105         [-1, 20, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 20, 200, 200]              40\n",
      "            ReLU-107         [-1, 20, 200, 200]               0\n",
      "          Conv2d-108          [-1, 7, 200, 200]           1,260\n",
      "      conv_layer-109         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 27, 200, 200]              54\n",
      "            ReLU-111         [-1, 27, 200, 200]               0\n",
      "          Conv2d-112          [-1, 7, 200, 200]           1,701\n",
      "      conv_layer-113         [-1, 34, 200, 200]               0\n",
      "     Dense_block-114         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 34, 200, 200]              68\n",
      "            ReLU-116         [-1, 34, 200, 200]               0\n",
      "          Conv2d-117         [-1, 17, 200, 200]             578\n",
      "     BatchNorm2d-118         [-1, 17, 200, 200]              34\n",
      "            ReLU-119         [-1, 17, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             272\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 37,722\n",
      "Trainable params: 37,722\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 224.28\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 225.03\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]              36\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              18\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              27\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]              36\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]              45\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]              81\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              27\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]              36\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]              36\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              36\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]              45\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]              81\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              54\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]              63\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             144\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 8, 200, 200]              16\n",
      "            ReLU-139          [-1, 8, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              72\n",
      "      conv_layer-141          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 9, 200, 200]              18\n",
      "            ReLU-143          [-1, 9, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              81\n",
      "      conv_layer-145         [-1, 10, 200, 200]               0\n",
      "     Dense_block-146         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 10, 200, 200]              20\n",
      "            ReLU-148         [-1, 10, 200, 200]               0\n",
      "          Conv2d-149          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-150          [-1, 5, 200, 200]              10\n",
      "            ReLU-151          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              80\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,033\n",
      "Trainable params: 2,033\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 67.29\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 67.90\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]           1,176\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           2,940\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           3,136\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           2,352\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           4,116\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           2,940\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           4,704\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           5,929\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           3,234\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           4,998\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      Dense_block-58           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 23, 25, 25]              46\n",
      "             ReLU-60           [-1, 23, 25, 25]               0\n",
      "           Conv2d-61           [-1, 11, 25, 25]             253\n",
      "      BatchNorm2d-62           [-1, 11, 25, 25]              22\n",
      "             ReLU-63           [-1, 11, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 13, 13]           5,929\n",
      "    Encode_Decode-65           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 11, 13, 13]              22\n",
      "             ReLU-67           [-1, 11, 13, 13]               0\n",
      "           Conv2d-68            [-1, 6, 13, 13]           3,234\n",
      "       conv_layer-69           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 17, 13, 13]              34\n",
      "             ReLU-71           [-1, 17, 13, 13]               0\n",
      "           Conv2d-72            [-1, 6, 13, 13]           4,998\n",
      "       conv_layer-73           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 23, 13, 13]              46\n",
      "             ReLU-75           [-1, 23, 13, 13]               0\n",
      "           Conv2d-76            [-1, 6, 13, 13]           6,762\n",
      "       conv_layer-77           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 29, 13, 13]              58\n",
      "             ReLU-79           [-1, 29, 13, 13]               0\n",
      "           Conv2d-80            [-1, 6, 13, 13]           8,526\n",
      "       conv_layer-81           [-1, 35, 13, 13]               0\n",
      "      Dense_block-82           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 35, 13, 13]              70\n",
      "             ReLU-84           [-1, 35, 13, 13]               0\n",
      "           Conv2d-85           [-1, 17, 13, 13]             595\n",
      "      BatchNorm2d-86           [-1, 17, 13, 13]              34\n",
      "             ReLU-87           [-1, 17, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 17, 25, 25]          14,161\n",
      "    Encode_Decode-89           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 17, 25, 25]              34\n",
      "             ReLU-91           [-1, 17, 25, 25]               0\n",
      "           Conv2d-92            [-1, 6, 25, 25]           4,998\n",
      "       conv_layer-93           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 23, 25, 25]              46\n",
      "             ReLU-95           [-1, 23, 25, 25]               0\n",
      "           Conv2d-96            [-1, 6, 25, 25]           6,762\n",
      "       conv_layer-97           [-1, 29, 25, 25]               0\n",
      "      Dense_block-98           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 29, 25, 25]              58\n",
      "            ReLU-100           [-1, 29, 25, 25]               0\n",
      "          Conv2d-101           [-1, 14, 25, 25]             406\n",
      "     BatchNorm2d-102           [-1, 14, 25, 25]              28\n",
      "            ReLU-103           [-1, 14, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 14, 50, 50]           9,604\n",
      "   Encode_Decode-105           [-1, 14, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 24, 50, 50]              48\n",
      "            ReLU-107           [-1, 24, 50, 50]               0\n",
      "          Conv2d-108            [-1, 6, 50, 50]           7,056\n",
      "      conv_layer-109           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 30, 50, 50]              60\n",
      "            ReLU-111           [-1, 30, 50, 50]               0\n",
      "          Conv2d-112            [-1, 6, 50, 50]           8,820\n",
      "      conv_layer-113           [-1, 36, 50, 50]               0\n",
      "     Dense_block-114           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 36, 50, 50]              72\n",
      "            ReLU-116           [-1, 36, 50, 50]               0\n",
      "          Conv2d-117           [-1, 18, 50, 50]             648\n",
      "     BatchNorm2d-118           [-1, 18, 50, 50]              36\n",
      "            ReLU-119           [-1, 18, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 18, 100, 100]          15,876\n",
      "   Encode_Decode-121         [-1, 18, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 26, 100, 100]              52\n",
      "            ReLU-123         [-1, 26, 100, 100]               0\n",
      "          Conv2d-124          [-1, 6, 100, 100]           7,644\n",
      "      conv_layer-125         [-1, 32, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 32, 100, 100]              64\n",
      "            ReLU-127         [-1, 32, 100, 100]               0\n",
      "          Conv2d-128          [-1, 6, 100, 100]           9,408\n",
      "      conv_layer-129         [-1, 38, 100, 100]               0\n",
      "     Dense_block-130         [-1, 38, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 38, 100, 100]              76\n",
      "            ReLU-132         [-1, 38, 100, 100]               0\n",
      "          Conv2d-133         [-1, 19, 100, 100]             722\n",
      "     BatchNorm2d-134         [-1, 19, 100, 100]              38\n",
      "            ReLU-135         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 19, 200, 200]          17,689\n",
      "   Encode_Decode-137         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 23, 200, 200]              46\n",
      "            ReLU-139         [-1, 23, 200, 200]               0\n",
      "          Conv2d-140          [-1, 6, 200, 200]           6,762\n",
      "      conv_layer-141         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 29, 200, 200]              58\n",
      "            ReLU-143         [-1, 29, 200, 200]               0\n",
      "          Conv2d-144          [-1, 6, 200, 200]           8,526\n",
      "      conv_layer-145         [-1, 35, 200, 200]               0\n",
      "     Dense_block-146         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 35, 200, 200]              70\n",
      "            ReLU-148         [-1, 35, 200, 200]               0\n",
      "          Conv2d-149         [-1, 17, 200, 200]             595\n",
      "     BatchNorm2d-150         [-1, 17, 200, 200]              34\n",
      "            ReLU-151         [-1, 17, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             272\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 192,891\n",
      "Trainable params: 192,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 220.32\n",
      "Params size (MB): 0.74\n",
      "Estimated Total Size (MB): 221.67\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      Dense_block-58            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 8, 25, 25]              16\n",
      "             ReLU-60            [-1, 8, 25, 25]               0\n",
      "           Conv2d-61            [-1, 4, 25, 25]              32\n",
      "      BatchNorm2d-62            [-1, 4, 25, 25]               8\n",
      "             ReLU-63            [-1, 4, 25, 25]               0\n",
      "           Conv2d-64            [-1, 4, 13, 13]             400\n",
      "    Encode_Decode-65            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 4, 13, 13]               8\n",
      "             ReLU-67            [-1, 4, 13, 13]               0\n",
      "           Conv2d-68            [-1, 2, 13, 13]             200\n",
      "       conv_layer-69            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 6, 13, 13]              12\n",
      "             ReLU-71            [-1, 6, 13, 13]               0\n",
      "           Conv2d-72            [-1, 2, 13, 13]             300\n",
      "       conv_layer-73            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 8, 13, 13]              16\n",
      "             ReLU-75            [-1, 8, 13, 13]               0\n",
      "           Conv2d-76            [-1, 2, 13, 13]             400\n",
      "       conv_layer-77           [-1, 10, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 10, 13, 13]              20\n",
      "             ReLU-79           [-1, 10, 13, 13]               0\n",
      "           Conv2d-80            [-1, 2, 13, 13]             500\n",
      "       conv_layer-81           [-1, 12, 13, 13]               0\n",
      "      Dense_block-82           [-1, 12, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 12, 13, 13]              24\n",
      "             ReLU-84           [-1, 12, 13, 13]               0\n",
      "           Conv2d-85            [-1, 6, 13, 13]              72\n",
      "      BatchNorm2d-86            [-1, 6, 13, 13]              12\n",
      "             ReLU-87            [-1, 6, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 6, 25, 25]             900\n",
      "    Encode_Decode-89            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 10, 25, 25]              20\n",
      "             ReLU-91           [-1, 10, 25, 25]               0\n",
      "           Conv2d-92            [-1, 2, 25, 25]             500\n",
      "       conv_layer-93           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 12, 25, 25]              24\n",
      "             ReLU-95           [-1, 12, 25, 25]               0\n",
      "           Conv2d-96            [-1, 2, 25, 25]             600\n",
      "       conv_layer-97           [-1, 14, 25, 25]               0\n",
      "      Dense_block-98           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 14, 25, 25]              28\n",
      "            ReLU-100           [-1, 14, 25, 25]               0\n",
      "          Conv2d-101            [-1, 7, 25, 25]              98\n",
      "     BatchNorm2d-102            [-1, 7, 25, 25]              14\n",
      "            ReLU-103            [-1, 7, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 7, 50, 50]           1,225\n",
      "   Encode_Decode-105            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 11, 50, 50]              22\n",
      "            ReLU-107           [-1, 11, 50, 50]               0\n",
      "          Conv2d-108            [-1, 2, 50, 50]             550\n",
      "      conv_layer-109           [-1, 13, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 13, 50, 50]              26\n",
      "            ReLU-111           [-1, 13, 50, 50]               0\n",
      "          Conv2d-112            [-1, 2, 50, 50]             650\n",
      "      conv_layer-113           [-1, 15, 50, 50]               0\n",
      "     Dense_block-114           [-1, 15, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 15, 50, 50]              30\n",
      "            ReLU-116           [-1, 15, 50, 50]               0\n",
      "          Conv2d-117            [-1, 7, 50, 50]             105\n",
      "     BatchNorm2d-118            [-1, 7, 50, 50]              14\n",
      "            ReLU-119            [-1, 7, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 7, 100, 100]           1,225\n",
      "   Encode_Decode-121          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 11, 100, 100]              22\n",
      "            ReLU-123         [-1, 11, 100, 100]               0\n",
      "          Conv2d-124          [-1, 2, 100, 100]             550\n",
      "      conv_layer-125         [-1, 13, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 13, 100, 100]              26\n",
      "            ReLU-127         [-1, 13, 100, 100]               0\n",
      "          Conv2d-128          [-1, 2, 100, 100]             650\n",
      "      conv_layer-129         [-1, 15, 100, 100]               0\n",
      "     Dense_block-130         [-1, 15, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 15, 100, 100]              30\n",
      "            ReLU-132         [-1, 15, 100, 100]               0\n",
      "          Conv2d-133          [-1, 7, 100, 100]             105\n",
      "     BatchNorm2d-134          [-1, 7, 100, 100]              14\n",
      "            ReLU-135          [-1, 7, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 7, 200, 200]           1,225\n",
      "   Encode_Decode-137          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 11, 200, 200]              22\n",
      "            ReLU-139         [-1, 11, 200, 200]               0\n",
      "          Conv2d-140          [-1, 2, 200, 200]             550\n",
      "      conv_layer-141         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 13, 200, 200]              26\n",
      "            ReLU-143         [-1, 13, 200, 200]               0\n",
      "          Conv2d-144          [-1, 2, 200, 200]             650\n",
      "      conv_layer-145         [-1, 15, 200, 200]               0\n",
      "     Dense_block-146         [-1, 15, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 15, 200, 200]              30\n",
      "            ReLU-148         [-1, 15, 200, 200]               0\n",
      "          Conv2d-149          [-1, 7, 200, 200]             105\n",
      "     BatchNorm2d-150          [-1, 7, 200, 200]              14\n",
      "            ReLU-151          [-1, 7, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             112\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 15,774\n",
      "Trainable params: 15,774\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 99.46\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 100.13\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             600\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           1,500\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           1,600\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           1,200\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           2,100\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           2,500\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           1,500\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           2,400\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 22, 50, 50]              44\n",
      "             ReLU-43           [-1, 22, 50, 50]               0\n",
      "           Conv2d-44            [-1, 6, 50, 50]           3,300\n",
      "       conv_layer-45           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 28, 50, 50]              56\n",
      "             ReLU-47           [-1, 28, 50, 50]               0\n",
      "           Conv2d-48            [-1, 6, 50, 50]           4,200\n",
      "       conv_layer-49           [-1, 34, 50, 50]               0\n",
      "      Dense_block-50           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 34, 50, 50]              68\n",
      "             ReLU-52           [-1, 34, 50, 50]               0\n",
      "           Conv2d-53           [-1, 17, 50, 50]             578\n",
      "      BatchNorm2d-54           [-1, 17, 50, 50]              34\n",
      "             ReLU-55           [-1, 17, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 17, 100, 100]           7,225\n",
      "    Encode_Decode-57         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 17, 100, 100]              34\n",
      "             ReLU-59         [-1, 17, 100, 100]               0\n",
      "           Conv2d-60          [-1, 6, 100, 100]           2,550\n",
      "       conv_layer-61         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 23, 100, 100]              46\n",
      "             ReLU-63         [-1, 23, 100, 100]               0\n",
      "           Conv2d-64          [-1, 6, 100, 100]           3,450\n",
      "       conv_layer-65         [-1, 29, 100, 100]               0\n",
      "      Dense_block-66         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 29, 100, 100]              58\n",
      "             ReLU-68         [-1, 29, 100, 100]               0\n",
      "           Conv2d-69         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-70         [-1, 14, 100, 100]              28\n",
      "             ReLU-71         [-1, 14, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 14, 200, 200]           4,900\n",
      "    Encode_Decode-73         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 18, 200, 200]              36\n",
      "             ReLU-75         [-1, 18, 200, 200]               0\n",
      "           Conv2d-76          [-1, 6, 200, 200]           2,700\n",
      "       conv_layer-77         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 24, 200, 200]              48\n",
      "             ReLU-79         [-1, 24, 200, 200]               0\n",
      "           Conv2d-80          [-1, 6, 200, 200]           3,600\n",
      "       conv_layer-81         [-1, 30, 200, 200]               0\n",
      "      Dense_block-82         [-1, 30, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 30, 200, 200]              60\n",
      "             ReLU-84         [-1, 30, 200, 200]               0\n",
      "           Conv2d-85         [-1, 15, 200, 200]             450\n",
      "      BatchNorm2d-86         [-1, 15, 200, 200]              30\n",
      "             ReLU-87         [-1, 15, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             240\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 48,245\n",
      "Trainable params: 48,245\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 188.24\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 189.03\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              27\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              36\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]              36\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 2, 100, 100]               4\n",
      "             ReLU-91          [-1, 2, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              18\n",
      "       conv_layer-93          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 3, 100, 100]               6\n",
      "             ReLU-95          [-1, 3, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              27\n",
      "       conv_layer-97          [-1, 4, 100, 100]               0\n",
      "      Dense_block-98          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 4, 100, 100]               8\n",
      "            ReLU-100          [-1, 4, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]              36\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 2, 200, 200]               4\n",
      "            ReLU-107          [-1, 2, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              18\n",
      "      conv_layer-109          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 3, 200, 200]               6\n",
      "            ReLU-111          [-1, 3, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              27\n",
      "      conv_layer-113          [-1, 4, 200, 200]               0\n",
      "     Dense_block-114          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 4, 200, 200]               8\n",
      "            ReLU-116          [-1, 4, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,234\n",
      "Trainable params: 1,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.13\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 43.74\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 38, 25, 25]              76\n",
      "             ReLU-59           [-1, 38, 25, 25]               0\n",
      "           Conv2d-60           [-1, 10, 25, 25]           3,420\n",
      "       conv_layer-61           [-1, 48, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 48, 25, 25]              96\n",
      "             ReLU-63           [-1, 48, 25, 25]               0\n",
      "           Conv2d-64           [-1, 10, 25, 25]           4,320\n",
      "       conv_layer-65           [-1, 58, 25, 25]               0\n",
      "      Dense_block-66           [-1, 58, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 58, 25, 25]             116\n",
      "             ReLU-68           [-1, 58, 25, 25]               0\n",
      "           Conv2d-69           [-1, 29, 25, 25]           1,682\n",
      "      BatchNorm2d-70           [-1, 29, 25, 25]              58\n",
      "             ReLU-71           [-1, 29, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 29, 50, 50]           7,569\n",
      "    Encode_Decode-73           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 45, 50, 50]              90\n",
      "             ReLU-75           [-1, 45, 50, 50]               0\n",
      "           Conv2d-76           [-1, 10, 50, 50]           4,050\n",
      "       conv_layer-77           [-1, 55, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 55, 50, 50]             110\n",
      "             ReLU-79           [-1, 55, 50, 50]               0\n",
      "           Conv2d-80           [-1, 10, 50, 50]           4,950\n",
      "       conv_layer-81           [-1, 65, 50, 50]               0\n",
      "      Dense_block-82           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 65, 50, 50]             130\n",
      "             ReLU-84           [-1, 65, 50, 50]               0\n",
      "           Conv2d-85           [-1, 32, 50, 50]           2,080\n",
      "      BatchNorm2d-86           [-1, 32, 50, 50]              64\n",
      "             ReLU-87           [-1, 32, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 32, 100, 100]           9,216\n",
      "    Encode_Decode-89         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 44, 100, 100]              88\n",
      "             ReLU-91         [-1, 44, 100, 100]               0\n",
      "           Conv2d-92         [-1, 10, 100, 100]           3,960\n",
      "       conv_layer-93         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 54, 100, 100]             108\n",
      "             ReLU-95         [-1, 54, 100, 100]               0\n",
      "           Conv2d-96         [-1, 10, 100, 100]           4,860\n",
      "       conv_layer-97         [-1, 64, 100, 100]               0\n",
      "      Dense_block-98         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 64, 100, 100]             128\n",
      "            ReLU-100         [-1, 64, 100, 100]               0\n",
      "          Conv2d-101         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-102         [-1, 32, 100, 100]              64\n",
      "            ReLU-103         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 32, 200, 200]           9,216\n",
      "   Encode_Decode-105         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 36, 200, 200]              72\n",
      "            ReLU-107         [-1, 36, 200, 200]               0\n",
      "          Conv2d-108         [-1, 10, 200, 200]           3,240\n",
      "      conv_layer-109         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 46, 200, 200]              92\n",
      "            ReLU-111         [-1, 46, 200, 200]               0\n",
      "          Conv2d-112         [-1, 10, 200, 200]           4,140\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 89,491\n",
      "Trainable params: 89,491\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 348.71\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 349.66\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             900\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           2,925\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           3,025\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           2,475\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           4,500\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           3,150\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           5,175\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           6,400\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           3,600\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           5,625\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           7,225\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           3,825\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           5,850\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           7,875\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           9,900\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          16,900\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           5,850\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]           7,875\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          12,100\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           8,100\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          10,125\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          18,225\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 38, 100, 100]              76\n",
      "            ReLU-123         [-1, 38, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           8,550\n",
      "      conv_layer-125         [-1, 47, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 47, 100, 100]              94\n",
      "            ReLU-127         [-1, 47, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          10,575\n",
      "      conv_layer-129         [-1, 56, 100, 100]               0\n",
      "     Dense_block-130         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 56, 100, 100]             112\n",
      "            ReLU-132         [-1, 56, 100, 100]               0\n",
      "          Conv2d-133         [-1, 28, 100, 100]           1,568\n",
      "     BatchNorm2d-134         [-1, 28, 100, 100]              56\n",
      "            ReLU-135         [-1, 28, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 28, 200, 200]          19,600\n",
      "   Encode_Decode-137         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 32, 200, 200]              64\n",
      "            ReLU-139         [-1, 32, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           7,200\n",
      "      conv_layer-141         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 41, 200, 200]              82\n",
      "            ReLU-143         [-1, 41, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           9,225\n",
      "      conv_layer-145         [-1, 50, 200, 200]               0\n",
      "     Dense_block-146         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 50, 200, 200]             100\n",
      "            ReLU-148         [-1, 50, 200, 200]               0\n",
      "          Conv2d-149         [-1, 25, 200, 200]           1,250\n",
      "     BatchNorm2d-150         [-1, 25, 200, 200]              50\n",
      "            ReLU-151         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             400\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 222,795\n",
      "Trainable params: 222,795\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 312.58\n",
      "Params size (MB): 0.85\n",
      "Estimated Total Size (MB): 314.04\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 3, 200, 200]             108\n",
      "        conv_layer-5          [-1, 7, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 7, 200, 200]              14\n",
      "              ReLU-7          [-1, 7, 200, 200]               0\n",
      "            Conv2d-8          [-1, 3, 200, 200]             189\n",
      "        conv_layer-9         [-1, 10, 200, 200]               0\n",
      "      Dense_block-10         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 10, 200, 200]              20\n",
      "             ReLU-12         [-1, 10, 200, 200]               0\n",
      "           Conv2d-13          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-14          [-1, 5, 200, 200]              10\n",
      "             ReLU-15          [-1, 5, 200, 200]               0\n",
      "           Conv2d-16          [-1, 5, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 5, 100, 100]              10\n",
      "             ReLU-19          [-1, 5, 100, 100]               0\n",
      "           Conv2d-20          [-1, 3, 100, 100]             135\n",
      "       conv_layer-21          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 8, 100, 100]              16\n",
      "             ReLU-23          [-1, 8, 100, 100]               0\n",
      "           Conv2d-24          [-1, 3, 100, 100]             216\n",
      "       conv_layer-25         [-1, 11, 100, 100]               0\n",
      "      Dense_block-26         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 11, 100, 100]              22\n",
      "             ReLU-28         [-1, 11, 100, 100]               0\n",
      "           Conv2d-29          [-1, 5, 100, 100]              55\n",
      "      BatchNorm2d-30          [-1, 5, 100, 100]              10\n",
      "             ReLU-31          [-1, 5, 100, 100]               0\n",
      "           Conv2d-32            [-1, 5, 50, 50]             225\n",
      "    Encode_Decode-33            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 5, 50, 50]              10\n",
      "             ReLU-35            [-1, 5, 50, 50]               0\n",
      "           Conv2d-36            [-1, 3, 50, 50]             135\n",
      "       conv_layer-37            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 8, 50, 50]              16\n",
      "             ReLU-39            [-1, 8, 50, 50]               0\n",
      "           Conv2d-40            [-1, 3, 50, 50]             216\n",
      "       conv_layer-41           [-1, 11, 50, 50]               0\n",
      "      Dense_block-42           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 11, 50, 50]              22\n",
      "             ReLU-44           [-1, 11, 50, 50]               0\n",
      "           Conv2d-45            [-1, 5, 50, 50]              55\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 25, 25]             225\n",
      "    Encode_Decode-49            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 5, 25, 25]              10\n",
      "             ReLU-51            [-1, 5, 25, 25]               0\n",
      "           Conv2d-52            [-1, 3, 25, 25]             135\n",
      "       conv_layer-53            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 8, 25, 25]              16\n",
      "             ReLU-55            [-1, 8, 25, 25]               0\n",
      "           Conv2d-56            [-1, 3, 25, 25]             216\n",
      "       conv_layer-57           [-1, 11, 25, 25]               0\n",
      "      Dense_block-58           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 11, 25, 25]              22\n",
      "             ReLU-60           [-1, 11, 25, 25]               0\n",
      "           Conv2d-61            [-1, 5, 25, 25]              55\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 13, 13]             225\n",
      "    Encode_Decode-65            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 5, 13, 13]              10\n",
      "             ReLU-67            [-1, 5, 13, 13]               0\n",
      "           Conv2d-68            [-1, 3, 13, 13]             135\n",
      "       conv_layer-69            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 8, 13, 13]              16\n",
      "             ReLU-71            [-1, 8, 13, 13]               0\n",
      "           Conv2d-72            [-1, 3, 13, 13]             216\n",
      "       conv_layer-73           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 11, 13, 13]              22\n",
      "             ReLU-75           [-1, 11, 13, 13]               0\n",
      "           Conv2d-76            [-1, 3, 13, 13]             297\n",
      "       conv_layer-77           [-1, 14, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 14, 13, 13]              28\n",
      "             ReLU-79           [-1, 14, 13, 13]               0\n",
      "           Conv2d-80            [-1, 3, 13, 13]             378\n",
      "       conv_layer-81           [-1, 17, 13, 13]               0\n",
      "      Dense_block-82           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 17, 13, 13]              34\n",
      "             ReLU-84           [-1, 17, 13, 13]               0\n",
      "           Conv2d-85            [-1, 8, 13, 13]             136\n",
      "      BatchNorm2d-86            [-1, 8, 13, 13]              16\n",
      "             ReLU-87            [-1, 8, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 8, 25, 25]             576\n",
      "    Encode_Decode-89            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 13, 25, 25]              26\n",
      "             ReLU-91           [-1, 13, 25, 25]               0\n",
      "           Conv2d-92            [-1, 3, 25, 25]             351\n",
      "       conv_layer-93           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 16, 25, 25]              32\n",
      "             ReLU-95           [-1, 16, 25, 25]               0\n",
      "           Conv2d-96            [-1, 3, 25, 25]             432\n",
      "       conv_layer-97           [-1, 19, 25, 25]               0\n",
      "      Dense_block-98           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 19, 25, 25]              38\n",
      "            ReLU-100           [-1, 19, 25, 25]               0\n",
      "          Conv2d-101            [-1, 9, 25, 25]             171\n",
      "     BatchNorm2d-102            [-1, 9, 25, 25]              18\n",
      "            ReLU-103            [-1, 9, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 9, 50, 50]             729\n",
      "   Encode_Decode-105            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 14, 50, 50]              28\n",
      "            ReLU-107           [-1, 14, 50, 50]               0\n",
      "          Conv2d-108            [-1, 3, 50, 50]             378\n",
      "      conv_layer-109           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 17, 50, 50]              34\n",
      "            ReLU-111           [-1, 17, 50, 50]               0\n",
      "          Conv2d-112            [-1, 3, 50, 50]             459\n",
      "      conv_layer-113           [-1, 20, 50, 50]               0\n",
      "     Dense_block-114           [-1, 20, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 20, 50, 50]              40\n",
      "            ReLU-116           [-1, 20, 50, 50]               0\n",
      "          Conv2d-117           [-1, 10, 50, 50]             200\n",
      "     BatchNorm2d-118           [-1, 10, 50, 50]              20\n",
      "            ReLU-119           [-1, 10, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 10, 100, 100]             900\n",
      "   Encode_Decode-121         [-1, 10, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 15, 100, 100]              30\n",
      "            ReLU-123         [-1, 15, 100, 100]               0\n",
      "          Conv2d-124          [-1, 3, 100, 100]             405\n",
      "      conv_layer-125         [-1, 18, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 18, 100, 100]              36\n",
      "            ReLU-127         [-1, 18, 100, 100]               0\n",
      "          Conv2d-128          [-1, 3, 100, 100]             486\n",
      "      conv_layer-129         [-1, 21, 100, 100]               0\n",
      "     Dense_block-130         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 21, 100, 100]              42\n",
      "            ReLU-132         [-1, 21, 100, 100]               0\n",
      "          Conv2d-133         [-1, 10, 100, 100]             210\n",
      "     BatchNorm2d-134         [-1, 10, 100, 100]              20\n",
      "            ReLU-135         [-1, 10, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 10, 200, 200]             900\n",
      "   Encode_Decode-137         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 10, 200, 200]              20\n",
      "            ReLU-139         [-1, 10, 200, 200]               0\n",
      "          Conv2d-140          [-1, 3, 200, 200]             270\n",
      "      conv_layer-141         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 13, 200, 200]              26\n",
      "            ReLU-143         [-1, 13, 200, 200]               0\n",
      "          Conv2d-144          [-1, 3, 200, 200]             351\n",
      "      conv_layer-145         [-1, 16, 200, 200]               0\n",
      "     Dense_block-146         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 16, 200, 200]              32\n",
      "            ReLU-148         [-1, 16, 200, 200]               0\n",
      "          Conv2d-149          [-1, 8, 200, 200]             128\n",
      "     BatchNorm2d-150          [-1, 8, 200, 200]              16\n",
      "            ReLU-151          [-1, 8, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             128\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 11,655\n",
      "Trainable params: 11,655\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 117.23\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 117.88\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 3\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 |     139 |      20 |  0.012510452 |        nadir\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              72\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              81\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,458\n",
      "Trainable params: 1,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 66.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 7, 200, 200]              14\n",
      "            ReLU-107          [-1, 7, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             175\n",
      "      conv_layer-109          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 8, 200, 200]              16\n",
      "            ReLU-111          [-1, 8, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             200\n",
      "      conv_layer-113          [-1, 9, 200, 200]               0\n",
      "     Dense_block-114          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 9, 200, 200]              18\n",
      "            ReLU-116          [-1, 9, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              36\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,262\n",
      "Trainable params: 3,262\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 61.59\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 62.22\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 6, 200, 200]              12\n",
      "             ReLU-75          [-1, 6, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              54\n",
      "       conv_layer-77          [-1, 7, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 7, 200, 200]              14\n",
      "             ReLU-79          [-1, 7, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              63\n",
      "       conv_layer-81          [-1, 8, 200, 200]               0\n",
      "      Dense_block-82          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 8, 200, 200]              16\n",
      "             ReLU-84          [-1, 8, 200, 200]               0\n",
      "           Conv2d-85          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-86          [-1, 4, 200, 200]               8\n",
      "             ReLU-87          [-1, 4, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              64\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,168\n",
      "Trainable params: 1,168\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 56.17\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 56.79\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 32, 50, 50]              64\n",
      "             ReLU-43           [-1, 32, 50, 50]               0\n",
      "           Conv2d-44            [-1, 9, 50, 50]          14,112\n",
      "       conv_layer-45           [-1, 41, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 41, 50, 50]              82\n",
      "             ReLU-47           [-1, 41, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 50, 50]          18,081\n",
      "       conv_layer-49           [-1, 50, 50, 50]               0\n",
      "      Dense_block-50           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 50, 50, 50]             100\n",
      "             ReLU-52           [-1, 50, 50, 50]               0\n",
      "           Conv2d-53           [-1, 25, 50, 50]           1,250\n",
      "      BatchNorm2d-54           [-1, 25, 50, 50]              50\n",
      "             ReLU-55           [-1, 25, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 25, 100, 100]          30,625\n",
      "    Encode_Decode-57         [-1, 25, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 25, 100, 100]              50\n",
      "             ReLU-59         [-1, 25, 100, 100]               0\n",
      "           Conv2d-60          [-1, 9, 100, 100]          11,025\n",
      "       conv_layer-61         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 34, 100, 100]              68\n",
      "             ReLU-63         [-1, 34, 100, 100]               0\n",
      "           Conv2d-64          [-1, 9, 100, 100]          14,994\n",
      "       conv_layer-65         [-1, 43, 100, 100]               0\n",
      "      Dense_block-66         [-1, 43, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 43, 100, 100]              86\n",
      "             ReLU-68         [-1, 43, 100, 100]               0\n",
      "           Conv2d-69         [-1, 21, 100, 100]             903\n",
      "      BatchNorm2d-70         [-1, 21, 100, 100]              42\n",
      "             ReLU-71         [-1, 21, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 21, 200, 200]          21,609\n",
      "    Encode_Decode-73         [-1, 21, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 21, 200, 200]              42\n",
      "             ReLU-75         [-1, 21, 200, 200]               0\n",
      "           Conv2d-76          [-1, 9, 200, 200]           9,261\n",
      "       conv_layer-77         [-1, 30, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 30, 200, 200]              60\n",
      "             ReLU-79         [-1, 30, 200, 200]               0\n",
      "           Conv2d-80          [-1, 9, 200, 200]          13,230\n",
      "       conv_layer-81         [-1, 39, 200, 200]               0\n",
      "      Dense_block-82         [-1, 39, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 39, 200, 200]              78\n",
      "             ReLU-84         [-1, 39, 200, 200]               0\n",
      "           Conv2d-85         [-1, 19, 200, 200]             741\n",
      "      BatchNorm2d-86         [-1, 19, 200, 200]              38\n",
      "             ReLU-87         [-1, 19, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             304\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 191,027\n",
      "Trainable params: 191,027\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 252.59\n",
      "Params size (MB): 0.73\n",
      "Estimated Total Size (MB): 253.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             150\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             175\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             100\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             125\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,552\n",
      "Trainable params: 3,552\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.14\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]          14,994\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]          18,963\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]          33,124\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 40, 50, 50]              80\n",
      "             ReLU-75           [-1, 40, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]          17,640\n",
      "       conv_layer-77           [-1, 49, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 49, 50, 50]              98\n",
      "             ReLU-79           [-1, 49, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]          21,609\n",
      "       conv_layer-81           [-1, 58, 50, 50]               0\n",
      "      Dense_block-82           [-1, 58, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 58, 50, 50]             116\n",
      "             ReLU-84           [-1, 58, 50, 50]               0\n",
      "           Conv2d-85           [-1, 29, 50, 50]           1,682\n",
      "      BatchNorm2d-86           [-1, 29, 50, 50]              58\n",
      "             ReLU-87           [-1, 29, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 29, 100, 100]          41,209\n",
      "    Encode_Decode-89         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 40, 100, 100]              80\n",
      "             ReLU-91         [-1, 40, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]          17,640\n",
      "       conv_layer-93         [-1, 49, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 49, 100, 100]              98\n",
      "             ReLU-95         [-1, 49, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]          21,609\n",
      "       conv_layer-97         [-1, 58, 100, 100]               0\n",
      "      Dense_block-98         [-1, 58, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 58, 100, 100]             116\n",
      "            ReLU-100         [-1, 58, 100, 100]               0\n",
      "          Conv2d-101         [-1, 29, 100, 100]           1,682\n",
      "     BatchNorm2d-102         [-1, 29, 100, 100]              58\n",
      "            ReLU-103         [-1, 29, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 29, 200, 200]          41,209\n",
      "   Encode_Decode-105         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 33, 200, 200]              66\n",
      "            ReLU-107         [-1, 33, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]          14,553\n",
      "      conv_layer-109         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 42, 200, 200]              84\n",
      "            ReLU-111         [-1, 42, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]          18,522\n",
      "      conv_layer-113         [-1, 51, 200, 200]               0\n",
      "     Dense_block-114         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 51, 200, 200]             102\n",
      "            ReLU-116         [-1, 51, 200, 200]               0\n",
      "          Conv2d-117         [-1, 25, 200, 200]           1,275\n",
      "     BatchNorm2d-118         [-1, 25, 200, 200]              50\n",
      "            ReLU-119         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             400\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 354,226\n",
      "Trainable params: 354,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 317.31\n",
      "Params size (MB): 1.35\n",
      "Estimated Total Size (MB): 319.27\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             500\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           1,125\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             875\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           1,500\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           1,600\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,000\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           1,625\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 18, 50, 50]              36\n",
      "             ReLU-43           [-1, 18, 50, 50]               0\n",
      "           Conv2d-44            [-1, 5, 50, 50]           2,250\n",
      "       conv_layer-45           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 23, 50, 50]              46\n",
      "             ReLU-47           [-1, 23, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 50, 50]           2,875\n",
      "       conv_layer-49           [-1, 28, 50, 50]               0\n",
      "      Dense_block-50           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 28, 50, 50]              56\n",
      "             ReLU-52           [-1, 28, 50, 50]               0\n",
      "           Conv2d-53           [-1, 14, 50, 50]             392\n",
      "      BatchNorm2d-54           [-1, 14, 50, 50]              28\n",
      "             ReLU-55           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-57         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 14, 100, 100]              28\n",
      "             ReLU-59         [-1, 14, 100, 100]               0\n",
      "           Conv2d-60          [-1, 5, 100, 100]           1,750\n",
      "       conv_layer-61         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 19, 100, 100]              38\n",
      "             ReLU-63         [-1, 19, 100, 100]               0\n",
      "           Conv2d-64          [-1, 5, 100, 100]           2,375\n",
      "       conv_layer-65         [-1, 24, 100, 100]               0\n",
      "      Dense_block-66         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 24, 100, 100]              48\n",
      "             ReLU-68         [-1, 24, 100, 100]               0\n",
      "           Conv2d-69         [-1, 12, 100, 100]             288\n",
      "      BatchNorm2d-70         [-1, 12, 100, 100]              24\n",
      "             ReLU-71         [-1, 12, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 12, 200, 200]           3,600\n",
      "    Encode_Decode-73         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 12, 200, 200]              24\n",
      "             ReLU-75         [-1, 12, 200, 200]               0\n",
      "           Conv2d-76          [-1, 5, 200, 200]           1,500\n",
      "       conv_layer-77         [-1, 17, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 17, 200, 200]              34\n",
      "             ReLU-79         [-1, 17, 200, 200]               0\n",
      "           Conv2d-80          [-1, 5, 200, 200]           2,125\n",
      "       conv_layer-81         [-1, 22, 200, 200]               0\n",
      "      Dense_block-82         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 22, 200, 200]              44\n",
      "             ReLU-84         [-1, 22, 200, 200]               0\n",
      "           Conv2d-85         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-86         [-1, 11, 200, 200]              22\n",
      "             ReLU-87         [-1, 11, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             176\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 32,927\n",
      "Trainable params: 32,927\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 150.22\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 150.96\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]             324\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           1,053\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           1,089\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]             891\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           1,620\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           1,764\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           1,134\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]           1,863\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]           2,304\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           1,296\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]           2,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]           2,601\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           1,377\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]           2,106\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]           2,835\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]           3,564\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]           6,084\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]           2,106\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]           2,835\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]           4,356\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           2,916\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]           3,645\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]           6,561\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 38, 100, 100]              76\n",
      "            ReLU-123         [-1, 38, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           3,078\n",
      "      conv_layer-125         [-1, 47, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 47, 100, 100]              94\n",
      "            ReLU-127         [-1, 47, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]           3,807\n",
      "      conv_layer-129         [-1, 56, 100, 100]               0\n",
      "     Dense_block-130         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 56, 100, 100]             112\n",
      "            ReLU-132         [-1, 56, 100, 100]               0\n",
      "          Conv2d-133         [-1, 28, 100, 100]           1,568\n",
      "     BatchNorm2d-134         [-1, 28, 100, 100]              56\n",
      "            ReLU-135         [-1, 28, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 28, 200, 200]           7,056\n",
      "   Encode_Decode-137         [-1, 28, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 28, 200, 200]              56\n",
      "            ReLU-139         [-1, 28, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           2,268\n",
      "      conv_layer-141         [-1, 37, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 37, 200, 200]              74\n",
      "            ReLU-143         [-1, 37, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]           2,997\n",
      "      conv_layer-145         [-1, 46, 200, 200]               0\n",
      "     Dense_block-146         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 46, 200, 200]              92\n",
      "            ReLU-148         [-1, 46, 200, 200]               0\n",
      "          Conv2d-149         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-150         [-1, 23, 200, 200]              46\n",
      "            ReLU-151         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             368\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 86,423\n",
      "Trainable params: 86,423\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 299.76\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 300.70\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 51, 25, 25]             102\n",
      "             ReLU-91           [-1, 51, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           5,049\n",
      "       conv_layer-93           [-1, 62, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 62, 25, 25]             124\n",
      "             ReLU-95           [-1, 62, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           6,138\n",
      "       conv_layer-97           [-1, 73, 25, 25]               0\n",
      "      Dense_block-98           [-1, 73, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 73, 25, 25]             146\n",
      "            ReLU-100           [-1, 73, 25, 25]               0\n",
      "          Conv2d-101           [-1, 36, 25, 25]           2,628\n",
      "     BatchNorm2d-102           [-1, 36, 25, 25]              72\n",
      "            ReLU-103           [-1, 36, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 36, 50, 50]          11,664\n",
      "   Encode_Decode-105           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 53, 50, 50]             106\n",
      "            ReLU-107           [-1, 53, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           5,247\n",
      "      conv_layer-109           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 64, 50, 50]             128\n",
      "            ReLU-111           [-1, 64, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           6,336\n",
      "      conv_layer-113           [-1, 75, 50, 50]               0\n",
      "     Dense_block-114           [-1, 75, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 75, 50, 50]             150\n",
      "            ReLU-116           [-1, 75, 50, 50]               0\n",
      "          Conv2d-117           [-1, 37, 50, 50]           2,775\n",
      "     BatchNorm2d-118           [-1, 37, 50, 50]              74\n",
      "            ReLU-119           [-1, 37, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 37, 100, 100]          12,321\n",
      "   Encode_Decode-121         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 37, 100, 100]              74\n",
      "            ReLU-123         [-1, 37, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           3,663\n",
      "      conv_layer-125         [-1, 48, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 48, 100, 100]              96\n",
      "            ReLU-127         [-1, 48, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           4,752\n",
      "      conv_layer-129         [-1, 59, 100, 100]               0\n",
      "     Dense_block-130         [-1, 59, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 59, 100, 100]             118\n",
      "            ReLU-132         [-1, 59, 100, 100]               0\n",
      "          Conv2d-133         [-1, 29, 100, 100]           1,711\n",
      "     BatchNorm2d-134         [-1, 29, 100, 100]              58\n",
      "            ReLU-135         [-1, 29, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 29, 200, 200]           7,569\n",
      "   Encode_Decode-137         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 29, 200, 200]              58\n",
      "            ReLU-139         [-1, 29, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           2,871\n",
      "      conv_layer-141         [-1, 40, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 40, 200, 200]              80\n",
      "            ReLU-143         [-1, 40, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           3,960\n",
      "      conv_layer-145         [-1, 51, 200, 200]               0\n",
      "     Dense_block-146         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 51, 200, 200]             102\n",
      "            ReLU-148         [-1, 51, 200, 200]               0\n",
      "          Conv2d-149         [-1, 25, 200, 200]           1,275\n",
      "     BatchNorm2d-150         [-1, 25, 200, 200]              50\n",
      "            ReLU-151         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             400\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 135,278\n",
      "Trainable params: 135,278\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 337.83\n",
      "Params size (MB): 0.52\n",
      "Estimated Total Size (MB): 338.96\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           1,566\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]             918\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           1,242\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           1,188\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           1,512\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           2,601\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 21, 200, 200]              42\n",
      "            ReLU-107         [-1, 21, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           1,134\n",
      "      conv_layer-109         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 27, 200, 200]              54\n",
      "            ReLU-111         [-1, 27, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           1,458\n",
      "      conv_layer-113         [-1, 33, 200, 200]               0\n",
      "     Dense_block-114         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 33, 200, 200]              66\n",
      "            ReLU-116         [-1, 33, 200, 200]               0\n",
      "          Conv2d-117         [-1, 16, 200, 200]             528\n",
      "     BatchNorm2d-118         [-1, 16, 200, 200]              32\n",
      "            ReLU-119         [-1, 16, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             256\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 28,852\n",
      "Trainable params: 28,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 206.61\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 207.33\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          10,000\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           5,500\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           8,525\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          11,550\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          14,575\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          25,600\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           8,800\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          11,825\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          18,225\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          12,100\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          15,125\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          27,225\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          12,650\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          15,675\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          28,900\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 38, 200, 200]              76\n",
      "            ReLU-139         [-1, 38, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          10,450\n",
      "      conv_layer-141         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 49, 200, 200]              98\n",
      "            ReLU-143         [-1, 49, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          13,475\n",
      "      conv_layer-145         [-1, 60, 200, 200]               0\n",
      "     Dense_block-146         [-1, 60, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 60, 200, 200]             120\n",
      "            ReLU-148         [-1, 60, 200, 200]               0\n",
      "          Conv2d-149         [-1, 30, 200, 200]           1,800\n",
      "     BatchNorm2d-150         [-1, 30, 200, 200]              60\n",
      "            ReLU-151         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             480\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 327,515\n",
      "Trainable params: 327,515\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 373.84\n",
      "Params size (MB): 1.25\n",
      "Estimated Total Size (MB): 375.69\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              45\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              54\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              54\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              63\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             144\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              36\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              45\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,648\n",
      "Trainable params: 1,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.13\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           2,156\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           8,085\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           8,281\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           7,007\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          12,936\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           9,163\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          15,092\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          17,689\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          10,241\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          16,170\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          19,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]          10,780\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]          16,709\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          22,638\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          28,567\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          50,176\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 51, 25, 25]             102\n",
      "             ReLU-91           [-1, 51, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]          27,489\n",
      "       conv_layer-93           [-1, 62, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 62, 25, 25]             124\n",
      "             ReLU-95           [-1, 62, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          33,418\n",
      "       conv_layer-97           [-1, 73, 25, 25]               0\n",
      "      Dense_block-98           [-1, 73, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 73, 25, 25]             146\n",
      "            ReLU-100           [-1, 73, 25, 25]               0\n",
      "          Conv2d-101           [-1, 36, 25, 25]           2,628\n",
      "     BatchNorm2d-102           [-1, 36, 25, 25]              72\n",
      "            ReLU-103           [-1, 36, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 36, 50, 50]          63,504\n",
      "   Encode_Decode-105           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 53, 50, 50]             106\n",
      "            ReLU-107           [-1, 53, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          28,567\n",
      "      conv_layer-109           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 64, 50, 50]             128\n",
      "            ReLU-111           [-1, 64, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          34,496\n",
      "      conv_layer-113           [-1, 75, 50, 50]               0\n",
      "     Dense_block-114           [-1, 75, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 75, 50, 50]             150\n",
      "            ReLU-116           [-1, 75, 50, 50]               0\n",
      "          Conv2d-117           [-1, 37, 50, 50]           2,775\n",
      "     BatchNorm2d-118           [-1, 37, 50, 50]              74\n",
      "            ReLU-119           [-1, 37, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 37, 100, 100]          67,081\n",
      "   Encode_Decode-121         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 50, 100, 100]             100\n",
      "            ReLU-123         [-1, 50, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          26,950\n",
      "      conv_layer-125         [-1, 61, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 61, 100, 100]             122\n",
      "            ReLU-127         [-1, 61, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          32,879\n",
      "      conv_layer-129         [-1, 72, 100, 100]               0\n",
      "     Dense_block-130         [-1, 72, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 72, 100, 100]             144\n",
      "            ReLU-132         [-1, 72, 100, 100]               0\n",
      "          Conv2d-133         [-1, 36, 100, 100]           2,592\n",
      "     BatchNorm2d-134         [-1, 36, 100, 100]              72\n",
      "            ReLU-135         [-1, 36, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 36, 200, 200]          63,504\n",
      "   Encode_Decode-137         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 36, 200, 200]              72\n",
      "            ReLU-139         [-1, 36, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          19,404\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          25,333\n",
      "      conv_layer-145         [-1, 58, 200, 200]               0\n",
      "     Dense_block-146         [-1, 58, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 58, 200, 200]             116\n",
      "            ReLU-148         [-1, 58, 200, 200]               0\n",
      "          Conv2d-149         [-1, 29, 200, 200]           1,682\n",
      "     BatchNorm2d-150         [-1, 29, 200, 200]              58\n",
      "            ReLU-151         [-1, 29, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             464\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 709,787\n",
      "Trainable params: 709,787\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 375.52\n",
      "Params size (MB): 2.71\n",
      "Estimated Total Size (MB): 378.84\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 2, 200, 200]               4\n",
      "             ReLU-75          [-1, 2, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              18\n",
      "       conv_layer-77          [-1, 3, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 3, 200, 200]               6\n",
      "             ReLU-79          [-1, 3, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              27\n",
      "       conv_layer-81          [-1, 4, 200, 200]               0\n",
      "      Dense_block-82          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 4, 200, 200]               8\n",
      "             ReLU-84          [-1, 4, 200, 200]               0\n",
      "           Conv2d-85          [-1, 2, 200, 200]               8\n",
      "      BatchNorm2d-86          [-1, 2, 200, 200]               4\n",
      "             ReLU-87          [-1, 2, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              32\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,012\n",
      "Trainable params: 1,012\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.35\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 43.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 6, 50, 50]              12\n",
      "             ReLU-75            [-1, 6, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             300\n",
      "       conv_layer-77            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 8, 50, 50]              16\n",
      "             ReLU-79            [-1, 8, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             400\n",
      "       conv_layer-81           [-1, 10, 50, 50]               0\n",
      "      Dense_block-82           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 10, 50, 50]              20\n",
      "             ReLU-84           [-1, 10, 50, 50]               0\n",
      "           Conv2d-85            [-1, 5, 50, 50]              50\n",
      "      BatchNorm2d-86            [-1, 5, 50, 50]              10\n",
      "             ReLU-87            [-1, 5, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 5, 100, 100]             625\n",
      "    Encode_Decode-89          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 9, 100, 100]              18\n",
      "             ReLU-91          [-1, 9, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             450\n",
      "       conv_layer-93         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 11, 100, 100]              22\n",
      "             ReLU-95         [-1, 11, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             550\n",
      "       conv_layer-97         [-1, 13, 100, 100]               0\n",
      "      Dense_block-98         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 13, 100, 100]              26\n",
      "            ReLU-100         [-1, 13, 100, 100]               0\n",
      "          Conv2d-101          [-1, 6, 100, 100]              78\n",
      "     BatchNorm2d-102          [-1, 6, 100, 100]              12\n",
      "            ReLU-103          [-1, 6, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 6, 200, 200]             900\n",
      "   Encode_Decode-105          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 6, 200, 200]              12\n",
      "            ReLU-107          [-1, 6, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             300\n",
      "      conv_layer-109          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 8, 200, 200]              16\n",
      "            ReLU-111          [-1, 8, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             400\n",
      "      conv_layer-113         [-1, 10, 200, 200]               0\n",
      "     Dense_block-114         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 10, 200, 200]              20\n",
      "            ReLU-116         [-1, 10, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              50\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 9,913\n",
      "Trainable params: 9,913\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 79.83\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 80.48\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           4,230\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           5,130\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]           9,801\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           4,410\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           5,310\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          10,404\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           4,140\n",
      "      conv_layer-125         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 56, 100, 100]             112\n",
      "            ReLU-127         [-1, 56, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           5,040\n",
      "      conv_layer-129         [-1, 66, 100, 100]               0\n",
      "     Dense_block-130         [-1, 66, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 66, 100, 100]             132\n",
      "            ReLU-132         [-1, 66, 100, 100]               0\n",
      "          Conv2d-133         [-1, 33, 100, 100]           2,178\n",
      "     BatchNorm2d-134         [-1, 33, 100, 100]              66\n",
      "            ReLU-135         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 33, 200, 200]           9,801\n",
      "   Encode_Decode-137         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 37, 200, 200]              74\n",
      "            ReLU-139         [-1, 37, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           3,330\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           4,230\n",
      "      conv_layer-145         [-1, 57, 200, 200]               0\n",
      "     Dense_block-146         [-1, 57, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 57, 200, 200]             114\n",
      "            ReLU-148         [-1, 57, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,596\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 123,492\n",
      "Trainable params: 123,492\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 357.48\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 358.56\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             180\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]             405\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             315\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]             540\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]             576\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]             360\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]             585\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 18, 50, 50]              36\n",
      "             ReLU-43           [-1, 18, 50, 50]               0\n",
      "           Conv2d-44            [-1, 5, 50, 50]             810\n",
      "       conv_layer-45           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 23, 50, 50]              46\n",
      "             ReLU-47           [-1, 23, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 50, 50]           1,035\n",
      "       conv_layer-49           [-1, 28, 50, 50]               0\n",
      "      Dense_block-50           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 28, 50, 50]              56\n",
      "             ReLU-52           [-1, 28, 50, 50]               0\n",
      "           Conv2d-53           [-1, 14, 50, 50]             392\n",
      "      BatchNorm2d-54           [-1, 14, 50, 50]              28\n",
      "             ReLU-55           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-57         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 14, 100, 100]              28\n",
      "             ReLU-59         [-1, 14, 100, 100]               0\n",
      "           Conv2d-60          [-1, 5, 100, 100]             630\n",
      "       conv_layer-61         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 19, 100, 100]              38\n",
      "             ReLU-63         [-1, 19, 100, 100]               0\n",
      "           Conv2d-64          [-1, 5, 100, 100]             855\n",
      "       conv_layer-65         [-1, 24, 100, 100]               0\n",
      "      Dense_block-66         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 24, 100, 100]              48\n",
      "             ReLU-68         [-1, 24, 100, 100]               0\n",
      "           Conv2d-69         [-1, 12, 100, 100]             288\n",
      "      BatchNorm2d-70         [-1, 12, 100, 100]              24\n",
      "             ReLU-71         [-1, 12, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 12, 200, 200]           1,296\n",
      "    Encode_Decode-73         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 16, 200, 200]              32\n",
      "             ReLU-75         [-1, 16, 200, 200]               0\n",
      "           Conv2d-76          [-1, 5, 200, 200]             720\n",
      "       conv_layer-77         [-1, 21, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 21, 200, 200]              42\n",
      "             ReLU-79         [-1, 21, 200, 200]               0\n",
      "           Conv2d-80          [-1, 5, 200, 200]             945\n",
      "       conv_layer-81         [-1, 26, 200, 200]               0\n",
      "      Dense_block-82         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 26, 200, 200]              52\n",
      "             ReLU-84         [-1, 26, 200, 200]               0\n",
      "           Conv2d-85         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-86         [-1, 13, 200, 200]              26\n",
      "             ReLU-87         [-1, 13, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             208\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 13,715\n",
      "Trainable params: 13,715\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 163.04\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 163.70\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 5\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      Dense_block-58           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 26, 25, 25]              52\n",
      "             ReLU-60           [-1, 26, 25, 25]               0\n",
      "           Conv2d-61           [-1, 13, 25, 25]             338\n",
      "      BatchNorm2d-62           [-1, 13, 25, 25]              26\n",
      "             ReLU-63           [-1, 13, 25, 25]               0\n",
      "           Conv2d-64           [-1, 13, 13, 13]           8,281\n",
      "    Encode_Decode-65           [-1, 13, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 13, 13, 13]              26\n",
      "             ReLU-67           [-1, 13, 13, 13]               0\n",
      "           Conv2d-68            [-1, 7, 13, 13]           4,459\n",
      "       conv_layer-69           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 20, 13, 13]              40\n",
      "             ReLU-71           [-1, 20, 13, 13]               0\n",
      "           Conv2d-72            [-1, 7, 13, 13]           6,860\n",
      "       conv_layer-73           [-1, 27, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 27, 13, 13]              54\n",
      "             ReLU-75           [-1, 27, 13, 13]               0\n",
      "           Conv2d-76            [-1, 7, 13, 13]           9,261\n",
      "       conv_layer-77           [-1, 34, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 34, 13, 13]              68\n",
      "             ReLU-79           [-1, 34, 13, 13]               0\n",
      "           Conv2d-80            [-1, 7, 13, 13]          11,662\n",
      "       conv_layer-81           [-1, 41, 13, 13]               0\n",
      "      Dense_block-82           [-1, 41, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 41, 13, 13]              82\n",
      "             ReLU-84           [-1, 41, 13, 13]               0\n",
      "           Conv2d-85           [-1, 20, 13, 13]             820\n",
      "      BatchNorm2d-86           [-1, 20, 13, 13]              40\n",
      "             ReLU-87           [-1, 20, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 20, 25, 25]          19,600\n",
      "    Encode_Decode-89           [-1, 20, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 20, 25, 25]              40\n",
      "             ReLU-91           [-1, 20, 25, 25]               0\n",
      "           Conv2d-92            [-1, 7, 25, 25]           6,860\n",
      "       conv_layer-93           [-1, 27, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 27, 25, 25]              54\n",
      "             ReLU-95           [-1, 27, 25, 25]               0\n",
      "           Conv2d-96            [-1, 7, 25, 25]           9,261\n",
      "       conv_layer-97           [-1, 34, 25, 25]               0\n",
      "      Dense_block-98           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 34, 25, 25]              68\n",
      "            ReLU-100           [-1, 34, 25, 25]               0\n",
      "          Conv2d-101           [-1, 17, 25, 25]             578\n",
      "     BatchNorm2d-102           [-1, 17, 25, 25]              34\n",
      "            ReLU-103           [-1, 17, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 17, 50, 50]          14,161\n",
      "   Encode_Decode-105           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 28, 50, 50]              56\n",
      "            ReLU-107           [-1, 28, 50, 50]               0\n",
      "          Conv2d-108            [-1, 7, 50, 50]           9,604\n",
      "      conv_layer-109           [-1, 35, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 35, 50, 50]              70\n",
      "            ReLU-111           [-1, 35, 50, 50]               0\n",
      "          Conv2d-112            [-1, 7, 50, 50]          12,005\n",
      "      conv_layer-113           [-1, 42, 50, 50]               0\n",
      "     Dense_block-114           [-1, 42, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 42, 50, 50]              84\n",
      "            ReLU-116           [-1, 42, 50, 50]               0\n",
      "          Conv2d-117           [-1, 21, 50, 50]             882\n",
      "     BatchNorm2d-118           [-1, 21, 50, 50]              42\n",
      "            ReLU-119           [-1, 21, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 21, 100, 100]          21,609\n",
      "   Encode_Decode-121         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 30, 100, 100]              60\n",
      "            ReLU-123         [-1, 30, 100, 100]               0\n",
      "          Conv2d-124          [-1, 7, 100, 100]          10,290\n",
      "      conv_layer-125         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 37, 100, 100]              74\n",
      "            ReLU-127         [-1, 37, 100, 100]               0\n",
      "          Conv2d-128          [-1, 7, 100, 100]          12,691\n",
      "      conv_layer-129         [-1, 44, 100, 100]               0\n",
      "     Dense_block-130         [-1, 44, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 44, 100, 100]              88\n",
      "            ReLU-132         [-1, 44, 100, 100]               0\n",
      "          Conv2d-133         [-1, 22, 100, 100]             968\n",
      "     BatchNorm2d-134         [-1, 22, 100, 100]              44\n",
      "            ReLU-135         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 22, 200, 200]          23,716\n",
      "   Encode_Decode-137         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 22, 200, 200]              44\n",
      "            ReLU-139         [-1, 22, 200, 200]               0\n",
      "          Conv2d-140          [-1, 7, 200, 200]           7,546\n",
      "      conv_layer-141         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 29, 200, 200]              58\n",
      "            ReLU-143         [-1, 29, 200, 200]               0\n",
      "          Conv2d-144          [-1, 7, 200, 200]           9,947\n",
      "      conv_layer-145         [-1, 36, 200, 200]               0\n",
      "     Dense_block-146         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 36, 200, 200]              72\n",
      "            ReLU-148         [-1, 36, 200, 200]               0\n",
      "          Conv2d-149         [-1, 18, 200, 200]             648\n",
      "     BatchNorm2d-150         [-1, 18, 200, 200]              36\n",
      "            ReLU-151         [-1, 18, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             288\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 256,156\n",
      "Trainable params: 256,156\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 238.36\n",
      "Params size (MB): 0.98\n",
      "Estimated Total Size (MB): 239.95\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 6, 50, 50]              12\n",
      "             ReLU-75            [-1, 6, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             300\n",
      "       conv_layer-77            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 8, 50, 50]              16\n",
      "             ReLU-79            [-1, 8, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             400\n",
      "       conv_layer-81           [-1, 10, 50, 50]               0\n",
      "      Dense_block-82           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 10, 50, 50]              20\n",
      "             ReLU-84           [-1, 10, 50, 50]               0\n",
      "           Conv2d-85            [-1, 5, 50, 50]              50\n",
      "      BatchNorm2d-86            [-1, 5, 50, 50]              10\n",
      "             ReLU-87            [-1, 5, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 5, 100, 100]             625\n",
      "    Encode_Decode-89          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 9, 100, 100]              18\n",
      "             ReLU-91          [-1, 9, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             450\n",
      "       conv_layer-93         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 11, 100, 100]              22\n",
      "             ReLU-95         [-1, 11, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             550\n",
      "       conv_layer-97         [-1, 13, 100, 100]               0\n",
      "      Dense_block-98         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 13, 100, 100]              26\n",
      "            ReLU-100         [-1, 13, 100, 100]               0\n",
      "          Conv2d-101          [-1, 6, 100, 100]              78\n",
      "     BatchNorm2d-102          [-1, 6, 100, 100]              12\n",
      "            ReLU-103          [-1, 6, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 6, 200, 200]             900\n",
      "   Encode_Decode-105          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 10, 200, 200]              20\n",
      "            ReLU-107         [-1, 10, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             500\n",
      "      conv_layer-109         [-1, 12, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 12, 200, 200]              24\n",
      "            ReLU-111         [-1, 12, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             600\n",
      "      conv_layer-113         [-1, 14, 200, 200]               0\n",
      "     Dense_block-114         [-1, 14, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 14, 200, 200]              28\n",
      "            ReLU-116         [-1, 14, 200, 200]               0\n",
      "          Conv2d-117          [-1, 7, 200, 200]              98\n",
      "     BatchNorm2d-118          [-1, 7, 200, 200]              14\n",
      "            ReLU-119          [-1, 7, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             112\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 10,421\n",
      "Trainable params: 10,421\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 92.65\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 93.30\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              45\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              54\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              54\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              63\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             144\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              36\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              45\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,648\n",
      "Trainable params: 1,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.13\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 |     159 |      20 |  0.144263779 |        nadir\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           3,168\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           4,257\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]           6,561\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           4,356\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           5,445\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]           9,801\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,554\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           5,643\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          10,404\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,366\n",
      "      conv_layer-141         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 45, 200, 200]              90\n",
      "            ReLU-143         [-1, 45, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           4,455\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 126,799\n",
      "Trainable params: 126,799\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 361.02\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 362.11\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              72\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              81\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,458\n",
      "Trainable params: 1,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 66.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             100\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             125\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             150\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             175\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             400\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             100\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             125\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,734\n",
      "Trainable params: 2,734\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 54.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             800\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           2,400\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           2,500\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           2,000\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           3,600\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           4,225\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           2,600\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           4,200\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           4,900\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           2,800\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           4,400\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 30, 25, 25]              60\n",
      "             ReLU-59           [-1, 30, 25, 25]               0\n",
      "           Conv2d-60            [-1, 8, 25, 25]           6,000\n",
      "       conv_layer-61           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 38, 25, 25]              76\n",
      "             ReLU-63           [-1, 38, 25, 25]               0\n",
      "           Conv2d-64            [-1, 8, 25, 25]           7,600\n",
      "       conv_layer-65           [-1, 46, 25, 25]               0\n",
      "      Dense_block-66           [-1, 46, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 46, 25, 25]              92\n",
      "             ReLU-68           [-1, 46, 25, 25]               0\n",
      "           Conv2d-69           [-1, 23, 25, 25]           1,058\n",
      "      BatchNorm2d-70           [-1, 23, 25, 25]              46\n",
      "             ReLU-71           [-1, 23, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 23, 50, 50]          13,225\n",
      "    Encode_Decode-73           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 36, 50, 50]              72\n",
      "             ReLU-75           [-1, 36, 50, 50]               0\n",
      "           Conv2d-76            [-1, 8, 50, 50]           7,200\n",
      "       conv_layer-77           [-1, 44, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 44, 50, 50]              88\n",
      "             ReLU-79           [-1, 44, 50, 50]               0\n",
      "           Conv2d-80            [-1, 8, 50, 50]           8,800\n",
      "       conv_layer-81           [-1, 52, 50, 50]               0\n",
      "      Dense_block-82           [-1, 52, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 52, 50, 50]             104\n",
      "             ReLU-84           [-1, 52, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,352\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]          16,900\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 36, 100, 100]              72\n",
      "             ReLU-91         [-1, 36, 100, 100]               0\n",
      "           Conv2d-92          [-1, 8, 100, 100]           7,200\n",
      "       conv_layer-93         [-1, 44, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 44, 100, 100]              88\n",
      "             ReLU-95         [-1, 44, 100, 100]               0\n",
      "           Conv2d-96          [-1, 8, 100, 100]           8,800\n",
      "       conv_layer-97         [-1, 52, 100, 100]               0\n",
      "      Dense_block-98         [-1, 52, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 52, 100, 100]             104\n",
      "            ReLU-100         [-1, 52, 100, 100]               0\n",
      "          Conv2d-101         [-1, 26, 100, 100]           1,352\n",
      "     BatchNorm2d-102         [-1, 26, 100, 100]              52\n",
      "            ReLU-103         [-1, 26, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 26, 200, 200]          16,900\n",
      "   Encode_Decode-105         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 30, 200, 200]              60\n",
      "            ReLU-107         [-1, 30, 200, 200]               0\n",
      "          Conv2d-108          [-1, 8, 200, 200]           6,000\n",
      "      conv_layer-109         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 38, 200, 200]              76\n",
      "            ReLU-111         [-1, 38, 200, 200]               0\n",
      "          Conv2d-112          [-1, 8, 200, 200]           7,600\n",
      "      conv_layer-113         [-1, 46, 200, 200]               0\n",
      "     Dense_block-114         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 46, 200, 200]              92\n",
      "            ReLU-116         [-1, 46, 200, 200]               0\n",
      "          Conv2d-117         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-118         [-1, 23, 200, 200]              46\n",
      "            ReLU-119         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             368\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 148,558\n",
      "Trainable params: 148,558\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 287.43\n",
      "Params size (MB): 0.57\n",
      "Estimated Total Size (MB): 288.61\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]          15,876\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           8,820\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]          13,720\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]          17,689\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           9,310\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]          14,210\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]          19,110\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]          24,010\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]          41,209\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]          23,030\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]          27,930\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]          53,361\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]          24,010\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]          28,910\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          56,644\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]          22,540\n",
      "      conv_layer-125         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 56, 100, 100]             112\n",
      "            ReLU-127         [-1, 56, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]          27,440\n",
      "      conv_layer-129         [-1, 66, 100, 100]               0\n",
      "     Dense_block-130         [-1, 66, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 66, 100, 100]             132\n",
      "            ReLU-132         [-1, 66, 100, 100]               0\n",
      "          Conv2d-133         [-1, 33, 100, 100]           2,178\n",
      "     BatchNorm2d-134         [-1, 33, 100, 100]              66\n",
      "            ReLU-135         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 33, 200, 200]          53,361\n",
      "   Encode_Decode-137         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 33, 200, 200]              66\n",
      "            ReLU-139         [-1, 33, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]          16,170\n",
      "      conv_layer-141         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 43, 200, 200]              86\n",
      "            ReLU-143         [-1, 43, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]          21,070\n",
      "      conv_layer-145         [-1, 53, 200, 200]               0\n",
      "     Dense_block-146         [-1, 53, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 53, 200, 200]             106\n",
      "            ReLU-148         [-1, 53, 200, 200]               0\n",
      "          Conv2d-149         [-1, 26, 200, 200]           1,378\n",
      "     BatchNorm2d-150         [-1, 26, 200, 200]              52\n",
      "            ReLU-151         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             416\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 599,294\n",
      "Trainable params: 599,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 344.66\n",
      "Params size (MB): 2.29\n",
      "Estimated Total Size (MB): 347.56\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          11,275\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          14,300\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          24,025\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           8,525\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          11,550\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]          16,900\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          10,725\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          13,750\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]          22,500\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 30, 200, 200]              60\n",
      "            ReLU-107         [-1, 30, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           8,250\n",
      "      conv_layer-109         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 41, 200, 200]              82\n",
      "            ReLU-111         [-1, 41, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          11,275\n",
      "      conv_layer-113         [-1, 52, 200, 200]               0\n",
      "     Dense_block-114         [-1, 52, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 52, 200, 200]             104\n",
      "            ReLU-116         [-1, 52, 200, 200]               0\n",
      "          Conv2d-117         [-1, 26, 200, 200]           1,352\n",
      "     BatchNorm2d-118         [-1, 26, 200, 200]              52\n",
      "            ReLU-119         [-1, 26, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             416\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 225,481\n",
      "Trainable params: 225,481\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 334.65\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 336.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           1,566\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]             918\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           1,242\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           1,188\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           1,512\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           2,601\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]             918\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           1,242\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 28,238\n",
      "Trainable params: 28,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 193.80\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 194.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             125\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             150\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]             225\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 3, 200, 200]               6\n",
      "            ReLU-107          [-1, 3, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              75\n",
      "      conv_layer-109          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 4, 200, 200]               8\n",
      "            ReLU-111          [-1, 4, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             100\n",
      "      conv_layer-113          [-1, 5, 200, 200]               0\n",
      "     Dense_block-114          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 5, 200, 200]              10\n",
      "            ReLU-116          [-1, 5, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]              10\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,976\n",
      "Trainable params: 2,976\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 48.78\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 49.40\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 51, 25, 25]             102\n",
      "             ReLU-91           [-1, 51, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           5,049\n",
      "       conv_layer-93           [-1, 62, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 62, 25, 25]             124\n",
      "             ReLU-95           [-1, 62, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           6,138\n",
      "       conv_layer-97           [-1, 73, 25, 25]               0\n",
      "      Dense_block-98           [-1, 73, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 73, 25, 25]             146\n",
      "            ReLU-100           [-1, 73, 25, 25]               0\n",
      "          Conv2d-101           [-1, 36, 25, 25]           2,628\n",
      "     BatchNorm2d-102           [-1, 36, 25, 25]              72\n",
      "            ReLU-103           [-1, 36, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 36, 50, 50]          11,664\n",
      "   Encode_Decode-105           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 53, 50, 50]             106\n",
      "            ReLU-107           [-1, 53, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           5,247\n",
      "      conv_layer-109           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 64, 50, 50]             128\n",
      "            ReLU-111           [-1, 64, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           6,336\n",
      "      conv_layer-113           [-1, 75, 50, 50]               0\n",
      "     Dense_block-114           [-1, 75, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 75, 50, 50]             150\n",
      "            ReLU-116           [-1, 75, 50, 50]               0\n",
      "          Conv2d-117           [-1, 37, 50, 50]           2,775\n",
      "     BatchNorm2d-118           [-1, 37, 50, 50]              74\n",
      "            ReLU-119           [-1, 37, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 37, 100, 100]          12,321\n",
      "   Encode_Decode-121         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 50, 100, 100]             100\n",
      "            ReLU-123         [-1, 50, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,950\n",
      "      conv_layer-125         [-1, 61, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 61, 100, 100]             122\n",
      "            ReLU-127         [-1, 61, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           6,039\n",
      "      conv_layer-129         [-1, 72, 100, 100]               0\n",
      "     Dense_block-130         [-1, 72, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 72, 100, 100]             144\n",
      "            ReLU-132         [-1, 72, 100, 100]               0\n",
      "          Conv2d-133         [-1, 36, 100, 100]           2,592\n",
      "     BatchNorm2d-134         [-1, 36, 100, 100]              72\n",
      "            ReLU-135         [-1, 36, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 36, 200, 200]          11,664\n",
      "   Encode_Decode-137         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 40, 200, 200]              80\n",
      "            ReLU-139         [-1, 40, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,960\n",
      "      conv_layer-141         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 51, 200, 200]             102\n",
      "            ReLU-143         [-1, 51, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           5,049\n",
      "      conv_layer-145         [-1, 62, 200, 200]               0\n",
      "     Dense_block-146         [-1, 62, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 62, 200, 200]             124\n",
      "            ReLU-148         [-1, 62, 200, 200]               0\n",
      "          Conv2d-149         [-1, 31, 200, 200]           1,922\n",
      "     BatchNorm2d-150         [-1, 31, 200, 200]              62\n",
      "            ReLU-151         [-1, 31, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             496\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 145,919\n",
      "Trainable params: 145,919\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 388.34\n",
      "Params size (MB): 0.56\n",
      "Estimated Total Size (MB): 389.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 3, 200, 200]             108\n",
      "        conv_layer-5          [-1, 7, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 7, 200, 200]              14\n",
      "              ReLU-7          [-1, 7, 200, 200]               0\n",
      "            Conv2d-8          [-1, 3, 200, 200]             189\n",
      "        conv_layer-9         [-1, 10, 200, 200]               0\n",
      "      Dense_block-10         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 10, 200, 200]              20\n",
      "             ReLU-12         [-1, 10, 200, 200]               0\n",
      "           Conv2d-13          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-14          [-1, 5, 200, 200]              10\n",
      "             ReLU-15          [-1, 5, 200, 200]               0\n",
      "           Conv2d-16          [-1, 5, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 5, 100, 100]              10\n",
      "             ReLU-19          [-1, 5, 100, 100]               0\n",
      "           Conv2d-20          [-1, 3, 100, 100]             135\n",
      "       conv_layer-21          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 8, 100, 100]              16\n",
      "             ReLU-23          [-1, 8, 100, 100]               0\n",
      "           Conv2d-24          [-1, 3, 100, 100]             216\n",
      "       conv_layer-25         [-1, 11, 100, 100]               0\n",
      "      Dense_block-26         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 11, 100, 100]              22\n",
      "             ReLU-28         [-1, 11, 100, 100]               0\n",
      "           Conv2d-29          [-1, 5, 100, 100]              55\n",
      "      BatchNorm2d-30          [-1, 5, 100, 100]              10\n",
      "             ReLU-31          [-1, 5, 100, 100]               0\n",
      "           Conv2d-32            [-1, 5, 50, 50]             225\n",
      "    Encode_Decode-33            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 5, 50, 50]              10\n",
      "             ReLU-35            [-1, 5, 50, 50]               0\n",
      "           Conv2d-36            [-1, 3, 50, 50]             135\n",
      "       conv_layer-37            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 8, 50, 50]              16\n",
      "             ReLU-39            [-1, 8, 50, 50]               0\n",
      "           Conv2d-40            [-1, 3, 50, 50]             216\n",
      "       conv_layer-41           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 11, 50, 50]              22\n",
      "             ReLU-43           [-1, 11, 50, 50]               0\n",
      "           Conv2d-44            [-1, 3, 50, 50]             297\n",
      "       conv_layer-45           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48            [-1, 3, 50, 50]             378\n",
      "       conv_layer-49           [-1, 17, 50, 50]               0\n",
      "      Dense_block-50           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 17, 50, 50]              34\n",
      "             ReLU-52           [-1, 17, 50, 50]               0\n",
      "           Conv2d-53            [-1, 8, 50, 50]             136\n",
      "      BatchNorm2d-54            [-1, 8, 50, 50]              16\n",
      "             ReLU-55            [-1, 8, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-57          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 8, 100, 100]              16\n",
      "             ReLU-59          [-1, 8, 100, 100]               0\n",
      "           Conv2d-60          [-1, 3, 100, 100]             216\n",
      "       conv_layer-61         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 11, 100, 100]              22\n",
      "             ReLU-63         [-1, 11, 100, 100]               0\n",
      "           Conv2d-64          [-1, 3, 100, 100]             297\n",
      "       conv_layer-65         [-1, 14, 100, 100]               0\n",
      "      Dense_block-66         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 14, 100, 100]              28\n",
      "             ReLU-68         [-1, 14, 100, 100]               0\n",
      "           Conv2d-69          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-70          [-1, 7, 100, 100]              14\n",
      "             ReLU-71          [-1, 7, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 7, 200, 200]             441\n",
      "    Encode_Decode-73          [-1, 7, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 7, 200, 200]              14\n",
      "             ReLU-75          [-1, 7, 200, 200]               0\n",
      "           Conv2d-76          [-1, 3, 200, 200]             189\n",
      "       conv_layer-77         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 10, 200, 200]              20\n",
      "             ReLU-79         [-1, 10, 200, 200]               0\n",
      "           Conv2d-80          [-1, 3, 200, 200]             270\n",
      "       conv_layer-81         [-1, 13, 200, 200]               0\n",
      "      Dense_block-82         [-1, 13, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 13, 200, 200]              26\n",
      "             ReLU-84         [-1, 13, 200, 200]               0\n",
      "           Conv2d-85          [-1, 6, 200, 200]              78\n",
      "      BatchNorm2d-86          [-1, 6, 200, 200]              12\n",
      "             ReLU-87          [-1, 6, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              96\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 5,158\n",
      "Trainable params: 5,158\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 95.88\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 96.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 3\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              27\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              36\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]              36\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 6, 200, 200]              12\n",
      "             ReLU-75          [-1, 6, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              54\n",
      "       conv_layer-77          [-1, 7, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 7, 200, 200]              14\n",
      "             ReLU-79          [-1, 7, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              63\n",
      "       conv_layer-81          [-1, 8, 200, 200]               0\n",
      "      Dense_block-82          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 8, 200, 200]              16\n",
      "             ReLU-84          [-1, 8, 200, 200]               0\n",
      "           Conv2d-85          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-86          [-1, 4, 200, 200]               8\n",
      "             ReLU-87          [-1, 4, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              64\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,168\n",
      "Trainable params: 1,168\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 56.17\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 56.79\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 52, 100, 100]             104\n",
      "             ReLU-91         [-1, 52, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          15,600\n",
      "       conv_layer-93         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 64, 100, 100]             128\n",
      "             ReLU-95         [-1, 64, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          19,200\n",
      "       conv_layer-97         [-1, 76, 100, 100]               0\n",
      "      Dense_block-98         [-1, 76, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 76, 100, 100]             152\n",
      "            ReLU-100         [-1, 76, 100, 100]               0\n",
      "          Conv2d-101         [-1, 38, 100, 100]           2,888\n",
      "     BatchNorm2d-102         [-1, 38, 100, 100]              76\n",
      "            ReLU-103         [-1, 38, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 38, 200, 200]          36,100\n",
      "   Encode_Decode-105         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 42, 200, 200]              84\n",
      "            ReLU-107         [-1, 42, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]          12,600\n",
      "      conv_layer-109         [-1, 54, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 54, 200, 200]             108\n",
      "            ReLU-111         [-1, 54, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          16,200\n",
      "      conv_layer-113         [-1, 66, 200, 200]               0\n",
      "     Dense_block-114         [-1, 66, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 66, 200, 200]             132\n",
      "            ReLU-116         [-1, 66, 200, 200]               0\n",
      "          Conv2d-117         [-1, 33, 200, 200]           2,178\n",
      "     BatchNorm2d-118         [-1, 33, 200, 200]              66\n",
      "            ReLU-119         [-1, 33, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             528\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 320,257\n",
      "Trainable params: 320,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 409.62\n",
      "Params size (MB): 1.22\n",
      "Estimated Total Size (MB): 411.45\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           1,566\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]             918\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           1,242\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 14, 100, 100]              28\n",
      "             ReLU-91         [-1, 14, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]             756\n",
      "       conv_layer-93         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 20, 100, 100]              40\n",
      "             ReLU-95         [-1, 20, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           1,080\n",
      "       conv_layer-97         [-1, 26, 100, 100]               0\n",
      "      Dense_block-98         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 26, 100, 100]              52\n",
      "            ReLU-100         [-1, 26, 100, 100]               0\n",
      "          Conv2d-101         [-1, 13, 100, 100]             338\n",
      "     BatchNorm2d-102         [-1, 13, 100, 100]              26\n",
      "            ReLU-103         [-1, 13, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 13, 200, 200]           1,521\n",
      "   Encode_Decode-105         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]             918\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           1,242\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 25,998\n",
      "Trainable params: 25,998\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 184.95\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 185.66\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 10, 50, 50]              20\n",
      "             ReLU-75           [-1, 10, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             500\n",
      "       conv_layer-77           [-1, 12, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 12, 50, 50]              24\n",
      "             ReLU-79           [-1, 12, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             600\n",
      "       conv_layer-81           [-1, 14, 50, 50]               0\n",
      "      Dense_block-82           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 14, 50, 50]              28\n",
      "             ReLU-84           [-1, 14, 50, 50]               0\n",
      "           Conv2d-85            [-1, 7, 50, 50]              98\n",
      "      BatchNorm2d-86            [-1, 7, 50, 50]              14\n",
      "             ReLU-87            [-1, 7, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-89          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 11, 100, 100]              22\n",
      "             ReLU-91         [-1, 11, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             550\n",
      "       conv_layer-93         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 13, 100, 100]              26\n",
      "             ReLU-95         [-1, 13, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             650\n",
      "       conv_layer-97         [-1, 15, 100, 100]               0\n",
      "      Dense_block-98         [-1, 15, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 15, 100, 100]              30\n",
      "            ReLU-100         [-1, 15, 100, 100]               0\n",
      "          Conv2d-101          [-1, 7, 100, 100]             105\n",
      "     BatchNorm2d-102          [-1, 7, 100, 100]              14\n",
      "            ReLU-103          [-1, 7, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 7, 200, 200]           1,225\n",
      "   Encode_Decode-105          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 7, 200, 200]              14\n",
      "            ReLU-107          [-1, 7, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             350\n",
      "      conv_layer-109          [-1, 9, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 9, 200, 200]              18\n",
      "            ReLU-111          [-1, 9, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             450\n",
      "      conv_layer-113         [-1, 11, 200, 200]               0\n",
      "     Dense_block-114         [-1, 11, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 11, 200, 200]              22\n",
      "            ReLU-116         [-1, 11, 200, 200]               0\n",
      "          Conv2d-117          [-1, 5, 200, 200]              55\n",
      "     BatchNorm2d-118          [-1, 5, 200, 200]              10\n",
      "            ReLU-119          [-1, 5, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              80\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 11,666\n",
      "Trainable params: 11,666\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 85.90\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 86.55\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]             360\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           1,260\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           1,296\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           1,080\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]           1,980\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]           2,304\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           1,440\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]           2,340\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]           2,916\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           1,620\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]           2,520\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      Dense_block-58           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 38, 25, 25]              76\n",
      "             ReLU-60           [-1, 38, 25, 25]               0\n",
      "           Conv2d-61           [-1, 19, 25, 25]             722\n",
      "      BatchNorm2d-62           [-1, 19, 25, 25]              38\n",
      "             ReLU-63           [-1, 19, 25, 25]               0\n",
      "           Conv2d-64           [-1, 19, 13, 13]           3,249\n",
      "    Encode_Decode-65           [-1, 19, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 19, 13, 13]              38\n",
      "             ReLU-67           [-1, 19, 13, 13]               0\n",
      "           Conv2d-68           [-1, 10, 13, 13]           1,710\n",
      "       conv_layer-69           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 29, 13, 13]              58\n",
      "             ReLU-71           [-1, 29, 13, 13]               0\n",
      "           Conv2d-72           [-1, 10, 13, 13]           2,610\n",
      "       conv_layer-73           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 39, 13, 13]              78\n",
      "             ReLU-75           [-1, 39, 13, 13]               0\n",
      "           Conv2d-76           [-1, 10, 13, 13]           3,510\n",
      "       conv_layer-77           [-1, 49, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 49, 13, 13]              98\n",
      "             ReLU-79           [-1, 49, 13, 13]               0\n",
      "           Conv2d-80           [-1, 10, 13, 13]           4,410\n",
      "       conv_layer-81           [-1, 59, 13, 13]               0\n",
      "      Dense_block-82           [-1, 59, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 59, 13, 13]             118\n",
      "             ReLU-84           [-1, 59, 13, 13]               0\n",
      "           Conv2d-85           [-1, 29, 13, 13]           1,711\n",
      "      BatchNorm2d-86           [-1, 29, 13, 13]              58\n",
      "             ReLU-87           [-1, 29, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 29, 25, 25]           7,569\n",
      "    Encode_Decode-89           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 47, 25, 25]              94\n",
      "             ReLU-91           [-1, 47, 25, 25]               0\n",
      "           Conv2d-92           [-1, 10, 25, 25]           4,230\n",
      "       conv_layer-93           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 57, 25, 25]             114\n",
      "             ReLU-95           [-1, 57, 25, 25]               0\n",
      "           Conv2d-96           [-1, 10, 25, 25]           5,130\n",
      "       conv_layer-97           [-1, 67, 25, 25]               0\n",
      "      Dense_block-98           [-1, 67, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 67, 25, 25]             134\n",
      "            ReLU-100           [-1, 67, 25, 25]               0\n",
      "          Conv2d-101           [-1, 33, 25, 25]           2,211\n",
      "     BatchNorm2d-102           [-1, 33, 25, 25]              66\n",
      "            ReLU-103           [-1, 33, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 33, 50, 50]           9,801\n",
      "   Encode_Decode-105           [-1, 33, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 49, 50, 50]              98\n",
      "            ReLU-107           [-1, 49, 50, 50]               0\n",
      "          Conv2d-108           [-1, 10, 50, 50]           4,410\n",
      "      conv_layer-109           [-1, 59, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 59, 50, 50]             118\n",
      "            ReLU-111           [-1, 59, 50, 50]               0\n",
      "          Conv2d-112           [-1, 10, 50, 50]           5,310\n",
      "      conv_layer-113           [-1, 69, 50, 50]               0\n",
      "     Dense_block-114           [-1, 69, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 69, 50, 50]             138\n",
      "            ReLU-116           [-1, 69, 50, 50]               0\n",
      "          Conv2d-117           [-1, 34, 50, 50]           2,346\n",
      "     BatchNorm2d-118           [-1, 34, 50, 50]              68\n",
      "            ReLU-119           [-1, 34, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 34, 100, 100]          10,404\n",
      "   Encode_Decode-121         [-1, 34, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 10, 100, 100]           4,140\n",
      "      conv_layer-125         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 56, 100, 100]             112\n",
      "            ReLU-127         [-1, 56, 100, 100]               0\n",
      "          Conv2d-128         [-1, 10, 100, 100]           5,040\n",
      "      conv_layer-129         [-1, 66, 100, 100]               0\n",
      "     Dense_block-130         [-1, 66, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 66, 100, 100]             132\n",
      "            ReLU-132         [-1, 66, 100, 100]               0\n",
      "          Conv2d-133         [-1, 33, 100, 100]           2,178\n",
      "     BatchNorm2d-134         [-1, 33, 100, 100]              66\n",
      "            ReLU-135         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 33, 200, 200]           9,801\n",
      "   Encode_Decode-137         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 37, 200, 200]              74\n",
      "            ReLU-139         [-1, 37, 200, 200]               0\n",
      "          Conv2d-140         [-1, 10, 200, 200]           3,330\n",
      "      conv_layer-141         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 47, 200, 200]              94\n",
      "            ReLU-143         [-1, 47, 200, 200]               0\n",
      "          Conv2d-144         [-1, 10, 200, 200]           4,230\n",
      "      conv_layer-145         [-1, 57, 200, 200]               0\n",
      "     Dense_block-146         [-1, 57, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 57, 200, 200]             114\n",
      "            ReLU-148         [-1, 57, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,596\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 123,492\n",
      "Trainable params: 123,492\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 357.48\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 358.56\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          14,161\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           7,497\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          11,466\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          15,435\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          19,404\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          33,124\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          11,466\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          15,435\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          23,716\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 22, 50, 50]              44\n",
      "            ReLU-107           [-1, 22, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]           9,702\n",
      "      conv_layer-109           [-1, 31, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 31, 50, 50]              62\n",
      "            ReLU-111           [-1, 31, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          13,671\n",
      "      conv_layer-113           [-1, 40, 50, 50]               0\n",
      "     Dense_block-114           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 40, 50, 50]              80\n",
      "            ReLU-116           [-1, 40, 50, 50]               0\n",
      "          Conv2d-117           [-1, 20, 50, 50]             800\n",
      "     BatchNorm2d-118           [-1, 20, 50, 50]              40\n",
      "            ReLU-119           [-1, 20, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 20, 100, 100]          19,600\n",
      "   Encode_Decode-121         [-1, 20, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 20, 100, 100]              40\n",
      "            ReLU-123         [-1, 20, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]           8,820\n",
      "      conv_layer-125         [-1, 29, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 29, 100, 100]              58\n",
      "            ReLU-127         [-1, 29, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          12,789\n",
      "      conv_layer-129         [-1, 38, 100, 100]               0\n",
      "     Dense_block-130         [-1, 38, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 38, 100, 100]              76\n",
      "            ReLU-132         [-1, 38, 100, 100]               0\n",
      "          Conv2d-133         [-1, 19, 100, 100]             722\n",
      "     BatchNorm2d-134         [-1, 19, 100, 100]              38\n",
      "            ReLU-135         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 19, 200, 200]          17,689\n",
      "   Encode_Decode-137         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 23, 200, 200]              46\n",
      "            ReLU-139         [-1, 23, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]          10,143\n",
      "      conv_layer-141         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 32, 200, 200]              64\n",
      "            ReLU-143         [-1, 32, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          14,112\n",
      "      conv_layer-145         [-1, 41, 200, 200]               0\n",
      "     Dense_block-146         [-1, 41, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 41, 200, 200]              82\n",
      "            ReLU-148         [-1, 41, 200, 200]               0\n",
      "          Conv2d-149         [-1, 20, 200, 200]             820\n",
      "     BatchNorm2d-150         [-1, 20, 200, 200]              40\n",
      "            ReLU-151         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             320\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 350,691\n",
      "Trainable params: 350,691\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 259.50\n",
      "Params size (MB): 1.34\n",
      "Estimated Total Size (MB): 261.45\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              45\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              54\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 3, 100, 100]               6\n",
      "             ReLU-91          [-1, 3, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              27\n",
      "       conv_layer-93          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 4, 100, 100]               8\n",
      "             ReLU-95          [-1, 4, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              36\n",
      "       conv_layer-97          [-1, 5, 100, 100]               0\n",
      "      Dense_block-98          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 5, 100, 100]              10\n",
      "            ReLU-100          [-1, 5, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]              36\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 2, 200, 200]               4\n",
      "            ReLU-107          [-1, 2, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              18\n",
      "      conv_layer-109          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 3, 200, 200]               6\n",
      "            ReLU-111          [-1, 3, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              27\n",
      "      conv_layer-113          [-1, 4, 200, 200]               0\n",
      "     Dense_block-114          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 4, 200, 200]               8\n",
      "            ReLU-116          [-1, 4, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,366\n",
      "Trainable params: 1,366\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 44.37\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 44.99\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 4, 200, 200]           1,296\n",
      "        conv_layer-5          [-1, 8, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 8, 200, 200]              16\n",
      "              ReLU-7          [-1, 8, 200, 200]               0\n",
      "            Conv2d-8          [-1, 4, 200, 200]           2,592\n",
      "        conv_layer-9         [-1, 12, 200, 200]               0\n",
      "      Dense_block-10         [-1, 12, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 12, 200, 200]              24\n",
      "             ReLU-12         [-1, 12, 200, 200]               0\n",
      "           Conv2d-13          [-1, 6, 200, 200]              72\n",
      "      BatchNorm2d-14          [-1, 6, 200, 200]              12\n",
      "             ReLU-15          [-1, 6, 200, 200]               0\n",
      "           Conv2d-16          [-1, 6, 100, 100]           2,916\n",
      "    Encode_Decode-17          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 6, 100, 100]              12\n",
      "             ReLU-19          [-1, 6, 100, 100]               0\n",
      "           Conv2d-20          [-1, 4, 100, 100]           1,944\n",
      "       conv_layer-21         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 10, 100, 100]              20\n",
      "             ReLU-23         [-1, 10, 100, 100]               0\n",
      "           Conv2d-24          [-1, 4, 100, 100]           3,240\n",
      "       conv_layer-25         [-1, 14, 100, 100]               0\n",
      "      Dense_block-26         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 14, 100, 100]              28\n",
      "             ReLU-28         [-1, 14, 100, 100]               0\n",
      "           Conv2d-29          [-1, 7, 100, 100]              98\n",
      "      BatchNorm2d-30          [-1, 7, 100, 100]              14\n",
      "             ReLU-31          [-1, 7, 100, 100]               0\n",
      "           Conv2d-32            [-1, 7, 50, 50]           3,969\n",
      "    Encode_Decode-33            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 7, 50, 50]              14\n",
      "             ReLU-35            [-1, 7, 50, 50]               0\n",
      "           Conv2d-36            [-1, 4, 50, 50]           2,268\n",
      "       conv_layer-37           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 11, 50, 50]              22\n",
      "             ReLU-39           [-1, 11, 50, 50]               0\n",
      "           Conv2d-40            [-1, 4, 50, 50]           3,564\n",
      "       conv_layer-41           [-1, 15, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 15, 50, 50]              30\n",
      "             ReLU-43           [-1, 15, 50, 50]               0\n",
      "           Conv2d-44            [-1, 4, 50, 50]           4,860\n",
      "       conv_layer-45           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 50, 50]           6,156\n",
      "       conv_layer-49           [-1, 23, 50, 50]               0\n",
      "      Dense_block-50           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 23, 50, 50]              46\n",
      "             ReLU-52           [-1, 23, 50, 50]               0\n",
      "           Conv2d-53           [-1, 11, 50, 50]             253\n",
      "      BatchNorm2d-54           [-1, 11, 50, 50]              22\n",
      "             ReLU-55           [-1, 11, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 11, 100, 100]           9,801\n",
      "    Encode_Decode-57         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 11, 100, 100]              22\n",
      "             ReLU-59         [-1, 11, 100, 100]               0\n",
      "           Conv2d-60          [-1, 4, 100, 100]           3,564\n",
      "       conv_layer-61         [-1, 15, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 15, 100, 100]              30\n",
      "             ReLU-63         [-1, 15, 100, 100]               0\n",
      "           Conv2d-64          [-1, 4, 100, 100]           4,860\n",
      "       conv_layer-65         [-1, 19, 100, 100]               0\n",
      "      Dense_block-66         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 19, 100, 100]              38\n",
      "             ReLU-68         [-1, 19, 100, 100]               0\n",
      "           Conv2d-69          [-1, 9, 100, 100]             171\n",
      "      BatchNorm2d-70          [-1, 9, 100, 100]              18\n",
      "             ReLU-71          [-1, 9, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 9, 200, 200]           6,561\n",
      "    Encode_Decode-73          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 13, 200, 200]              26\n",
      "             ReLU-75         [-1, 13, 200, 200]               0\n",
      "           Conv2d-76          [-1, 4, 200, 200]           4,212\n",
      "       conv_layer-77         [-1, 17, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 17, 200, 200]              34\n",
      "             ReLU-79         [-1, 17, 200, 200]               0\n",
      "           Conv2d-80          [-1, 4, 200, 200]           5,508\n",
      "       conv_layer-81         [-1, 21, 200, 200]               0\n",
      "      Dense_block-82         [-1, 21, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 21, 200, 200]              42\n",
      "             ReLU-84         [-1, 21, 200, 200]               0\n",
      "           Conv2d-85         [-1, 10, 200, 200]             210\n",
      "      BatchNorm2d-86         [-1, 10, 200, 200]              20\n",
      "             ReLU-87         [-1, 10, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             160\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 68,955\n",
      "Trainable params: 68,955\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 133.90\n",
      "Params size (MB): 0.26\n",
      "Estimated Total Size (MB): 134.77\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 9\n",
      "growth_rate= 4\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              36\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              45\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,294\n",
      "Trainable params: 1,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 54.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              45\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              54\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 3, 100, 100]               6\n",
      "             ReLU-91          [-1, 3, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              27\n",
      "       conv_layer-93          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 4, 100, 100]               8\n",
      "             ReLU-95          [-1, 4, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              36\n",
      "       conv_layer-97          [-1, 5, 100, 100]               0\n",
      "      Dense_block-98          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 5, 100, 100]              10\n",
      "            ReLU-100          [-1, 5, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]              36\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 2, 200, 200]               4\n",
      "            ReLU-107          [-1, 2, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              18\n",
      "      conv_layer-109          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 3, 200, 200]               6\n",
      "            ReLU-111          [-1, 3, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              27\n",
      "      conv_layer-113          [-1, 4, 200, 200]               0\n",
      "     Dense_block-114          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 4, 200, 200]               8\n",
      "            ReLU-116          [-1, 4, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,366\n",
      "Trainable params: 1,366\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 44.37\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 44.99\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 |     179 |      22 |  0.004663176 |            f\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]              36\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]              45\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]              81\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              27\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]              36\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]              36\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              45\n",
      "       conv_layer-93          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 6, 100, 100]              12\n",
      "             ReLU-95          [-1, 6, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              54\n",
      "       conv_layer-97          [-1, 7, 100, 100]               0\n",
      "      Dense_block-98          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 7, 100, 100]              14\n",
      "            ReLU-100          [-1, 7, 100, 100]               0\n",
      "          Conv2d-101          [-1, 3, 100, 100]              21\n",
      "     BatchNorm2d-102          [-1, 3, 100, 100]               6\n",
      "            ReLU-103          [-1, 3, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 3, 200, 200]              81\n",
      "   Encode_Decode-105          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 3, 200, 200]               6\n",
      "            ReLU-107          [-1, 3, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              27\n",
      "      conv_layer-109          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 4, 200, 200]               8\n",
      "            ReLU-111          [-1, 4, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              36\n",
      "      conv_layer-113          [-1, 5, 200, 200]               0\n",
      "     Dense_block-114          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 5, 200, 200]              10\n",
      "            ReLU-116          [-1, 5, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]              10\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,392\n",
      "Trainable params: 1,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 48.78\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 49.39\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]           1,568\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           4,704\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           3,920\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           7,056\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           8,281\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           5,096\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           8,232\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           9,604\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           5,488\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           8,624\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 30, 25, 25]              60\n",
      "             ReLU-59           [-1, 30, 25, 25]               0\n",
      "           Conv2d-60            [-1, 8, 25, 25]          11,760\n",
      "       conv_layer-61           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 38, 25, 25]              76\n",
      "             ReLU-63           [-1, 38, 25, 25]               0\n",
      "           Conv2d-64            [-1, 8, 25, 25]          14,896\n",
      "       conv_layer-65           [-1, 46, 25, 25]               0\n",
      "      Dense_block-66           [-1, 46, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 46, 25, 25]              92\n",
      "             ReLU-68           [-1, 46, 25, 25]               0\n",
      "           Conv2d-69           [-1, 23, 25, 25]           1,058\n",
      "      BatchNorm2d-70           [-1, 23, 25, 25]              46\n",
      "             ReLU-71           [-1, 23, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 23, 50, 50]          25,921\n",
      "    Encode_Decode-73           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 23, 50, 50]              46\n",
      "             ReLU-75           [-1, 23, 50, 50]               0\n",
      "           Conv2d-76            [-1, 8, 50, 50]           9,016\n",
      "       conv_layer-77           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 31, 50, 50]              62\n",
      "             ReLU-79           [-1, 31, 50, 50]               0\n",
      "           Conv2d-80            [-1, 8, 50, 50]          12,152\n",
      "       conv_layer-81           [-1, 39, 50, 50]               0\n",
      "      Dense_block-82           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 39, 50, 50]              78\n",
      "             ReLU-84           [-1, 39, 50, 50]               0\n",
      "           Conv2d-85           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-86           [-1, 19, 50, 50]              38\n",
      "             ReLU-87           [-1, 19, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 19, 100, 100]          17,689\n",
      "    Encode_Decode-89         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 29, 100, 100]              58\n",
      "             ReLU-91         [-1, 29, 100, 100]               0\n",
      "           Conv2d-92          [-1, 8, 100, 100]          11,368\n",
      "       conv_layer-93         [-1, 37, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 37, 100, 100]              74\n",
      "             ReLU-95         [-1, 37, 100, 100]               0\n",
      "           Conv2d-96          [-1, 8, 100, 100]          14,504\n",
      "       conv_layer-97         [-1, 45, 100, 100]               0\n",
      "      Dense_block-98         [-1, 45, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 45, 100, 100]              90\n",
      "            ReLU-100         [-1, 45, 100, 100]               0\n",
      "          Conv2d-101         [-1, 22, 100, 100]             990\n",
      "     BatchNorm2d-102         [-1, 22, 100, 100]              44\n",
      "            ReLU-103         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 22, 200, 200]          23,716\n",
      "   Encode_Decode-105         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 26, 200, 200]              52\n",
      "            ReLU-107         [-1, 26, 200, 200]               0\n",
      "          Conv2d-108          [-1, 8, 200, 200]          10,192\n",
      "      conv_layer-109         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 34, 200, 200]              68\n",
      "            ReLU-111         [-1, 34, 200, 200]               0\n",
      "          Conv2d-112          [-1, 8, 200, 200]          13,328\n",
      "      conv_layer-113         [-1, 42, 200, 200]               0\n",
      "     Dense_block-114         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 42, 200, 200]              84\n",
      "            ReLU-116         [-1, 42, 200, 200]               0\n",
      "          Conv2d-117         [-1, 21, 200, 200]             882\n",
      "     BatchNorm2d-118         [-1, 21, 200, 200]              42\n",
      "            ReLU-119         [-1, 21, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             336\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 238,572\n",
      "Trainable params: 238,572\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 262.75\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 264.27\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 39, 50, 50]              78\n",
      "             ReLU-43           [-1, 39, 50, 50]               0\n",
      "           Conv2d-44           [-1, 11, 50, 50]           3,861\n",
      "       conv_layer-45           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 50, 50, 50]             100\n",
      "             ReLU-47           [-1, 50, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 50, 50]           4,950\n",
      "       conv_layer-49           [-1, 61, 50, 50]               0\n",
      "      Dense_block-50           [-1, 61, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 61, 50, 50]             122\n",
      "             ReLU-52           [-1, 61, 50, 50]               0\n",
      "           Conv2d-53           [-1, 30, 50, 50]           1,830\n",
      "      BatchNorm2d-54           [-1, 30, 50, 50]              60\n",
      "             ReLU-55           [-1, 30, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 30, 100, 100]           8,100\n",
      "    Encode_Decode-57         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 43, 100, 100]              86\n",
      "             ReLU-59         [-1, 43, 100, 100]               0\n",
      "           Conv2d-60         [-1, 11, 100, 100]           4,257\n",
      "       conv_layer-61         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 54, 100, 100]             108\n",
      "             ReLU-63         [-1, 54, 100, 100]               0\n",
      "           Conv2d-64         [-1, 11, 100, 100]           5,346\n",
      "       conv_layer-65         [-1, 65, 100, 100]               0\n",
      "      Dense_block-66         [-1, 65, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 65, 100, 100]             130\n",
      "             ReLU-68         [-1, 65, 100, 100]               0\n",
      "           Conv2d-69         [-1, 32, 100, 100]           2,080\n",
      "      BatchNorm2d-70         [-1, 32, 100, 100]              64\n",
      "             ReLU-71         [-1, 32, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 32, 200, 200]           9,216\n",
      "    Encode_Decode-73         [-1, 32, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 36, 200, 200]              72\n",
      "             ReLU-75         [-1, 36, 200, 200]               0\n",
      "           Conv2d-76         [-1, 11, 200, 200]           3,564\n",
      "       conv_layer-77         [-1, 47, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 47, 200, 200]              94\n",
      "             ReLU-79         [-1, 47, 200, 200]               0\n",
      "           Conv2d-80         [-1, 11, 200, 200]           4,653\n",
      "       conv_layer-81         [-1, 58, 200, 200]               0\n",
      "      Dense_block-82         [-1, 58, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 58, 200, 200]             116\n",
      "             ReLU-84         [-1, 58, 200, 200]               0\n",
      "           Conv2d-85         [-1, 29, 200, 200]           1,682\n",
      "      BatchNorm2d-86         [-1, 29, 200, 200]              58\n",
      "             ReLU-87         [-1, 29, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             464\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 66,673\n",
      "Trainable params: 66,673\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 352.04\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 352.90\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 3, 100, 100]               6\n",
      "             ReLU-91          [-1, 3, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              75\n",
      "       conv_layer-93          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 4, 100, 100]               8\n",
      "             ReLU-95          [-1, 4, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             100\n",
      "       conv_layer-97          [-1, 5, 100, 100]               0\n",
      "      Dense_block-98          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 5, 100, 100]              10\n",
      "            ReLU-100          [-1, 5, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 2, 200, 200]               4\n",
      "            ReLU-107          [-1, 2, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]              50\n",
      "      conv_layer-109          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 3, 200, 200]               6\n",
      "            ReLU-111          [-1, 3, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]              75\n",
      "      conv_layer-113          [-1, 4, 200, 200]               0\n",
      "     Dense_block-114          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 4, 200, 200]               8\n",
      "            ReLU-116          [-1, 4, 200, 200]               0\n",
      "          Conv2d-117          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-118          [-1, 2, 200, 200]               4\n",
      "            ReLU-119          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              32\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,918\n",
      "Trainable params: 2,918\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 44.37\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 44.99\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      Dense_block-58           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 23, 25, 25]              46\n",
      "             ReLU-60           [-1, 23, 25, 25]               0\n",
      "           Conv2d-61           [-1, 11, 25, 25]             253\n",
      "      BatchNorm2d-62           [-1, 11, 25, 25]              22\n",
      "             ReLU-63           [-1, 11, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 13, 13]           1,089\n",
      "    Encode_Decode-65           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 11, 13, 13]              22\n",
      "             ReLU-67           [-1, 11, 13, 13]               0\n",
      "           Conv2d-68            [-1, 6, 13, 13]             594\n",
      "       conv_layer-69           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 17, 13, 13]              34\n",
      "             ReLU-71           [-1, 17, 13, 13]               0\n",
      "           Conv2d-72            [-1, 6, 13, 13]             918\n",
      "       conv_layer-73           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 23, 13, 13]              46\n",
      "             ReLU-75           [-1, 23, 13, 13]               0\n",
      "           Conv2d-76            [-1, 6, 13, 13]           1,242\n",
      "       conv_layer-77           [-1, 29, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 29, 13, 13]              58\n",
      "             ReLU-79           [-1, 29, 13, 13]               0\n",
      "           Conv2d-80            [-1, 6, 13, 13]           1,566\n",
      "       conv_layer-81           [-1, 35, 13, 13]               0\n",
      "      Dense_block-82           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 35, 13, 13]              70\n",
      "             ReLU-84           [-1, 35, 13, 13]               0\n",
      "           Conv2d-85           [-1, 17, 13, 13]             595\n",
      "      BatchNorm2d-86           [-1, 17, 13, 13]              34\n",
      "             ReLU-87           [-1, 17, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 17, 25, 25]           2,601\n",
      "    Encode_Decode-89           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 17, 25, 25]              34\n",
      "             ReLU-91           [-1, 17, 25, 25]               0\n",
      "           Conv2d-92            [-1, 6, 25, 25]             918\n",
      "       conv_layer-93           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 23, 25, 25]              46\n",
      "             ReLU-95           [-1, 23, 25, 25]               0\n",
      "           Conv2d-96            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-97           [-1, 29, 25, 25]               0\n",
      "      Dense_block-98           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 29, 25, 25]              58\n",
      "            ReLU-100           [-1, 29, 25, 25]               0\n",
      "          Conv2d-101           [-1, 14, 25, 25]             406\n",
      "     BatchNorm2d-102           [-1, 14, 25, 25]              28\n",
      "            ReLU-103           [-1, 14, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 14, 50, 50]           1,764\n",
      "   Encode_Decode-105           [-1, 14, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 24, 50, 50]              48\n",
      "            ReLU-107           [-1, 24, 50, 50]               0\n",
      "          Conv2d-108            [-1, 6, 50, 50]           1,296\n",
      "      conv_layer-109           [-1, 30, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 30, 50, 50]              60\n",
      "            ReLU-111           [-1, 30, 50, 50]               0\n",
      "          Conv2d-112            [-1, 6, 50, 50]           1,620\n",
      "      conv_layer-113           [-1, 36, 50, 50]               0\n",
      "     Dense_block-114           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 36, 50, 50]              72\n",
      "            ReLU-116           [-1, 36, 50, 50]               0\n",
      "          Conv2d-117           [-1, 18, 50, 50]             648\n",
      "     BatchNorm2d-118           [-1, 18, 50, 50]              36\n",
      "            ReLU-119           [-1, 18, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 18, 100, 100]           2,916\n",
      "   Encode_Decode-121         [-1, 18, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 26, 100, 100]              52\n",
      "            ReLU-123         [-1, 26, 100, 100]               0\n",
      "          Conv2d-124          [-1, 6, 100, 100]           1,404\n",
      "      conv_layer-125         [-1, 32, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 32, 100, 100]              64\n",
      "            ReLU-127         [-1, 32, 100, 100]               0\n",
      "          Conv2d-128          [-1, 6, 100, 100]           1,728\n",
      "      conv_layer-129         [-1, 38, 100, 100]               0\n",
      "     Dense_block-130         [-1, 38, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 38, 100, 100]              76\n",
      "            ReLU-132         [-1, 38, 100, 100]               0\n",
      "          Conv2d-133         [-1, 19, 100, 100]             722\n",
      "     BatchNorm2d-134         [-1, 19, 100, 100]              38\n",
      "            ReLU-135         [-1, 19, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 19, 200, 200]           3,249\n",
      "   Encode_Decode-137         [-1, 19, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 23, 200, 200]              46\n",
      "            ReLU-139         [-1, 23, 200, 200]               0\n",
      "          Conv2d-140          [-1, 6, 200, 200]           1,242\n",
      "      conv_layer-141         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 29, 200, 200]              58\n",
      "            ReLU-143         [-1, 29, 200, 200]               0\n",
      "          Conv2d-144          [-1, 6, 200, 200]           1,566\n",
      "      conv_layer-145         [-1, 35, 200, 200]               0\n",
      "     Dense_block-146         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 35, 200, 200]              70\n",
      "            ReLU-148         [-1, 35, 200, 200]               0\n",
      "          Conv2d-149         [-1, 17, 200, 200]             595\n",
      "     BatchNorm2d-150         [-1, 17, 200, 200]              34\n",
      "            ReLU-151         [-1, 17, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             272\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 40,091\n",
      "Trainable params: 40,091\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 220.32\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 221.09\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 3, 200, 200]             972\n",
      "        conv_layer-5          [-1, 7, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 7, 200, 200]              14\n",
      "              ReLU-7          [-1, 7, 200, 200]               0\n",
      "            Conv2d-8          [-1, 3, 200, 200]           1,701\n",
      "        conv_layer-9         [-1, 10, 200, 200]               0\n",
      "      Dense_block-10         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 10, 200, 200]              20\n",
      "             ReLU-12         [-1, 10, 200, 200]               0\n",
      "           Conv2d-13          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-14          [-1, 5, 200, 200]              10\n",
      "             ReLU-15          [-1, 5, 200, 200]               0\n",
      "           Conv2d-16          [-1, 5, 100, 100]           2,025\n",
      "    Encode_Decode-17          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 5, 100, 100]              10\n",
      "             ReLU-19          [-1, 5, 100, 100]               0\n",
      "           Conv2d-20          [-1, 3, 100, 100]           1,215\n",
      "       conv_layer-21          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 8, 100, 100]              16\n",
      "             ReLU-23          [-1, 8, 100, 100]               0\n",
      "           Conv2d-24          [-1, 3, 100, 100]           1,944\n",
      "       conv_layer-25         [-1, 11, 100, 100]               0\n",
      "      Dense_block-26         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 11, 100, 100]              22\n",
      "             ReLU-28         [-1, 11, 100, 100]               0\n",
      "           Conv2d-29          [-1, 5, 100, 100]              55\n",
      "      BatchNorm2d-30          [-1, 5, 100, 100]              10\n",
      "             ReLU-31          [-1, 5, 100, 100]               0\n",
      "           Conv2d-32            [-1, 5, 50, 50]           2,025\n",
      "    Encode_Decode-33            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 5, 50, 50]              10\n",
      "             ReLU-35            [-1, 5, 50, 50]               0\n",
      "           Conv2d-36            [-1, 3, 50, 50]           1,215\n",
      "       conv_layer-37            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 8, 50, 50]              16\n",
      "             ReLU-39            [-1, 8, 50, 50]               0\n",
      "           Conv2d-40            [-1, 3, 50, 50]           1,944\n",
      "       conv_layer-41           [-1, 11, 50, 50]               0\n",
      "      Dense_block-42           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 11, 50, 50]              22\n",
      "             ReLU-44           [-1, 11, 50, 50]               0\n",
      "           Conv2d-45            [-1, 5, 50, 50]              55\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 5, 25, 25]           2,025\n",
      "    Encode_Decode-49            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 5, 25, 25]              10\n",
      "             ReLU-51            [-1, 5, 25, 25]               0\n",
      "           Conv2d-52            [-1, 3, 25, 25]           1,215\n",
      "       conv_layer-53            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 8, 25, 25]              16\n",
      "             ReLU-55            [-1, 8, 25, 25]               0\n",
      "           Conv2d-56            [-1, 3, 25, 25]           1,944\n",
      "       conv_layer-57           [-1, 11, 25, 25]               0\n",
      "      Dense_block-58           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 11, 25, 25]              22\n",
      "             ReLU-60           [-1, 11, 25, 25]               0\n",
      "           Conv2d-61            [-1, 5, 25, 25]              55\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 13, 13]           2,025\n",
      "    Encode_Decode-65            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 5, 13, 13]              10\n",
      "             ReLU-67            [-1, 5, 13, 13]               0\n",
      "           Conv2d-68            [-1, 3, 13, 13]           1,215\n",
      "       conv_layer-69            [-1, 8, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 8, 13, 13]              16\n",
      "             ReLU-71            [-1, 8, 13, 13]               0\n",
      "           Conv2d-72            [-1, 3, 13, 13]           1,944\n",
      "       conv_layer-73           [-1, 11, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 11, 13, 13]              22\n",
      "             ReLU-75           [-1, 11, 13, 13]               0\n",
      "           Conv2d-76            [-1, 3, 13, 13]           2,673\n",
      "       conv_layer-77           [-1, 14, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 14, 13, 13]              28\n",
      "             ReLU-79           [-1, 14, 13, 13]               0\n",
      "           Conv2d-80            [-1, 3, 13, 13]           3,402\n",
      "       conv_layer-81           [-1, 17, 13, 13]               0\n",
      "      Dense_block-82           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 17, 13, 13]              34\n",
      "             ReLU-84           [-1, 17, 13, 13]               0\n",
      "           Conv2d-85            [-1, 8, 13, 13]             136\n",
      "      BatchNorm2d-86            [-1, 8, 13, 13]              16\n",
      "             ReLU-87            [-1, 8, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 8, 25, 25]           5,184\n",
      "    Encode_Decode-89            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 13, 25, 25]              26\n",
      "             ReLU-91           [-1, 13, 25, 25]               0\n",
      "           Conv2d-92            [-1, 3, 25, 25]           3,159\n",
      "       conv_layer-93           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 16, 25, 25]              32\n",
      "             ReLU-95           [-1, 16, 25, 25]               0\n",
      "           Conv2d-96            [-1, 3, 25, 25]           3,888\n",
      "       conv_layer-97           [-1, 19, 25, 25]               0\n",
      "      Dense_block-98           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 19, 25, 25]              38\n",
      "            ReLU-100           [-1, 19, 25, 25]               0\n",
      "          Conv2d-101            [-1, 9, 25, 25]             171\n",
      "     BatchNorm2d-102            [-1, 9, 25, 25]              18\n",
      "            ReLU-103            [-1, 9, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 9, 50, 50]           6,561\n",
      "   Encode_Decode-105            [-1, 9, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 14, 50, 50]              28\n",
      "            ReLU-107           [-1, 14, 50, 50]               0\n",
      "          Conv2d-108            [-1, 3, 50, 50]           3,402\n",
      "      conv_layer-109           [-1, 17, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 17, 50, 50]              34\n",
      "            ReLU-111           [-1, 17, 50, 50]               0\n",
      "          Conv2d-112            [-1, 3, 50, 50]           4,131\n",
      "      conv_layer-113           [-1, 20, 50, 50]               0\n",
      "     Dense_block-114           [-1, 20, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 20, 50, 50]              40\n",
      "            ReLU-116           [-1, 20, 50, 50]               0\n",
      "          Conv2d-117           [-1, 10, 50, 50]             200\n",
      "     BatchNorm2d-118           [-1, 10, 50, 50]              20\n",
      "            ReLU-119           [-1, 10, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 10, 100, 100]           8,100\n",
      "   Encode_Decode-121         [-1, 10, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 15, 100, 100]              30\n",
      "            ReLU-123         [-1, 15, 100, 100]               0\n",
      "          Conv2d-124          [-1, 3, 100, 100]           3,645\n",
      "      conv_layer-125         [-1, 18, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 18, 100, 100]              36\n",
      "            ReLU-127         [-1, 18, 100, 100]               0\n",
      "          Conv2d-128          [-1, 3, 100, 100]           4,374\n",
      "      conv_layer-129         [-1, 21, 100, 100]               0\n",
      "     Dense_block-130         [-1, 21, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 21, 100, 100]              42\n",
      "            ReLU-132         [-1, 21, 100, 100]               0\n",
      "          Conv2d-133         [-1, 10, 100, 100]             210\n",
      "     BatchNorm2d-134         [-1, 10, 100, 100]              20\n",
      "            ReLU-135         [-1, 10, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 10, 200, 200]           8,100\n",
      "   Encode_Decode-137         [-1, 10, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 10, 200, 200]              20\n",
      "            ReLU-139         [-1, 10, 200, 200]               0\n",
      "          Conv2d-140          [-1, 3, 200, 200]           2,430\n",
      "      conv_layer-141         [-1, 13, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 13, 200, 200]              26\n",
      "            ReLU-143         [-1, 13, 200, 200]               0\n",
      "          Conv2d-144          [-1, 3, 200, 200]           3,159\n",
      "      conv_layer-145         [-1, 16, 200, 200]               0\n",
      "     Dense_block-146         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 16, 200, 200]              32\n",
      "            ReLU-148         [-1, 16, 200, 200]               0\n",
      "          Conv2d-149          [-1, 8, 200, 200]             128\n",
      "     BatchNorm2d-150          [-1, 8, 200, 200]              16\n",
      "            ReLU-151          [-1, 8, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             128\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 87,759\n",
      "Trainable params: 87,759\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 117.23\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 118.17\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 9\n",
      "growth_rate= 3\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]           1,568\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           4,704\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           3,920\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           7,056\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           8,281\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           5,096\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           8,232\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           9,604\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           5,488\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           8,624\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]          11,025\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           5,880\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           9,016\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]          12,152\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]          15,288\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]          25,921\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 37, 25, 25]              74\n",
      "             ReLU-91           [-1, 37, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]          14,504\n",
      "       conv_layer-93           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 45, 25, 25]              90\n",
      "             ReLU-95           [-1, 45, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]          17,640\n",
      "       conv_layer-97           [-1, 53, 25, 25]               0\n",
      "      Dense_block-98           [-1, 53, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 53, 25, 25]             106\n",
      "            ReLU-100           [-1, 53, 25, 25]               0\n",
      "          Conv2d-101           [-1, 26, 25, 25]           1,378\n",
      "     BatchNorm2d-102           [-1, 26, 25, 25]              52\n",
      "            ReLU-103           [-1, 26, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 26, 50, 50]          33,124\n",
      "   Encode_Decode-105           [-1, 26, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 39, 50, 50]              78\n",
      "            ReLU-107           [-1, 39, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]          15,288\n",
      "      conv_layer-109           [-1, 47, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 47, 50, 50]              94\n",
      "            ReLU-111           [-1, 47, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]          18,424\n",
      "      conv_layer-113           [-1, 55, 50, 50]               0\n",
      "     Dense_block-114           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 55, 50, 50]             110\n",
      "            ReLU-116           [-1, 55, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,485\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          35,721\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 37, 100, 100]              74\n",
      "            ReLU-123         [-1, 37, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]          14,504\n",
      "      conv_layer-125         [-1, 45, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 45, 100, 100]              90\n",
      "            ReLU-127         [-1, 45, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]          17,640\n",
      "      conv_layer-129         [-1, 53, 100, 100]               0\n",
      "     Dense_block-130         [-1, 53, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 53, 100, 100]             106\n",
      "            ReLU-132         [-1, 53, 100, 100]               0\n",
      "          Conv2d-133         [-1, 26, 100, 100]           1,378\n",
      "     BatchNorm2d-134         [-1, 26, 100, 100]              52\n",
      "            ReLU-135         [-1, 26, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 26, 200, 200]          33,124\n",
      "   Encode_Decode-137         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 30, 200, 200]              60\n",
      "            ReLU-139         [-1, 30, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]          11,760\n",
      "      conv_layer-141         [-1, 38, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 38, 200, 200]              76\n",
      "            ReLU-143         [-1, 38, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]          14,896\n",
      "      conv_layer-145         [-1, 46, 200, 200]               0\n",
      "     Dense_block-146         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 46, 200, 200]              92\n",
      "            ReLU-148         [-1, 46, 200, 200]               0\n",
      "          Conv2d-149         [-1, 23, 200, 200]           1,058\n",
      "     BatchNorm2d-150         [-1, 23, 200, 200]              46\n",
      "            ReLU-151         [-1, 23, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             368\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 383,818\n",
      "Trainable params: 383,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 290.97\n",
      "Params size (MB): 1.46\n",
      "Estimated Total Size (MB): 293.05\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 34, 25, 25]              68\n",
      "             ReLU-59           [-1, 34, 25, 25]               0\n",
      "           Conv2d-60            [-1, 9, 25, 25]          14,994\n",
      "       conv_layer-61           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 43, 25, 25]              86\n",
      "             ReLU-63           [-1, 43, 25, 25]               0\n",
      "           Conv2d-64            [-1, 9, 25, 25]          18,963\n",
      "       conv_layer-65           [-1, 52, 25, 25]               0\n",
      "      Dense_block-66           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 52, 25, 25]             104\n",
      "             ReLU-68           [-1, 52, 25, 25]               0\n",
      "           Conv2d-69           [-1, 26, 25, 25]           1,352\n",
      "      BatchNorm2d-70           [-1, 26, 25, 25]              52\n",
      "             ReLU-71           [-1, 26, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 26, 50, 50]          33,124\n",
      "    Encode_Decode-73           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 40, 50, 50]              80\n",
      "             ReLU-75           [-1, 40, 50, 50]               0\n",
      "           Conv2d-76            [-1, 9, 50, 50]          17,640\n",
      "       conv_layer-77           [-1, 49, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 49, 50, 50]              98\n",
      "             ReLU-79           [-1, 49, 50, 50]               0\n",
      "           Conv2d-80            [-1, 9, 50, 50]          21,609\n",
      "       conv_layer-81           [-1, 58, 50, 50]               0\n",
      "      Dense_block-82           [-1, 58, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 58, 50, 50]             116\n",
      "             ReLU-84           [-1, 58, 50, 50]               0\n",
      "           Conv2d-85           [-1, 29, 50, 50]           1,682\n",
      "      BatchNorm2d-86           [-1, 29, 50, 50]              58\n",
      "             ReLU-87           [-1, 29, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 29, 100, 100]          41,209\n",
      "    Encode_Decode-89         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 40, 100, 100]              80\n",
      "             ReLU-91         [-1, 40, 100, 100]               0\n",
      "           Conv2d-92          [-1, 9, 100, 100]          17,640\n",
      "       conv_layer-93         [-1, 49, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 49, 100, 100]              98\n",
      "             ReLU-95         [-1, 49, 100, 100]               0\n",
      "           Conv2d-96          [-1, 9, 100, 100]          21,609\n",
      "       conv_layer-97         [-1, 58, 100, 100]               0\n",
      "      Dense_block-98         [-1, 58, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 58, 100, 100]             116\n",
      "            ReLU-100         [-1, 58, 100, 100]               0\n",
      "          Conv2d-101         [-1, 29, 100, 100]           1,682\n",
      "     BatchNorm2d-102         [-1, 29, 100, 100]              58\n",
      "            ReLU-103         [-1, 29, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 29, 200, 200]          41,209\n",
      "   Encode_Decode-105         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 33, 200, 200]              66\n",
      "            ReLU-107         [-1, 33, 200, 200]               0\n",
      "          Conv2d-108          [-1, 9, 200, 200]          14,553\n",
      "      conv_layer-109         [-1, 42, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 42, 200, 200]              84\n",
      "            ReLU-111         [-1, 42, 200, 200]               0\n",
      "          Conv2d-112          [-1, 9, 200, 200]          18,522\n",
      "      conv_layer-113         [-1, 51, 200, 200]               0\n",
      "     Dense_block-114         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 51, 200, 200]             102\n",
      "            ReLU-116         [-1, 51, 200, 200]               0\n",
      "          Conv2d-117         [-1, 25, 200, 200]           1,275\n",
      "     BatchNorm2d-118         [-1, 25, 200, 200]              50\n",
      "            ReLU-119         [-1, 25, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             400\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 354,226\n",
      "Trainable params: 354,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 317.31\n",
      "Params size (MB): 1.35\n",
      "Estimated Total Size (MB): 319.27\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]              36\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]              45\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              54\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]              63\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             144\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              72\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              81\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,458\n",
      "Trainable params: 1,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 66.93\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 34, 50, 50]              68\n",
      "             ReLU-75           [-1, 34, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          10,200\n",
      "       conv_layer-77           [-1, 46, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 46, 50, 50]              92\n",
      "             ReLU-79           [-1, 46, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          13,800\n",
      "       conv_layer-81           [-1, 58, 50, 50]               0\n",
      "      Dense_block-82           [-1, 58, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 58, 50, 50]             116\n",
      "             ReLU-84           [-1, 58, 50, 50]               0\n",
      "           Conv2d-85           [-1, 29, 50, 50]           1,682\n",
      "      BatchNorm2d-86           [-1, 29, 50, 50]              58\n",
      "             ReLU-87           [-1, 29, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 29, 100, 100]          21,025\n",
      "    Encode_Decode-89         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 43, 100, 100]              86\n",
      "             ReLU-91         [-1, 43, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          12,900\n",
      "       conv_layer-93         [-1, 55, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 55, 100, 100]             110\n",
      "             ReLU-95         [-1, 55, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          16,500\n",
      "       conv_layer-97         [-1, 67, 100, 100]               0\n",
      "      Dense_block-98         [-1, 67, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 67, 100, 100]             134\n",
      "            ReLU-100         [-1, 67, 100, 100]               0\n",
      "          Conv2d-101         [-1, 33, 100, 100]           2,211\n",
      "     BatchNorm2d-102         [-1, 33, 100, 100]              66\n",
      "            ReLU-103         [-1, 33, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 33, 200, 200]          27,225\n",
      "   Encode_Decode-105         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 37, 200, 200]              74\n",
      "            ReLU-107         [-1, 37, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]          11,100\n",
      "      conv_layer-109         [-1, 49, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 49, 200, 200]              98\n",
      "            ReLU-111         [-1, 49, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          14,700\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 273,958\n",
      "Trainable params: 273,958\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 377.61\n",
      "Params size (MB): 1.05\n",
      "Estimated Total Size (MB): 379.27\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             100\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             125\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 3, 100, 100]               6\n",
      "             ReLU-59          [-1, 3, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]              75\n",
      "       conv_layer-61          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 4, 100, 100]               8\n",
      "             ReLU-63          [-1, 4, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             100\n",
      "       conv_layer-65          [-1, 5, 100, 100]               0\n",
      "      Dense_block-66          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 5, 100, 100]              10\n",
      "             ReLU-68          [-1, 5, 100, 100]               0\n",
      "           Conv2d-69          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-70          [-1, 2, 100, 100]               4\n",
      "             ReLU-71          [-1, 2, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 2, 200, 200]             100\n",
      "    Encode_Decode-73          [-1, 2, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 2, 200, 200]               4\n",
      "             ReLU-75          [-1, 2, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]              50\n",
      "       conv_layer-77          [-1, 3, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 3, 200, 200]               6\n",
      "             ReLU-79          [-1, 3, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]              75\n",
      "       conv_layer-81          [-1, 4, 200, 200]               0\n",
      "      Dense_block-82          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 4, 200, 200]               8\n",
      "             ReLU-84          [-1, 4, 200, 200]               0\n",
      "           Conv2d-85          [-1, 2, 200, 200]               8\n",
      "      BatchNorm2d-86          [-1, 2, 200, 200]               4\n",
      "             ReLU-87          [-1, 2, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              32\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,100\n",
      "Trainable params: 2,100\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 43.35\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 43.97\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]             200\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             300\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             400\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]             200\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             300\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             400\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]             200\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             300\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      Dense_block-42            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 8, 50, 50]              16\n",
      "             ReLU-44            [-1, 8, 50, 50]               0\n",
      "           Conv2d-45            [-1, 4, 50, 50]              32\n",
      "      BatchNorm2d-46            [-1, 4, 50, 50]               8\n",
      "             ReLU-47            [-1, 4, 50, 50]               0\n",
      "           Conv2d-48            [-1, 4, 25, 25]             400\n",
      "    Encode_Decode-49            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 4, 25, 25]               8\n",
      "             ReLU-51            [-1, 4, 25, 25]               0\n",
      "           Conv2d-52            [-1, 2, 25, 25]             200\n",
      "       conv_layer-53            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 6, 25, 25]              12\n",
      "             ReLU-55            [-1, 6, 25, 25]               0\n",
      "           Conv2d-56            [-1, 2, 25, 25]             300\n",
      "       conv_layer-57            [-1, 8, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 8, 25, 25]              16\n",
      "             ReLU-59            [-1, 8, 25, 25]               0\n",
      "           Conv2d-60            [-1, 2, 25, 25]             400\n",
      "       conv_layer-61           [-1, 10, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 10, 25, 25]              20\n",
      "             ReLU-63           [-1, 10, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 25, 25]             500\n",
      "       conv_layer-65           [-1, 12, 25, 25]               0\n",
      "      Dense_block-66           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 12, 25, 25]              24\n",
      "             ReLU-68           [-1, 12, 25, 25]               0\n",
      "           Conv2d-69            [-1, 6, 25, 25]              72\n",
      "      BatchNorm2d-70            [-1, 6, 25, 25]              12\n",
      "             ReLU-71            [-1, 6, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 6, 50, 50]             900\n",
      "    Encode_Decode-73            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 6, 50, 50]              12\n",
      "             ReLU-75            [-1, 6, 50, 50]               0\n",
      "           Conv2d-76            [-1, 2, 50, 50]             300\n",
      "       conv_layer-77            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 8, 50, 50]              16\n",
      "             ReLU-79            [-1, 8, 50, 50]               0\n",
      "           Conv2d-80            [-1, 2, 50, 50]             400\n",
      "       conv_layer-81           [-1, 10, 50, 50]               0\n",
      "      Dense_block-82           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 10, 50, 50]              20\n",
      "             ReLU-84           [-1, 10, 50, 50]               0\n",
      "           Conv2d-85            [-1, 5, 50, 50]              50\n",
      "      BatchNorm2d-86            [-1, 5, 50, 50]              10\n",
      "             ReLU-87            [-1, 5, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 5, 100, 100]             625\n",
      "    Encode_Decode-89          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 5, 100, 100]              10\n",
      "             ReLU-91          [-1, 5, 100, 100]               0\n",
      "           Conv2d-92          [-1, 2, 100, 100]             250\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 2, 100, 100]             350\n",
      "       conv_layer-97          [-1, 9, 100, 100]               0\n",
      "      Dense_block-98          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 9, 100, 100]              18\n",
      "            ReLU-100          [-1, 9, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              36\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 2, 200, 200]             200\n",
      "      conv_layer-109          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 6, 200, 200]              12\n",
      "            ReLU-111          [-1, 6, 200, 200]               0\n",
      "          Conv2d-112          [-1, 2, 200, 200]             300\n",
      "      conv_layer-113          [-1, 8, 200, 200]               0\n",
      "     Dense_block-114          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 8, 200, 200]              16\n",
      "            ReLU-116          [-1, 8, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 8,695\n",
      "Trainable params: 8,695\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 69.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 69.64\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]           4,059\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]           5,148\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]           8,649\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 48, 50, 50]              96\n",
      "             ReLU-75           [-1, 48, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           4,752\n",
      "       conv_layer-77           [-1, 59, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 59, 50, 50]             118\n",
      "             ReLU-79           [-1, 59, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]           5,841\n",
      "       conv_layer-81           [-1, 70, 50, 50]               0\n",
      "      Dense_block-82           [-1, 70, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 70, 50, 50]             140\n",
      "             ReLU-84           [-1, 70, 50, 50]               0\n",
      "           Conv2d-85           [-1, 35, 50, 50]           2,450\n",
      "      BatchNorm2d-86           [-1, 35, 50, 50]              70\n",
      "             ReLU-87           [-1, 35, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 35, 100, 100]          11,025\n",
      "    Encode_Decode-89         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 48, 100, 100]              96\n",
      "             ReLU-91         [-1, 48, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]           4,752\n",
      "       conv_layer-93         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 59, 100, 100]             118\n",
      "             ReLU-95         [-1, 59, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]           5,841\n",
      "       conv_layer-97         [-1, 70, 100, 100]               0\n",
      "      Dense_block-98         [-1, 70, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 70, 100, 100]             140\n",
      "            ReLU-100         [-1, 70, 100, 100]               0\n",
      "          Conv2d-101         [-1, 35, 100, 100]           2,450\n",
      "     BatchNorm2d-102         [-1, 35, 100, 100]              70\n",
      "            ReLU-103         [-1, 35, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 35, 200, 200]          11,025\n",
      "   Encode_Decode-105         [-1, 35, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 39, 200, 200]              78\n",
      "            ReLU-107         [-1, 39, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           3,861\n",
      "      conv_layer-109         [-1, 50, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 50, 200, 200]             100\n",
      "            ReLU-111         [-1, 50, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]           4,950\n",
      "      conv_layer-113         [-1, 61, 200, 200]               0\n",
      "     Dense_block-114         [-1, 61, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 61, 200, 200]             122\n",
      "            ReLU-116         [-1, 61, 200, 200]               0\n",
      "          Conv2d-117         [-1, 30, 200, 200]           1,830\n",
      "     BatchNorm2d-118         [-1, 30, 200, 200]              60\n",
      "            ReLU-119         [-1, 30, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             480\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 105,285\n",
      "Trainable params: 105,285\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 378.22\n",
      "Params size (MB): 0.40\n",
      "Estimated Total Size (MB): 379.23\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             100\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             125\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             150\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             175\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             400\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 8, 200, 200]              16\n",
      "             ReLU-75          [-1, 8, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             200\n",
      "       conv_layer-77          [-1, 9, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 9, 200, 200]              18\n",
      "             ReLU-79          [-1, 9, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             225\n",
      "       conv_layer-81         [-1, 10, 200, 200]               0\n",
      "      Dense_block-82         [-1, 10, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 10, 200, 200]              20\n",
      "             ReLU-84         [-1, 10, 200, 200]               0\n",
      "           Conv2d-85          [-1, 5, 200, 200]              50\n",
      "      BatchNorm2d-86          [-1, 5, 200, 200]              10\n",
      "             ReLU-87          [-1, 5, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              80\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,026\n",
      "Trainable params: 3,026\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 66.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 66.94\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 2, 200, 200]              72\n",
      "        conv_layer-5          [-1, 6, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 6, 200, 200]              12\n",
      "              ReLU-7          [-1, 6, 200, 200]               0\n",
      "            Conv2d-8          [-1, 2, 200, 200]             108\n",
      "        conv_layer-9          [-1, 8, 200, 200]               0\n",
      "      Dense_block-10          [-1, 8, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 8, 200, 200]              16\n",
      "             ReLU-12          [-1, 8, 200, 200]               0\n",
      "           Conv2d-13          [-1, 4, 200, 200]              32\n",
      "      BatchNorm2d-14          [-1, 4, 200, 200]               8\n",
      "             ReLU-15          [-1, 4, 200, 200]               0\n",
      "           Conv2d-16          [-1, 4, 100, 100]             144\n",
      "    Encode_Decode-17          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 4, 100, 100]               8\n",
      "             ReLU-19          [-1, 4, 100, 100]               0\n",
      "           Conv2d-20          [-1, 2, 100, 100]              72\n",
      "       conv_layer-21          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 6, 100, 100]              12\n",
      "             ReLU-23          [-1, 6, 100, 100]               0\n",
      "           Conv2d-24          [-1, 2, 100, 100]             108\n",
      "       conv_layer-25          [-1, 8, 100, 100]               0\n",
      "      Dense_block-26          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 8, 100, 100]              16\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "           Conv2d-29          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-30          [-1, 4, 100, 100]               8\n",
      "             ReLU-31          [-1, 4, 100, 100]               0\n",
      "           Conv2d-32            [-1, 4, 50, 50]             144\n",
      "    Encode_Decode-33            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 4, 50, 50]               8\n",
      "             ReLU-35            [-1, 4, 50, 50]               0\n",
      "           Conv2d-36            [-1, 2, 50, 50]              72\n",
      "       conv_layer-37            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 6, 50, 50]              12\n",
      "             ReLU-39            [-1, 6, 50, 50]               0\n",
      "           Conv2d-40            [-1, 2, 50, 50]             108\n",
      "       conv_layer-41            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 8, 50, 50]              16\n",
      "             ReLU-43            [-1, 8, 50, 50]               0\n",
      "           Conv2d-44            [-1, 2, 50, 50]             144\n",
      "       conv_layer-45           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 10, 50, 50]              20\n",
      "             ReLU-47           [-1, 10, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 50, 50]             180\n",
      "       conv_layer-49           [-1, 12, 50, 50]               0\n",
      "      Dense_block-50           [-1, 12, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 12, 50, 50]              24\n",
      "             ReLU-52           [-1, 12, 50, 50]               0\n",
      "           Conv2d-53            [-1, 6, 50, 50]              72\n",
      "      BatchNorm2d-54            [-1, 6, 50, 50]              12\n",
      "             ReLU-55            [-1, 6, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 6, 100, 100]             324\n",
      "    Encode_Decode-57          [-1, 6, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 2, 100, 100]             108\n",
      "       conv_layer-61          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 8, 100, 100]              16\n",
      "             ReLU-63          [-1, 8, 100, 100]               0\n",
      "           Conv2d-64          [-1, 2, 100, 100]             144\n",
      "       conv_layer-65         [-1, 10, 100, 100]               0\n",
      "      Dense_block-66         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 10, 100, 100]              20\n",
      "             ReLU-68         [-1, 10, 100, 100]               0\n",
      "           Conv2d-69          [-1, 5, 100, 100]              50\n",
      "      BatchNorm2d-70          [-1, 5, 100, 100]              10\n",
      "             ReLU-71          [-1, 5, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 5, 200, 200]             225\n",
      "    Encode_Decode-73          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 9, 200, 200]              18\n",
      "             ReLU-75          [-1, 9, 200, 200]               0\n",
      "           Conv2d-76          [-1, 2, 200, 200]             162\n",
      "       conv_layer-77         [-1, 11, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 11, 200, 200]              22\n",
      "             ReLU-79         [-1, 11, 200, 200]               0\n",
      "           Conv2d-80          [-1, 2, 200, 200]             198\n",
      "       conv_layer-81         [-1, 13, 200, 200]               0\n",
      "      Dense_block-82         [-1, 13, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 13, 200, 200]              26\n",
      "             ReLU-84         [-1, 13, 200, 200]               0\n",
      "           Conv2d-85          [-1, 6, 200, 200]              78\n",
      "      BatchNorm2d-86          [-1, 6, 200, 200]              12\n",
      "             ReLU-87          [-1, 6, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              96\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,133\n",
      "Trainable params: 3,133\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 84.95\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 85.58\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 2\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 5, 50, 50]              10\n",
      "             ReLU-75            [-1, 5, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]             125\n",
      "       conv_layer-77            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 6, 50, 50]              12\n",
      "             ReLU-79            [-1, 6, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             150\n",
      "       conv_layer-81            [-1, 7, 50, 50]               0\n",
      "      Dense_block-82            [-1, 7, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 7, 50, 50]              14\n",
      "             ReLU-84            [-1, 7, 50, 50]               0\n",
      "           Conv2d-85            [-1, 3, 50, 50]              21\n",
      "      BatchNorm2d-86            [-1, 3, 50, 50]               6\n",
      "             ReLU-87            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-89          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 6, 100, 100]              12\n",
      "             ReLU-91          [-1, 6, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]             150\n",
      "       conv_layer-93          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 7, 100, 100]              14\n",
      "             ReLU-95          [-1, 7, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]             175\n",
      "       conv_layer-97          [-1, 8, 100, 100]               0\n",
      "      Dense_block-98          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 8, 100, 100]              16\n",
      "            ReLU-100          [-1, 8, 100, 100]               0\n",
      "          Conv2d-101          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-102          [-1, 4, 100, 100]               8\n",
      "            ReLU-103          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 4, 200, 200]             400\n",
      "   Encode_Decode-105          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 4, 200, 200]               8\n",
      "            ReLU-107          [-1, 4, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             100\n",
      "      conv_layer-109          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 5, 200, 200]              10\n",
      "            ReLU-111          [-1, 5, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             125\n",
      "      conv_layer-113          [-1, 6, 200, 200]               0\n",
      "     Dense_block-114          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 6, 200, 200]              12\n",
      "            ReLU-116          [-1, 6, 200, 200]               0\n",
      "          Conv2d-117          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-118          [-1, 3, 200, 200]               6\n",
      "            ReLU-119          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              48\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,552\n",
      "Trainable params: 3,552\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.52\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.14\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 12, 200, 200]           1,200\n",
      "        conv_layer-5         [-1, 16, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 16, 200, 200]              32\n",
      "              ReLU-7         [-1, 16, 200, 200]               0\n",
      "            Conv2d-8         [-1, 12, 200, 200]           4,800\n",
      "        conv_layer-9         [-1, 28, 200, 200]               0\n",
      "      Dense_block-10         [-1, 28, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 28, 200, 200]              56\n",
      "             ReLU-12         [-1, 28, 200, 200]               0\n",
      "           Conv2d-13         [-1, 14, 200, 200]             392\n",
      "      BatchNorm2d-14         [-1, 14, 200, 200]              28\n",
      "             ReLU-15         [-1, 14, 200, 200]               0\n",
      "           Conv2d-16         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 14, 100, 100]              28\n",
      "             ReLU-19         [-1, 14, 100, 100]               0\n",
      "           Conv2d-20         [-1, 12, 100, 100]           4,200\n",
      "       conv_layer-21         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 26, 100, 100]              52\n",
      "             ReLU-23         [-1, 26, 100, 100]               0\n",
      "           Conv2d-24         [-1, 12, 100, 100]           7,800\n",
      "       conv_layer-25         [-1, 38, 100, 100]               0\n",
      "      Dense_block-26         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 38, 100, 100]              76\n",
      "             ReLU-28         [-1, 38, 100, 100]               0\n",
      "           Conv2d-29         [-1, 19, 100, 100]             722\n",
      "      BatchNorm2d-30         [-1, 19, 100, 100]              38\n",
      "             ReLU-31         [-1, 19, 100, 100]               0\n",
      "           Conv2d-32           [-1, 19, 50, 50]           9,025\n",
      "    Encode_Decode-33           [-1, 19, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 19, 50, 50]              38\n",
      "             ReLU-35           [-1, 19, 50, 50]               0\n",
      "           Conv2d-36           [-1, 12, 50, 50]           5,700\n",
      "       conv_layer-37           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 31, 50, 50]              62\n",
      "             ReLU-39           [-1, 31, 50, 50]               0\n",
      "           Conv2d-40           [-1, 12, 50, 50]           9,300\n",
      "       conv_layer-41           [-1, 43, 50, 50]               0\n",
      "      Dense_block-42           [-1, 43, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 43, 50, 50]              86\n",
      "             ReLU-44           [-1, 43, 50, 50]               0\n",
      "           Conv2d-45           [-1, 21, 50, 50]             903\n",
      "      BatchNorm2d-46           [-1, 21, 50, 50]              42\n",
      "             ReLU-47           [-1, 21, 50, 50]               0\n",
      "           Conv2d-48           [-1, 21, 25, 25]          11,025\n",
      "    Encode_Decode-49           [-1, 21, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 21, 25, 25]              42\n",
      "             ReLU-51           [-1, 21, 25, 25]               0\n",
      "           Conv2d-52           [-1, 12, 25, 25]           6,300\n",
      "       conv_layer-53           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 33, 25, 25]              66\n",
      "             ReLU-55           [-1, 33, 25, 25]               0\n",
      "           Conv2d-56           [-1, 12, 25, 25]           9,900\n",
      "       conv_layer-57           [-1, 45, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 45, 25, 25]              90\n",
      "             ReLU-59           [-1, 45, 25, 25]               0\n",
      "           Conv2d-60           [-1, 12, 25, 25]          13,500\n",
      "       conv_layer-61           [-1, 57, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 57, 25, 25]             114\n",
      "             ReLU-63           [-1, 57, 25, 25]               0\n",
      "           Conv2d-64           [-1, 12, 25, 25]          17,100\n",
      "       conv_layer-65           [-1, 69, 25, 25]               0\n",
      "      Dense_block-66           [-1, 69, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 69, 25, 25]             138\n",
      "             ReLU-68           [-1, 69, 25, 25]               0\n",
      "           Conv2d-69           [-1, 34, 25, 25]           2,346\n",
      "      BatchNorm2d-70           [-1, 34, 25, 25]              68\n",
      "             ReLU-71           [-1, 34, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 34, 50, 50]          28,900\n",
      "    Encode_Decode-73           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 53, 50, 50]             106\n",
      "             ReLU-75           [-1, 53, 50, 50]               0\n",
      "           Conv2d-76           [-1, 12, 50, 50]          15,900\n",
      "       conv_layer-77           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 65, 50, 50]             130\n",
      "             ReLU-79           [-1, 65, 50, 50]               0\n",
      "           Conv2d-80           [-1, 12, 50, 50]          19,500\n",
      "       conv_layer-81           [-1, 77, 50, 50]               0\n",
      "      Dense_block-82           [-1, 77, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 77, 50, 50]             154\n",
      "             ReLU-84           [-1, 77, 50, 50]               0\n",
      "           Conv2d-85           [-1, 38, 50, 50]           2,926\n",
      "      BatchNorm2d-86           [-1, 38, 50, 50]              76\n",
      "             ReLU-87           [-1, 38, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 38, 100, 100]          36,100\n",
      "    Encode_Decode-89         [-1, 38, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 38, 100, 100]              76\n",
      "             ReLU-91         [-1, 38, 100, 100]               0\n",
      "           Conv2d-92         [-1, 12, 100, 100]          11,400\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 12, 100, 100]          15,000\n",
      "       conv_layer-97         [-1, 62, 100, 100]               0\n",
      "      Dense_block-98         [-1, 62, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 62, 100, 100]             124\n",
      "            ReLU-100         [-1, 62, 100, 100]               0\n",
      "          Conv2d-101         [-1, 31, 100, 100]           1,922\n",
      "     BatchNorm2d-102         [-1, 31, 100, 100]              62\n",
      "            ReLU-103         [-1, 31, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 31, 200, 200]          24,025\n",
      "   Encode_Decode-105         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 31, 200, 200]              62\n",
      "            ReLU-107         [-1, 31, 200, 200]               0\n",
      "          Conv2d-108         [-1, 12, 200, 200]           9,300\n",
      "      conv_layer-109         [-1, 43, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 43, 200, 200]              86\n",
      "            ReLU-111         [-1, 43, 200, 200]               0\n",
      "          Conv2d-112         [-1, 12, 200, 200]          12,900\n",
      "      conv_layer-113         [-1, 55, 200, 200]               0\n",
      "     Dense_block-114         [-1, 55, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 55, 200, 200]             110\n",
      "            ReLU-116         [-1, 55, 200, 200]               0\n",
      "          Conv2d-117         [-1, 27, 200, 200]           1,485\n",
      "     BatchNorm2d-118         [-1, 27, 200, 200]              54\n",
      "            ReLU-119         [-1, 27, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             432\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 291,251\n",
      "Trainable params: 291,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 358.42\n",
      "Params size (MB): 1.11\n",
      "Estimated Total Size (MB): 360.15\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 12\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 2, 100, 100]               4\n",
      "             ReLU-91          [-1, 2, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              50\n",
      "       conv_layer-93          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 3, 100, 100]               6\n",
      "             ReLU-95          [-1, 3, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              75\n",
      "       conv_layer-97          [-1, 4, 100, 100]               0\n",
      "      Dense_block-98          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 4, 100, 100]               8\n",
      "            ReLU-100          [-1, 4, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 6, 200, 200]              12\n",
      "            ReLU-107          [-1, 6, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             150\n",
      "      conv_layer-109          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 7, 200, 200]              14\n",
      "            ReLU-111          [-1, 7, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             175\n",
      "      conv_layer-113          [-1, 8, 200, 200]               0\n",
      "     Dense_block-114          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 8, 200, 200]              16\n",
      "            ReLU-116          [-1, 8, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,894\n",
      "Trainable params: 2,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 55.95\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 56.57\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           2,156\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           8,085\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           8,281\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           7,007\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]          12,936\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]          14,161\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           9,163\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]          15,092\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]          17,689\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]          10,241\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]          16,170\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]          22,099\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]          28,028\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]          47,089\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]          16,709\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]          22,638\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]          33,124\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]          21,021\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]          26,950\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]          44,100\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 34, 200, 200]              68\n",
      "            ReLU-107         [-1, 34, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]          18,326\n",
      "      conv_layer-109         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 45, 200, 200]              90\n",
      "            ReLU-111         [-1, 45, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]          24,255\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 436,277\n",
      "Trainable params: 436,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 347.47\n",
      "Params size (MB): 1.66\n",
      "Estimated Total Size (MB): 349.75\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          10,000\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           5,500\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           8,525\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          11,550\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          14,575\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          25,600\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           8,800\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          11,825\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]          18,225\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          12,100\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          15,125\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]          27,225\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          12,650\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          15,675\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          28,900\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           9,350\n",
      "      conv_layer-141         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 45, 200, 200]              90\n",
      "            ReLU-143         [-1, 45, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          12,375\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 325,023\n",
      "Trainable params: 325,023\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 361.02\n",
      "Params size (MB): 1.24\n",
      "Estimated Total Size (MB): 362.87\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 |     199 |      24 |  0.013479975 |        ideal\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]           1,568\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           4,704\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           4,900\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           3,920\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           7,056\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           8,281\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           5,096\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           8,232\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      Dense_block-42           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 29, 50, 50]              58\n",
      "             ReLU-44           [-1, 29, 50, 50]               0\n",
      "           Conv2d-45           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-46           [-1, 14, 50, 50]              28\n",
      "             ReLU-47           [-1, 14, 50, 50]               0\n",
      "           Conv2d-48           [-1, 14, 25, 25]           9,604\n",
      "    Encode_Decode-49           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 14, 25, 25]              28\n",
      "             ReLU-51           [-1, 14, 25, 25]               0\n",
      "           Conv2d-52            [-1, 8, 25, 25]           5,488\n",
      "       conv_layer-53           [-1, 22, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 22, 25, 25]              44\n",
      "             ReLU-55           [-1, 22, 25, 25]               0\n",
      "           Conv2d-56            [-1, 8, 25, 25]           8,624\n",
      "       conv_layer-57           [-1, 30, 25, 25]               0\n",
      "      Dense_block-58           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 30, 25, 25]              60\n",
      "             ReLU-60           [-1, 30, 25, 25]               0\n",
      "           Conv2d-61           [-1, 15, 25, 25]             450\n",
      "      BatchNorm2d-62           [-1, 15, 25, 25]              30\n",
      "             ReLU-63           [-1, 15, 25, 25]               0\n",
      "           Conv2d-64           [-1, 15, 13, 13]          11,025\n",
      "    Encode_Decode-65           [-1, 15, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 15, 13, 13]              30\n",
      "             ReLU-67           [-1, 15, 13, 13]               0\n",
      "           Conv2d-68            [-1, 8, 13, 13]           5,880\n",
      "       conv_layer-69           [-1, 23, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 23, 13, 13]              46\n",
      "             ReLU-71           [-1, 23, 13, 13]               0\n",
      "           Conv2d-72            [-1, 8, 13, 13]           9,016\n",
      "       conv_layer-73           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 31, 13, 13]              62\n",
      "             ReLU-75           [-1, 31, 13, 13]               0\n",
      "           Conv2d-76            [-1, 8, 13, 13]          12,152\n",
      "       conv_layer-77           [-1, 39, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 39, 13, 13]              78\n",
      "             ReLU-79           [-1, 39, 13, 13]               0\n",
      "           Conv2d-80            [-1, 8, 13, 13]          15,288\n",
      "       conv_layer-81           [-1, 47, 13, 13]               0\n",
      "      Dense_block-82           [-1, 47, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 47, 13, 13]              94\n",
      "             ReLU-84           [-1, 47, 13, 13]               0\n",
      "           Conv2d-85           [-1, 23, 13, 13]           1,081\n",
      "      BatchNorm2d-86           [-1, 23, 13, 13]              46\n",
      "             ReLU-87           [-1, 23, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 23, 25, 25]          25,921\n",
      "    Encode_Decode-89           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 23, 25, 25]              46\n",
      "             ReLU-91           [-1, 23, 25, 25]               0\n",
      "           Conv2d-92            [-1, 8, 25, 25]           9,016\n",
      "       conv_layer-93           [-1, 31, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 31, 25, 25]              62\n",
      "             ReLU-95           [-1, 31, 25, 25]               0\n",
      "           Conv2d-96            [-1, 8, 25, 25]          12,152\n",
      "       conv_layer-97           [-1, 39, 25, 25]               0\n",
      "      Dense_block-98           [-1, 39, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 39, 25, 25]              78\n",
      "            ReLU-100           [-1, 39, 25, 25]               0\n",
      "          Conv2d-101           [-1, 19, 25, 25]             741\n",
      "     BatchNorm2d-102           [-1, 19, 25, 25]              38\n",
      "            ReLU-103           [-1, 19, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 19, 50, 50]          17,689\n",
      "   Encode_Decode-105           [-1, 19, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 32, 50, 50]              64\n",
      "            ReLU-107           [-1, 32, 50, 50]               0\n",
      "          Conv2d-108            [-1, 8, 50, 50]          12,544\n",
      "      conv_layer-109           [-1, 40, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 40, 50, 50]              80\n",
      "            ReLU-111           [-1, 40, 50, 50]               0\n",
      "          Conv2d-112            [-1, 8, 50, 50]          15,680\n",
      "      conv_layer-113           [-1, 48, 50, 50]               0\n",
      "     Dense_block-114           [-1, 48, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 48, 50, 50]              96\n",
      "            ReLU-116           [-1, 48, 50, 50]               0\n",
      "          Conv2d-117           [-1, 24, 50, 50]           1,152\n",
      "     BatchNorm2d-118           [-1, 24, 50, 50]              48\n",
      "            ReLU-119           [-1, 24, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 24, 100, 100]          28,224\n",
      "   Encode_Decode-121         [-1, 24, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 24, 100, 100]              48\n",
      "            ReLU-123         [-1, 24, 100, 100]               0\n",
      "          Conv2d-124          [-1, 8, 100, 100]           9,408\n",
      "      conv_layer-125         [-1, 32, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 32, 100, 100]              64\n",
      "            ReLU-127         [-1, 32, 100, 100]               0\n",
      "          Conv2d-128          [-1, 8, 100, 100]          12,544\n",
      "      conv_layer-129         [-1, 40, 100, 100]               0\n",
      "     Dense_block-130         [-1, 40, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 40, 100, 100]              80\n",
      "            ReLU-132         [-1, 40, 100, 100]               0\n",
      "          Conv2d-133         [-1, 20, 100, 100]             800\n",
      "     BatchNorm2d-134         [-1, 20, 100, 100]              40\n",
      "            ReLU-135         [-1, 20, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 20, 200, 200]          19,600\n",
      "   Encode_Decode-137         [-1, 20, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 24, 200, 200]              48\n",
      "            ReLU-139         [-1, 24, 200, 200]               0\n",
      "          Conv2d-140          [-1, 8, 200, 200]           9,408\n",
      "      conv_layer-141         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 32, 200, 200]              64\n",
      "            ReLU-143         [-1, 32, 200, 200]               0\n",
      "          Conv2d-144          [-1, 8, 200, 200]          12,544\n",
      "      conv_layer-145         [-1, 40, 200, 200]               0\n",
      "     Dense_block-146         [-1, 40, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 40, 200, 200]              80\n",
      "            ReLU-148         [-1, 40, 200, 200]               0\n",
      "          Conv2d-149         [-1, 20, 200, 200]             800\n",
      "     BatchNorm2d-150         [-1, 20, 200, 200]              40\n",
      "            ReLU-151         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             320\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 313,870\n",
      "Trainable params: 313,870\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 254.99\n",
      "Params size (MB): 1.20\n",
      "Estimated Total Size (MB): 256.80\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 8\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             600\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]           1,500\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]           1,600\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]           1,200\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]           2,100\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]           2,500\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]           1,500\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]           2,400\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           3,025\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]           1,650\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]           2,550\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           3,450\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           4,350\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]           2,550\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           3,450\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           4,900\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           3,300\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           4,200\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           7,225\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 21, 200, 200]              42\n",
      "            ReLU-107         [-1, 21, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]           3,150\n",
      "      conv_layer-109         [-1, 27, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 27, 200, 200]              54\n",
      "            ReLU-111         [-1, 27, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           4,050\n",
      "      conv_layer-113         [-1, 33, 200, 200]               0\n",
      "     Dense_block-114         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 33, 200, 200]              66\n",
      "            ReLU-116         [-1, 33, 200, 200]               0\n",
      "          Conv2d-117         [-1, 16, 200, 200]             528\n",
      "     BatchNorm2d-118         [-1, 16, 200, 200]              32\n",
      "            ReLU-119         [-1, 16, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             256\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 72,676\n",
      "Trainable params: 72,676\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 206.61\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 207.50\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]              36\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              18\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              27\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]              36\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]              45\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]              81\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              27\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]              36\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]              36\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              36\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]              45\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]              81\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 3, 100, 100]               6\n",
      "            ReLU-123          [-1, 3, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              27\n",
      "      conv_layer-125          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 4, 100, 100]               8\n",
      "            ReLU-127          [-1, 4, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]              36\n",
      "      conv_layer-129          [-1, 5, 100, 100]               0\n",
      "     Dense_block-130          [-1, 5, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 5, 100, 100]              10\n",
      "            ReLU-132          [-1, 5, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]              36\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 6, 200, 200]              12\n",
      "            ReLU-139          [-1, 6, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              54\n",
      "      conv_layer-141          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 7, 200, 200]              14\n",
      "            ReLU-143          [-1, 7, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              63\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 1,743\n",
      "Trainable params: 1,743\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 57.14\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 57.76\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 39, 50, 50]              78\n",
      "             ReLU-43           [-1, 39, 50, 50]               0\n",
      "           Conv2d-44           [-1, 11, 50, 50]           3,861\n",
      "       conv_layer-45           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 50, 50, 50]             100\n",
      "             ReLU-47           [-1, 50, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 50, 50]           4,950\n",
      "       conv_layer-49           [-1, 61, 50, 50]               0\n",
      "      Dense_block-50           [-1, 61, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 61, 50, 50]             122\n",
      "             ReLU-52           [-1, 61, 50, 50]               0\n",
      "           Conv2d-53           [-1, 30, 50, 50]           1,830\n",
      "      BatchNorm2d-54           [-1, 30, 50, 50]              60\n",
      "             ReLU-55           [-1, 30, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 30, 100, 100]           8,100\n",
      "    Encode_Decode-57         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 30, 100, 100]              60\n",
      "             ReLU-59         [-1, 30, 100, 100]               0\n",
      "           Conv2d-60         [-1, 11, 100, 100]           2,970\n",
      "       conv_layer-61         [-1, 41, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 41, 100, 100]              82\n",
      "             ReLU-63         [-1, 41, 100, 100]               0\n",
      "           Conv2d-64         [-1, 11, 100, 100]           4,059\n",
      "       conv_layer-65         [-1, 52, 100, 100]               0\n",
      "      Dense_block-66         [-1, 52, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 52, 100, 100]             104\n",
      "             ReLU-68         [-1, 52, 100, 100]               0\n",
      "           Conv2d-69         [-1, 26, 100, 100]           1,352\n",
      "      BatchNorm2d-70         [-1, 26, 100, 100]              52\n",
      "             ReLU-71         [-1, 26, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 26, 200, 200]           6,084\n",
      "    Encode_Decode-73         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 30, 200, 200]              60\n",
      "             ReLU-75         [-1, 30, 200, 200]               0\n",
      "           Conv2d-76         [-1, 11, 200, 200]           2,970\n",
      "       conv_layer-77         [-1, 41, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 41, 200, 200]              82\n",
      "             ReLU-79         [-1, 41, 200, 200]               0\n",
      "           Conv2d-80         [-1, 11, 200, 200]           4,059\n",
      "       conv_layer-81         [-1, 52, 200, 200]               0\n",
      "      Dense_block-82         [-1, 52, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 52, 200, 200]             104\n",
      "             ReLU-84         [-1, 52, 200, 200]               0\n",
      "           Conv2d-85         [-1, 26, 200, 200]           1,352\n",
      "      BatchNorm2d-86         [-1, 26, 200, 200]              52\n",
      "             ReLU-87         [-1, 26, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             416\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 58,541\n",
      "Trainable params: 58,541\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 318.85\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 319.69\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 8, 200, 200]             800\n",
      "        conv_layer-5         [-1, 12, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 12, 200, 200]              24\n",
      "              ReLU-7         [-1, 12, 200, 200]               0\n",
      "            Conv2d-8          [-1, 8, 200, 200]           2,400\n",
      "        conv_layer-9         [-1, 20, 200, 200]               0\n",
      "      Dense_block-10         [-1, 20, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 20, 200, 200]              40\n",
      "             ReLU-12         [-1, 20, 200, 200]               0\n",
      "           Conv2d-13         [-1, 10, 200, 200]             200\n",
      "      BatchNorm2d-14         [-1, 10, 200, 200]              20\n",
      "             ReLU-15         [-1, 10, 200, 200]               0\n",
      "           Conv2d-16         [-1, 10, 100, 100]           2,500\n",
      "    Encode_Decode-17         [-1, 10, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 10, 100, 100]              20\n",
      "             ReLU-19         [-1, 10, 100, 100]               0\n",
      "           Conv2d-20          [-1, 8, 100, 100]           2,000\n",
      "       conv_layer-21         [-1, 18, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 18, 100, 100]              36\n",
      "             ReLU-23         [-1, 18, 100, 100]               0\n",
      "           Conv2d-24          [-1, 8, 100, 100]           3,600\n",
      "       conv_layer-25         [-1, 26, 100, 100]               0\n",
      "      Dense_block-26         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 26, 100, 100]              52\n",
      "             ReLU-28         [-1, 26, 100, 100]               0\n",
      "           Conv2d-29         [-1, 13, 100, 100]             338\n",
      "      BatchNorm2d-30         [-1, 13, 100, 100]              26\n",
      "             ReLU-31         [-1, 13, 100, 100]               0\n",
      "           Conv2d-32           [-1, 13, 50, 50]           4,225\n",
      "    Encode_Decode-33           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 13, 50, 50]              26\n",
      "             ReLU-35           [-1, 13, 50, 50]               0\n",
      "           Conv2d-36            [-1, 8, 50, 50]           2,600\n",
      "       conv_layer-37           [-1, 21, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 21, 50, 50]              42\n",
      "             ReLU-39           [-1, 21, 50, 50]               0\n",
      "           Conv2d-40            [-1, 8, 50, 50]           4,200\n",
      "       conv_layer-41           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 29, 50, 50]              58\n",
      "             ReLU-43           [-1, 29, 50, 50]               0\n",
      "           Conv2d-44            [-1, 8, 50, 50]           5,800\n",
      "       conv_layer-45           [-1, 37, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 37, 50, 50]              74\n",
      "             ReLU-47           [-1, 37, 50, 50]               0\n",
      "           Conv2d-48            [-1, 8, 50, 50]           7,400\n",
      "       conv_layer-49           [-1, 45, 50, 50]               0\n",
      "      Dense_block-50           [-1, 45, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 45, 50, 50]              90\n",
      "             ReLU-52           [-1, 45, 50, 50]               0\n",
      "           Conv2d-53           [-1, 22, 50, 50]             990\n",
      "      BatchNorm2d-54           [-1, 22, 50, 50]              44\n",
      "             ReLU-55           [-1, 22, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 22, 100, 100]          12,100\n",
      "    Encode_Decode-57         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 32, 100, 100]              64\n",
      "             ReLU-59         [-1, 32, 100, 100]               0\n",
      "           Conv2d-60          [-1, 8, 100, 100]           6,400\n",
      "       conv_layer-61         [-1, 40, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 40, 100, 100]              80\n",
      "             ReLU-63         [-1, 40, 100, 100]               0\n",
      "           Conv2d-64          [-1, 8, 100, 100]           8,000\n",
      "       conv_layer-65         [-1, 48, 100, 100]               0\n",
      "      Dense_block-66         [-1, 48, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 48, 100, 100]              96\n",
      "             ReLU-68         [-1, 48, 100, 100]               0\n",
      "           Conv2d-69         [-1, 24, 100, 100]           1,152\n",
      "      BatchNorm2d-70         [-1, 24, 100, 100]              48\n",
      "             ReLU-71         [-1, 24, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 24, 200, 200]          14,400\n",
      "    Encode_Decode-73         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 28, 200, 200]              56\n",
      "             ReLU-75         [-1, 28, 200, 200]               0\n",
      "           Conv2d-76          [-1, 8, 200, 200]           5,600\n",
      "       conv_layer-77         [-1, 36, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 36, 200, 200]              72\n",
      "             ReLU-79         [-1, 36, 200, 200]               0\n",
      "           Conv2d-80          [-1, 8, 200, 200]           7,200\n",
      "       conv_layer-81         [-1, 44, 200, 200]               0\n",
      "      Dense_block-82         [-1, 44, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 44, 200, 200]              88\n",
      "             ReLU-84         [-1, 44, 200, 200]               0\n",
      "           Conv2d-85         [-1, 22, 200, 200]             968\n",
      "      BatchNorm2d-86         [-1, 22, 200, 200]              44\n",
      "             ReLU-87         [-1, 22, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             352\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 94,477\n",
      "Trainable params: 94,477\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 268.31\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 269.28\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 8\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 9, 200, 200]           1,764\n",
      "        conv_layer-5         [-1, 13, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 13, 200, 200]              26\n",
      "              ReLU-7         [-1, 13, 200, 200]               0\n",
      "            Conv2d-8          [-1, 9, 200, 200]           5,733\n",
      "        conv_layer-9         [-1, 22, 200, 200]               0\n",
      "      Dense_block-10         [-1, 22, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 22, 200, 200]              44\n",
      "             ReLU-12         [-1, 22, 200, 200]               0\n",
      "           Conv2d-13         [-1, 11, 200, 200]             242\n",
      "      BatchNorm2d-14         [-1, 11, 200, 200]              22\n",
      "             ReLU-15         [-1, 11, 200, 200]               0\n",
      "           Conv2d-16         [-1, 11, 100, 100]           5,929\n",
      "    Encode_Decode-17         [-1, 11, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 11, 100, 100]              22\n",
      "             ReLU-19         [-1, 11, 100, 100]               0\n",
      "           Conv2d-20          [-1, 9, 100, 100]           4,851\n",
      "       conv_layer-21         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 20, 100, 100]              40\n",
      "             ReLU-23         [-1, 20, 100, 100]               0\n",
      "           Conv2d-24          [-1, 9, 100, 100]           8,820\n",
      "       conv_layer-25         [-1, 29, 100, 100]               0\n",
      "      Dense_block-26         [-1, 29, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 29, 100, 100]              58\n",
      "             ReLU-28         [-1, 29, 100, 100]               0\n",
      "           Conv2d-29         [-1, 14, 100, 100]             406\n",
      "      BatchNorm2d-30         [-1, 14, 100, 100]              28\n",
      "             ReLU-31         [-1, 14, 100, 100]               0\n",
      "           Conv2d-32           [-1, 14, 50, 50]           9,604\n",
      "    Encode_Decode-33           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 14, 50, 50]              28\n",
      "             ReLU-35           [-1, 14, 50, 50]               0\n",
      "           Conv2d-36            [-1, 9, 50, 50]           6,174\n",
      "       conv_layer-37           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 23, 50, 50]              46\n",
      "             ReLU-39           [-1, 23, 50, 50]               0\n",
      "           Conv2d-40            [-1, 9, 50, 50]          10,143\n",
      "       conv_layer-41           [-1, 32, 50, 50]               0\n",
      "      Dense_block-42           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 32, 50, 50]              64\n",
      "             ReLU-44           [-1, 32, 50, 50]               0\n",
      "           Conv2d-45           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-46           [-1, 16, 50, 50]              32\n",
      "             ReLU-47           [-1, 16, 50, 50]               0\n",
      "           Conv2d-48           [-1, 16, 25, 25]          12,544\n",
      "    Encode_Decode-49           [-1, 16, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 16, 25, 25]              32\n",
      "             ReLU-51           [-1, 16, 25, 25]               0\n",
      "           Conv2d-52            [-1, 9, 25, 25]           7,056\n",
      "       conv_layer-53           [-1, 25, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 25, 25, 25]              50\n",
      "             ReLU-55           [-1, 25, 25, 25]               0\n",
      "           Conv2d-56            [-1, 9, 25, 25]          11,025\n",
      "       conv_layer-57           [-1, 34, 25, 25]               0\n",
      "      Dense_block-58           [-1, 34, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 34, 25, 25]              68\n",
      "             ReLU-60           [-1, 34, 25, 25]               0\n",
      "           Conv2d-61           [-1, 17, 25, 25]             578\n",
      "      BatchNorm2d-62           [-1, 17, 25, 25]              34\n",
      "             ReLU-63           [-1, 17, 25, 25]               0\n",
      "           Conv2d-64           [-1, 17, 13, 13]          14,161\n",
      "    Encode_Decode-65           [-1, 17, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 17, 13, 13]              34\n",
      "             ReLU-67           [-1, 17, 13, 13]               0\n",
      "           Conv2d-68            [-1, 9, 13, 13]           7,497\n",
      "       conv_layer-69           [-1, 26, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 26, 13, 13]              52\n",
      "             ReLU-71           [-1, 26, 13, 13]               0\n",
      "           Conv2d-72            [-1, 9, 13, 13]          11,466\n",
      "       conv_layer-73           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 35, 13, 13]              70\n",
      "             ReLU-75           [-1, 35, 13, 13]               0\n",
      "           Conv2d-76            [-1, 9, 13, 13]          15,435\n",
      "       conv_layer-77           [-1, 44, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 44, 13, 13]              88\n",
      "             ReLU-79           [-1, 44, 13, 13]               0\n",
      "           Conv2d-80            [-1, 9, 13, 13]          19,404\n",
      "       conv_layer-81           [-1, 53, 13, 13]               0\n",
      "      Dense_block-82           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 53, 13, 13]             106\n",
      "             ReLU-84           [-1, 53, 13, 13]               0\n",
      "           Conv2d-85           [-1, 26, 13, 13]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 13, 13]              52\n",
      "             ReLU-87           [-1, 26, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 26, 25, 25]          33,124\n",
      "    Encode_Decode-89           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 26, 25, 25]              52\n",
      "             ReLU-91           [-1, 26, 25, 25]               0\n",
      "           Conv2d-92            [-1, 9, 25, 25]          11,466\n",
      "       conv_layer-93           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 35, 25, 25]              70\n",
      "             ReLU-95           [-1, 35, 25, 25]               0\n",
      "           Conv2d-96            [-1, 9, 25, 25]          15,435\n",
      "       conv_layer-97           [-1, 44, 25, 25]               0\n",
      "      Dense_block-98           [-1, 44, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 44, 25, 25]              88\n",
      "            ReLU-100           [-1, 44, 25, 25]               0\n",
      "          Conv2d-101           [-1, 22, 25, 25]             968\n",
      "     BatchNorm2d-102           [-1, 22, 25, 25]              44\n",
      "            ReLU-103           [-1, 22, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 22, 50, 50]          23,716\n",
      "   Encode_Decode-105           [-1, 22, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 36, 50, 50]              72\n",
      "            ReLU-107           [-1, 36, 50, 50]               0\n",
      "          Conv2d-108            [-1, 9, 50, 50]          15,876\n",
      "      conv_layer-109           [-1, 45, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 45, 50, 50]              90\n",
      "            ReLU-111           [-1, 45, 50, 50]               0\n",
      "          Conv2d-112            [-1, 9, 50, 50]          19,845\n",
      "      conv_layer-113           [-1, 54, 50, 50]               0\n",
      "     Dense_block-114           [-1, 54, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 54, 50, 50]             108\n",
      "            ReLU-116           [-1, 54, 50, 50]               0\n",
      "          Conv2d-117           [-1, 27, 50, 50]           1,458\n",
      "     BatchNorm2d-118           [-1, 27, 50, 50]              54\n",
      "            ReLU-119           [-1, 27, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 27, 100, 100]          35,721\n",
      "   Encode_Decode-121         [-1, 27, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 27, 100, 100]              54\n",
      "            ReLU-123         [-1, 27, 100, 100]               0\n",
      "          Conv2d-124          [-1, 9, 100, 100]          11,907\n",
      "      conv_layer-125         [-1, 36, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 36, 100, 100]              72\n",
      "            ReLU-127         [-1, 36, 100, 100]               0\n",
      "          Conv2d-128          [-1, 9, 100, 100]          15,876\n",
      "      conv_layer-129         [-1, 45, 100, 100]               0\n",
      "     Dense_block-130         [-1, 45, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 45, 100, 100]              90\n",
      "            ReLU-132         [-1, 45, 100, 100]               0\n",
      "          Conv2d-133         [-1, 22, 100, 100]             990\n",
      "     BatchNorm2d-134         [-1, 22, 100, 100]              44\n",
      "            ReLU-135         [-1, 22, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 22, 200, 200]          23,716\n",
      "   Encode_Decode-137         [-1, 22, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 22, 200, 200]              44\n",
      "            ReLU-139         [-1, 22, 200, 200]               0\n",
      "          Conv2d-140          [-1, 9, 200, 200]           9,702\n",
      "      conv_layer-141         [-1, 31, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 31, 200, 200]              62\n",
      "            ReLU-143         [-1, 31, 200, 200]               0\n",
      "          Conv2d-144          [-1, 9, 200, 200]          13,671\n",
      "      conv_layer-145         [-1, 40, 200, 200]               0\n",
      "     Dense_block-146         [-1, 40, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 40, 200, 200]              80\n",
      "            ReLU-148         [-1, 40, 200, 200]               0\n",
      "          Conv2d-149         [-1, 20, 200, 200]             800\n",
      "     BatchNorm2d-150         [-1, 20, 200, 200]              40\n",
      "            ReLU-151         [-1, 20, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             320\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 391,525\n",
      "Trainable params: 391,525\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 267.95\n",
      "Params size (MB): 1.49\n",
      "Estimated Total Size (MB): 270.05\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 9\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]           1,100\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           4,125\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           4,225\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           3,575\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           6,600\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           7,225\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           4,675\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           7,700\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           9,025\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           5,225\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           8,250\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]          10,000\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           5,500\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           8,525\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]          11,550\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]          14,575\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]          25,600\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 51, 25, 25]             102\n",
      "             ReLU-91           [-1, 51, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]          14,025\n",
      "       conv_layer-93           [-1, 62, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 62, 25, 25]             124\n",
      "             ReLU-95           [-1, 62, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]          17,050\n",
      "       conv_layer-97           [-1, 73, 25, 25]               0\n",
      "      Dense_block-98           [-1, 73, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 73, 25, 25]             146\n",
      "            ReLU-100           [-1, 73, 25, 25]               0\n",
      "          Conv2d-101           [-1, 36, 25, 25]           2,628\n",
      "     BatchNorm2d-102           [-1, 36, 25, 25]              72\n",
      "            ReLU-103           [-1, 36, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 36, 50, 50]          32,400\n",
      "   Encode_Decode-105           [-1, 36, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 53, 50, 50]             106\n",
      "            ReLU-107           [-1, 53, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]          14,575\n",
      "      conv_layer-109           [-1, 64, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 64, 50, 50]             128\n",
      "            ReLU-111           [-1, 64, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]          17,600\n",
      "      conv_layer-113           [-1, 75, 50, 50]               0\n",
      "     Dense_block-114           [-1, 75, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 75, 50, 50]             150\n",
      "            ReLU-116           [-1, 75, 50, 50]               0\n",
      "          Conv2d-117           [-1, 37, 50, 50]           2,775\n",
      "     BatchNorm2d-118           [-1, 37, 50, 50]              74\n",
      "            ReLU-119           [-1, 37, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 37, 100, 100]          34,225\n",
      "   Encode_Decode-121         [-1, 37, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 50, 100, 100]             100\n",
      "            ReLU-123         [-1, 50, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]          13,750\n",
      "      conv_layer-125         [-1, 61, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 61, 100, 100]             122\n",
      "            ReLU-127         [-1, 61, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]          16,775\n",
      "      conv_layer-129         [-1, 72, 100, 100]               0\n",
      "     Dense_block-130         [-1, 72, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 72, 100, 100]             144\n",
      "            ReLU-132         [-1, 72, 100, 100]               0\n",
      "          Conv2d-133         [-1, 36, 100, 100]           2,592\n",
      "     BatchNorm2d-134         [-1, 36, 100, 100]              72\n",
      "            ReLU-135         [-1, 36, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 36, 200, 200]          32,400\n",
      "   Encode_Decode-137         [-1, 36, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 40, 200, 200]              80\n",
      "            ReLU-139         [-1, 40, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]          11,000\n",
      "      conv_layer-141         [-1, 51, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 51, 200, 200]             102\n",
      "            ReLU-143         [-1, 51, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]          14,025\n",
      "      conv_layer-145         [-1, 62, 200, 200]               0\n",
      "     Dense_block-146         [-1, 62, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 62, 200, 200]             124\n",
      "            ReLU-148         [-1, 62, 200, 200]               0\n",
      "          Conv2d-149         [-1, 31, 200, 200]           1,922\n",
      "     BatchNorm2d-150         [-1, 31, 200, 200]              62\n",
      "            ReLU-151         [-1, 31, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             496\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 373,311\n",
      "Trainable params: 373,311\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 388.34\n",
      "Params size (MB): 1.42\n",
      "Estimated Total Size (MB): 390.37\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 11\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 39, 50, 50]              78\n",
      "             ReLU-43           [-1, 39, 50, 50]               0\n",
      "           Conv2d-44           [-1, 11, 50, 50]           3,861\n",
      "       conv_layer-45           [-1, 50, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 50, 50, 50]             100\n",
      "             ReLU-47           [-1, 50, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 50, 50]           4,950\n",
      "       conv_layer-49           [-1, 61, 50, 50]               0\n",
      "      Dense_block-50           [-1, 61, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 61, 50, 50]             122\n",
      "             ReLU-52           [-1, 61, 50, 50]               0\n",
      "           Conv2d-53           [-1, 30, 50, 50]           1,830\n",
      "      BatchNorm2d-54           [-1, 30, 50, 50]              60\n",
      "             ReLU-55           [-1, 30, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 30, 100, 100]           8,100\n",
      "    Encode_Decode-57         [-1, 30, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 30, 100, 100]              60\n",
      "             ReLU-59         [-1, 30, 100, 100]               0\n",
      "           Conv2d-60         [-1, 11, 100, 100]           2,970\n",
      "       conv_layer-61         [-1, 41, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 41, 100, 100]              82\n",
      "             ReLU-63         [-1, 41, 100, 100]               0\n",
      "           Conv2d-64         [-1, 11, 100, 100]           4,059\n",
      "       conv_layer-65         [-1, 52, 100, 100]               0\n",
      "      Dense_block-66         [-1, 52, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 52, 100, 100]             104\n",
      "             ReLU-68         [-1, 52, 100, 100]               0\n",
      "           Conv2d-69         [-1, 26, 100, 100]           1,352\n",
      "      BatchNorm2d-70         [-1, 26, 100, 100]              52\n",
      "             ReLU-71         [-1, 26, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 26, 200, 200]           6,084\n",
      "    Encode_Decode-73         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 26, 200, 200]              52\n",
      "             ReLU-75         [-1, 26, 200, 200]               0\n",
      "           Conv2d-76         [-1, 11, 200, 200]           2,574\n",
      "       conv_layer-77         [-1, 37, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 37, 200, 200]              74\n",
      "             ReLU-79         [-1, 37, 200, 200]               0\n",
      "           Conv2d-80         [-1, 11, 200, 200]           3,663\n",
      "       conv_layer-81         [-1, 48, 200, 200]               0\n",
      "      Dense_block-82         [-1, 48, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 48, 200, 200]              96\n",
      "             ReLU-84         [-1, 48, 200, 200]               0\n",
      "           Conv2d-85         [-1, 24, 200, 200]           1,152\n",
      "      BatchNorm2d-86         [-1, 24, 200, 200]              48\n",
      "             ReLU-87         [-1, 24, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             384\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 57,489\n",
      "Trainable params: 57,489\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 306.03\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 306.86\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-42            [-1, 4, 50, 50]               8\n",
      "             ReLU-43            [-1, 4, 50, 50]               0\n",
      "           Conv2d-44            [-1, 1, 50, 50]             100\n",
      "       conv_layer-45            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-46            [-1, 5, 50, 50]              10\n",
      "             ReLU-47            [-1, 5, 50, 50]               0\n",
      "           Conv2d-48            [-1, 1, 50, 50]             125\n",
      "       conv_layer-49            [-1, 6, 50, 50]               0\n",
      "      Dense_block-50            [-1, 6, 50, 50]               0\n",
      "      BatchNorm2d-51            [-1, 6, 50, 50]              12\n",
      "             ReLU-52            [-1, 6, 50, 50]               0\n",
      "           Conv2d-53            [-1, 3, 50, 50]              18\n",
      "      BatchNorm2d-54            [-1, 3, 50, 50]               6\n",
      "             ReLU-55            [-1, 3, 50, 50]               0\n",
      "  ConvTranspose2d-56          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-57          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-58          [-1, 6, 100, 100]              12\n",
      "             ReLU-59          [-1, 6, 100, 100]               0\n",
      "           Conv2d-60          [-1, 1, 100, 100]             150\n",
      "       conv_layer-61          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-62          [-1, 7, 100, 100]              14\n",
      "             ReLU-63          [-1, 7, 100, 100]               0\n",
      "           Conv2d-64          [-1, 1, 100, 100]             175\n",
      "       conv_layer-65          [-1, 8, 100, 100]               0\n",
      "      Dense_block-66          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-67          [-1, 8, 100, 100]              16\n",
      "             ReLU-68          [-1, 8, 100, 100]               0\n",
      "           Conv2d-69          [-1, 4, 100, 100]              32\n",
      "      BatchNorm2d-70          [-1, 4, 100, 100]               8\n",
      "             ReLU-71          [-1, 4, 100, 100]               0\n",
      "  ConvTranspose2d-72          [-1, 4, 200, 200]             400\n",
      "    Encode_Decode-73          [-1, 4, 200, 200]               0\n",
      "      BatchNorm2d-74          [-1, 4, 200, 200]               8\n",
      "             ReLU-75          [-1, 4, 200, 200]               0\n",
      "           Conv2d-76          [-1, 1, 200, 200]             100\n",
      "       conv_layer-77          [-1, 5, 200, 200]               0\n",
      "      BatchNorm2d-78          [-1, 5, 200, 200]              10\n",
      "             ReLU-79          [-1, 5, 200, 200]               0\n",
      "           Conv2d-80          [-1, 1, 200, 200]             125\n",
      "       conv_layer-81          [-1, 6, 200, 200]               0\n",
      "      Dense_block-82          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-83          [-1, 6, 200, 200]              12\n",
      "             ReLU-84          [-1, 6, 200, 200]               0\n",
      "           Conv2d-85          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-86          [-1, 3, 200, 200]               6\n",
      "             ReLU-87          [-1, 3, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]              48\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,734\n",
      "Trainable params: 2,734\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 53.50\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 54.12\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 6, 200, 200]             216\n",
      "        conv_layer-5         [-1, 10, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 10, 200, 200]              20\n",
      "              ReLU-7         [-1, 10, 200, 200]               0\n",
      "            Conv2d-8          [-1, 6, 200, 200]             540\n",
      "        conv_layer-9         [-1, 16, 200, 200]               0\n",
      "      Dense_block-10         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 16, 200, 200]              32\n",
      "             ReLU-12         [-1, 16, 200, 200]               0\n",
      "           Conv2d-13          [-1, 8, 200, 200]             128\n",
      "      BatchNorm2d-14          [-1, 8, 200, 200]              16\n",
      "             ReLU-15          [-1, 8, 200, 200]               0\n",
      "           Conv2d-16          [-1, 8, 100, 100]             576\n",
      "    Encode_Decode-17          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 8, 100, 100]              16\n",
      "             ReLU-19          [-1, 8, 100, 100]               0\n",
      "           Conv2d-20          [-1, 6, 100, 100]             432\n",
      "       conv_layer-21         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 14, 100, 100]              28\n",
      "             ReLU-23         [-1, 14, 100, 100]               0\n",
      "           Conv2d-24          [-1, 6, 100, 100]             756\n",
      "       conv_layer-25         [-1, 20, 100, 100]               0\n",
      "      Dense_block-26         [-1, 20, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 20, 100, 100]              40\n",
      "             ReLU-28         [-1, 20, 100, 100]               0\n",
      "           Conv2d-29         [-1, 10, 100, 100]             200\n",
      "      BatchNorm2d-30         [-1, 10, 100, 100]              20\n",
      "             ReLU-31         [-1, 10, 100, 100]               0\n",
      "           Conv2d-32           [-1, 10, 50, 50]             900\n",
      "    Encode_Decode-33           [-1, 10, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 10, 50, 50]              20\n",
      "             ReLU-35           [-1, 10, 50, 50]               0\n",
      "           Conv2d-36            [-1, 6, 50, 50]             540\n",
      "       conv_layer-37           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 16, 50, 50]              32\n",
      "             ReLU-39           [-1, 16, 50, 50]               0\n",
      "           Conv2d-40            [-1, 6, 50, 50]             864\n",
      "       conv_layer-41           [-1, 22, 50, 50]               0\n",
      "      Dense_block-42           [-1, 22, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 22, 50, 50]              44\n",
      "             ReLU-44           [-1, 22, 50, 50]               0\n",
      "           Conv2d-45           [-1, 11, 50, 50]             242\n",
      "      BatchNorm2d-46           [-1, 11, 50, 50]              22\n",
      "             ReLU-47           [-1, 11, 50, 50]               0\n",
      "           Conv2d-48           [-1, 11, 25, 25]           1,089\n",
      "    Encode_Decode-49           [-1, 11, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 11, 25, 25]              22\n",
      "             ReLU-51           [-1, 11, 25, 25]               0\n",
      "           Conv2d-52            [-1, 6, 25, 25]             594\n",
      "       conv_layer-53           [-1, 17, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 17, 25, 25]              34\n",
      "             ReLU-55           [-1, 17, 25, 25]               0\n",
      "           Conv2d-56            [-1, 6, 25, 25]             918\n",
      "       conv_layer-57           [-1, 23, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 23, 25, 25]              46\n",
      "             ReLU-59           [-1, 23, 25, 25]               0\n",
      "           Conv2d-60            [-1, 6, 25, 25]           1,242\n",
      "       conv_layer-61           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 29, 25, 25]              58\n",
      "             ReLU-63           [-1, 29, 25, 25]               0\n",
      "           Conv2d-64            [-1, 6, 25, 25]           1,566\n",
      "       conv_layer-65           [-1, 35, 25, 25]               0\n",
      "      Dense_block-66           [-1, 35, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 35, 25, 25]              70\n",
      "             ReLU-68           [-1, 35, 25, 25]               0\n",
      "           Conv2d-69           [-1, 17, 25, 25]             595\n",
      "      BatchNorm2d-70           [-1, 17, 25, 25]              34\n",
      "             ReLU-71           [-1, 17, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-73           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 17, 50, 50]              34\n",
      "             ReLU-75           [-1, 17, 50, 50]               0\n",
      "           Conv2d-76            [-1, 6, 50, 50]             918\n",
      "       conv_layer-77           [-1, 23, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 23, 50, 50]              46\n",
      "             ReLU-79           [-1, 23, 50, 50]               0\n",
      "           Conv2d-80            [-1, 6, 50, 50]           1,242\n",
      "       conv_layer-81           [-1, 29, 50, 50]               0\n",
      "      Dense_block-82           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 29, 50, 50]              58\n",
      "             ReLU-84           [-1, 29, 50, 50]               0\n",
      "           Conv2d-85           [-1, 14, 50, 50]             406\n",
      "      BatchNorm2d-86           [-1, 14, 50, 50]              28\n",
      "             ReLU-87           [-1, 14, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 14, 100, 100]           1,764\n",
      "    Encode_Decode-89         [-1, 14, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 22, 100, 100]              44\n",
      "             ReLU-91         [-1, 22, 100, 100]               0\n",
      "           Conv2d-92          [-1, 6, 100, 100]           1,188\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 6, 100, 100]           1,512\n",
      "       conv_layer-97         [-1, 34, 100, 100]               0\n",
      "      Dense_block-98         [-1, 34, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 34, 100, 100]              68\n",
      "            ReLU-100         [-1, 34, 100, 100]               0\n",
      "          Conv2d-101         [-1, 17, 100, 100]             578\n",
      "     BatchNorm2d-102         [-1, 17, 100, 100]              34\n",
      "            ReLU-103         [-1, 17, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 17, 200, 200]           2,601\n",
      "   Encode_Decode-105         [-1, 17, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 17, 200, 200]              34\n",
      "            ReLU-107         [-1, 17, 200, 200]               0\n",
      "          Conv2d-108          [-1, 6, 200, 200]             918\n",
      "      conv_layer-109         [-1, 23, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 23, 200, 200]              46\n",
      "            ReLU-111         [-1, 23, 200, 200]               0\n",
      "          Conv2d-112          [-1, 6, 200, 200]           1,242\n",
      "      conv_layer-113         [-1, 29, 200, 200]               0\n",
      "     Dense_block-114         [-1, 29, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 29, 200, 200]              58\n",
      "            ReLU-116         [-1, 29, 200, 200]               0\n",
      "          Conv2d-117         [-1, 14, 200, 200]             406\n",
      "     BatchNorm2d-118         [-1, 14, 200, 200]              28\n",
      "            ReLU-119         [-1, 14, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             224\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 28,238\n",
      "Trainable params: 28,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 193.80\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 194.51\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 6\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 5, 200, 200]             500\n",
      "        conv_layer-5          [-1, 9, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 9, 200, 200]              18\n",
      "              ReLU-7          [-1, 9, 200, 200]               0\n",
      "            Conv2d-8          [-1, 5, 200, 200]           1,125\n",
      "        conv_layer-9         [-1, 14, 200, 200]               0\n",
      "      Dense_block-10         [-1, 14, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 14, 200, 200]              28\n",
      "             ReLU-12         [-1, 14, 200, 200]               0\n",
      "           Conv2d-13          [-1, 7, 200, 200]              98\n",
      "      BatchNorm2d-14          [-1, 7, 200, 200]              14\n",
      "             ReLU-15          [-1, 7, 200, 200]               0\n",
      "           Conv2d-16          [-1, 7, 100, 100]           1,225\n",
      "    Encode_Decode-17          [-1, 7, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 7, 100, 100]              14\n",
      "             ReLU-19          [-1, 7, 100, 100]               0\n",
      "           Conv2d-20          [-1, 5, 100, 100]             875\n",
      "       conv_layer-21         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 12, 100, 100]              24\n",
      "             ReLU-23         [-1, 12, 100, 100]               0\n",
      "           Conv2d-24          [-1, 5, 100, 100]           1,500\n",
      "       conv_layer-25         [-1, 17, 100, 100]               0\n",
      "      Dense_block-26         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 17, 100, 100]              34\n",
      "             ReLU-28         [-1, 17, 100, 100]               0\n",
      "           Conv2d-29          [-1, 8, 100, 100]             136\n",
      "      BatchNorm2d-30          [-1, 8, 100, 100]              16\n",
      "             ReLU-31          [-1, 8, 100, 100]               0\n",
      "           Conv2d-32            [-1, 8, 50, 50]           1,600\n",
      "    Encode_Decode-33            [-1, 8, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 8, 50, 50]              16\n",
      "             ReLU-35            [-1, 8, 50, 50]               0\n",
      "           Conv2d-36            [-1, 5, 50, 50]           1,000\n",
      "       conv_layer-37           [-1, 13, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 13, 50, 50]              26\n",
      "             ReLU-39           [-1, 13, 50, 50]               0\n",
      "           Conv2d-40            [-1, 5, 50, 50]           1,625\n",
      "       conv_layer-41           [-1, 18, 50, 50]               0\n",
      "      Dense_block-42           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 18, 50, 50]              36\n",
      "             ReLU-44           [-1, 18, 50, 50]               0\n",
      "           Conv2d-45            [-1, 9, 50, 50]             162\n",
      "      BatchNorm2d-46            [-1, 9, 50, 50]              18\n",
      "             ReLU-47            [-1, 9, 50, 50]               0\n",
      "           Conv2d-48            [-1, 9, 25, 25]           2,025\n",
      "    Encode_Decode-49            [-1, 9, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 9, 25, 25]              18\n",
      "             ReLU-51            [-1, 9, 25, 25]               0\n",
      "           Conv2d-52            [-1, 5, 25, 25]           1,125\n",
      "       conv_layer-53           [-1, 14, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 14, 25, 25]              28\n",
      "             ReLU-55           [-1, 14, 25, 25]               0\n",
      "           Conv2d-56            [-1, 5, 25, 25]           1,750\n",
      "       conv_layer-57           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 19, 25, 25]              38\n",
      "             ReLU-59           [-1, 19, 25, 25]               0\n",
      "           Conv2d-60            [-1, 5, 25, 25]           2,375\n",
      "       conv_layer-61           [-1, 24, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 24, 25, 25]              48\n",
      "             ReLU-63           [-1, 24, 25, 25]               0\n",
      "           Conv2d-64            [-1, 5, 25, 25]           3,000\n",
      "       conv_layer-65           [-1, 29, 25, 25]               0\n",
      "      Dense_block-66           [-1, 29, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 29, 25, 25]              58\n",
      "             ReLU-68           [-1, 29, 25, 25]               0\n",
      "           Conv2d-69           [-1, 14, 25, 25]             406\n",
      "      BatchNorm2d-70           [-1, 14, 25, 25]              28\n",
      "             ReLU-71           [-1, 14, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 14, 50, 50]           4,900\n",
      "    Encode_Decode-73           [-1, 14, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 22, 50, 50]              44\n",
      "             ReLU-75           [-1, 22, 50, 50]               0\n",
      "           Conv2d-76            [-1, 5, 50, 50]           2,750\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 5, 50, 50]           3,375\n",
      "       conv_layer-81           [-1, 32, 50, 50]               0\n",
      "      Dense_block-82           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 32, 50, 50]              64\n",
      "             ReLU-84           [-1, 32, 50, 50]               0\n",
      "           Conv2d-85           [-1, 16, 50, 50]             512\n",
      "      BatchNorm2d-86           [-1, 16, 50, 50]              32\n",
      "             ReLU-87           [-1, 16, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 16, 100, 100]           6,400\n",
      "    Encode_Decode-89         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 23, 100, 100]              46\n",
      "             ReLU-91         [-1, 23, 100, 100]               0\n",
      "           Conv2d-92          [-1, 5, 100, 100]           2,875\n",
      "       conv_layer-93         [-1, 28, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 28, 100, 100]              56\n",
      "             ReLU-95         [-1, 28, 100, 100]               0\n",
      "           Conv2d-96          [-1, 5, 100, 100]           3,500\n",
      "       conv_layer-97         [-1, 33, 100, 100]               0\n",
      "      Dense_block-98         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 33, 100, 100]              66\n",
      "            ReLU-100         [-1, 33, 100, 100]               0\n",
      "          Conv2d-101         [-1, 16, 100, 100]             528\n",
      "     BatchNorm2d-102         [-1, 16, 100, 100]              32\n",
      "            ReLU-103         [-1, 16, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 16, 200, 200]           6,400\n",
      "   Encode_Decode-105         [-1, 16, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 16, 200, 200]              32\n",
      "            ReLU-107         [-1, 16, 200, 200]               0\n",
      "          Conv2d-108          [-1, 5, 200, 200]           2,000\n",
      "      conv_layer-109         [-1, 21, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 21, 200, 200]              42\n",
      "            ReLU-111         [-1, 21, 200, 200]               0\n",
      "          Conv2d-112          [-1, 5, 200, 200]           2,625\n",
      "      conv_layer-113         [-1, 26, 200, 200]               0\n",
      "     Dense_block-114         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 26, 200, 200]              52\n",
      "            ReLU-116         [-1, 26, 200, 200]               0\n",
      "          Conv2d-117         [-1, 13, 200, 200]             338\n",
      "     BatchNorm2d-118         [-1, 13, 200, 200]              26\n",
      "            ReLU-119         [-1, 13, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             208\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 58,098\n",
      "Trainable params: 58,098\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 177.60\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 178.43\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 5\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]              36\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]              45\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]              81\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              27\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]              36\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]              36\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              18\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              27\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]              36\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              18\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              27\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]              36\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              18\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              27\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]              36\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]              45\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]              81\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              45\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]              54\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]              81\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 5, 50, 50]              10\n",
      "            ReLU-107            [-1, 5, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]              45\n",
      "      conv_layer-109            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 6, 50, 50]              12\n",
      "            ReLU-111            [-1, 6, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]              54\n",
      "      conv_layer-113            [-1, 7, 50, 50]               0\n",
      "     Dense_block-114            [-1, 7, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 7, 50, 50]              14\n",
      "            ReLU-116            [-1, 7, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              21\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]              81\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              54\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]              63\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             144\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              36\n",
      "      conv_layer-141          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 5, 200, 200]              10\n",
      "            ReLU-143          [-1, 5, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              45\n",
      "      conv_layer-145          [-1, 6, 200, 200]               0\n",
      "     Dense_block-146          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 6, 200, 200]              12\n",
      "            ReLU-148          [-1, 6, 200, 200]               0\n",
      "          Conv2d-149          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-150          [-1, 3, 200, 200]               6\n",
      "            ReLU-151          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              48\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,002\n",
      "Trainable params: 2,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.78\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 55.40\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 5, 25, 25]              10\n",
      "             ReLU-91            [-1, 5, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             245\n",
      "       conv_layer-93            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 6, 25, 25]              12\n",
      "             ReLU-95            [-1, 6, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             294\n",
      "       conv_layer-97            [-1, 7, 25, 25]               0\n",
      "      Dense_block-98            [-1, 7, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 7, 25, 25]              14\n",
      "            ReLU-100            [-1, 7, 25, 25]               0\n",
      "          Conv2d-101            [-1, 3, 25, 25]              21\n",
      "     BatchNorm2d-102            [-1, 3, 25, 25]               6\n",
      "            ReLU-103            [-1, 3, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 3, 50, 50]             441\n",
      "   Encode_Decode-105            [-1, 3, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 3, 50, 50]               6\n",
      "            ReLU-107            [-1, 3, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             147\n",
      "      conv_layer-109            [-1, 4, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 4, 50, 50]               8\n",
      "            ReLU-111            [-1, 4, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             196\n",
      "      conv_layer-113            [-1, 5, 50, 50]               0\n",
      "     Dense_block-114            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 5, 50, 50]              10\n",
      "            ReLU-116            [-1, 5, 50, 50]               0\n",
      "          Conv2d-117            [-1, 2, 50, 50]              10\n",
      "     BatchNorm2d-118            [-1, 2, 50, 50]               4\n",
      "            ReLU-119            [-1, 2, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 2, 100, 100]             196\n",
      "   Encode_Decode-121          [-1, 2, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 2, 100, 100]               4\n",
      "            ReLU-123          [-1, 2, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              98\n",
      "      conv_layer-125          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 3, 100, 100]               6\n",
      "            ReLU-127          [-1, 3, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             147\n",
      "      conv_layer-129          [-1, 4, 100, 100]               0\n",
      "     Dense_block-130          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 4, 100, 100]               8\n",
      "            ReLU-132          [-1, 4, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             196\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 6, 200, 200]              12\n",
      "            ReLU-139          [-1, 6, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             294\n",
      "      conv_layer-141          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 7, 200, 200]              14\n",
      "            ReLU-143          [-1, 7, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             343\n",
      "      conv_layer-145          [-1, 8, 200, 200]               0\n",
      "     Dense_block-146          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 8, 200, 200]              16\n",
      "            ReLU-148          [-1, 8, 200, 200]               0\n",
      "          Conv2d-149          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-150          [-1, 4, 200, 200]               8\n",
      "            ReLU-151          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              64\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 6,664\n",
      "Trainable params: 6,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 56.21\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 56.84\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 1\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-58            [-1, 4, 25, 25]               8\n",
      "             ReLU-59            [-1, 4, 25, 25]               0\n",
      "           Conv2d-60            [-1, 1, 25, 25]             100\n",
      "       conv_layer-61            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-62            [-1, 5, 25, 25]              10\n",
      "             ReLU-63            [-1, 5, 25, 25]               0\n",
      "           Conv2d-64            [-1, 1, 25, 25]             125\n",
      "       conv_layer-65            [-1, 6, 25, 25]               0\n",
      "      Dense_block-66            [-1, 6, 25, 25]               0\n",
      "      BatchNorm2d-67            [-1, 6, 25, 25]              12\n",
      "             ReLU-68            [-1, 6, 25, 25]               0\n",
      "           Conv2d-69            [-1, 3, 25, 25]              18\n",
      "      BatchNorm2d-70            [-1, 3, 25, 25]               6\n",
      "             ReLU-71            [-1, 3, 25, 25]               0\n",
      "  ConvTranspose2d-72            [-1, 3, 50, 50]             225\n",
      "    Encode_Decode-73            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-74            [-1, 3, 50, 50]               6\n",
      "             ReLU-75            [-1, 3, 50, 50]               0\n",
      "           Conv2d-76            [-1, 1, 50, 50]              75\n",
      "       conv_layer-77            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-78            [-1, 4, 50, 50]               8\n",
      "             ReLU-79            [-1, 4, 50, 50]               0\n",
      "           Conv2d-80            [-1, 1, 50, 50]             100\n",
      "       conv_layer-81            [-1, 5, 50, 50]               0\n",
      "      Dense_block-82            [-1, 5, 50, 50]               0\n",
      "      BatchNorm2d-83            [-1, 5, 50, 50]              10\n",
      "             ReLU-84            [-1, 5, 50, 50]               0\n",
      "           Conv2d-85            [-1, 2, 50, 50]              10\n",
      "      BatchNorm2d-86            [-1, 2, 50, 50]               4\n",
      "             ReLU-87            [-1, 2, 50, 50]               0\n",
      "  ConvTranspose2d-88          [-1, 2, 100, 100]             100\n",
      "    Encode_Decode-89          [-1, 2, 100, 100]               0\n",
      "      BatchNorm2d-90          [-1, 2, 100, 100]               4\n",
      "             ReLU-91          [-1, 2, 100, 100]               0\n",
      "           Conv2d-92          [-1, 1, 100, 100]              50\n",
      "       conv_layer-93          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-94          [-1, 3, 100, 100]               6\n",
      "             ReLU-95          [-1, 3, 100, 100]               0\n",
      "           Conv2d-96          [-1, 1, 100, 100]              75\n",
      "       conv_layer-97          [-1, 4, 100, 100]               0\n",
      "      Dense_block-98          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-99          [-1, 4, 100, 100]               8\n",
      "            ReLU-100          [-1, 4, 100, 100]               0\n",
      "          Conv2d-101          [-1, 2, 100, 100]               8\n",
      "     BatchNorm2d-102          [-1, 2, 100, 100]               4\n",
      "            ReLU-103          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-104          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-105          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-106          [-1, 6, 200, 200]              12\n",
      "            ReLU-107          [-1, 6, 200, 200]               0\n",
      "          Conv2d-108          [-1, 1, 200, 200]             150\n",
      "      conv_layer-109          [-1, 7, 200, 200]               0\n",
      "     BatchNorm2d-110          [-1, 7, 200, 200]              14\n",
      "            ReLU-111          [-1, 7, 200, 200]               0\n",
      "          Conv2d-112          [-1, 1, 200, 200]             175\n",
      "      conv_layer-113          [-1, 8, 200, 200]               0\n",
      "     Dense_block-114          [-1, 8, 200, 200]               0\n",
      "     BatchNorm2d-115          [-1, 8, 200, 200]              16\n",
      "            ReLU-116          [-1, 8, 200, 200]               0\n",
      "          Conv2d-117          [-1, 4, 200, 200]              32\n",
      "     BatchNorm2d-118          [-1, 4, 200, 200]               8\n",
      "            ReLU-119          [-1, 4, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]              64\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 2,894\n",
      "Trainable params: 2,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 55.95\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 56.57\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 41, 25, 25]              82\n",
      "             ReLU-59           [-1, 41, 25, 25]               0\n",
      "           Conv2d-60           [-1, 11, 25, 25]           4,059\n",
      "       conv_layer-61           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 52, 25, 25]             104\n",
      "             ReLU-63           [-1, 52, 25, 25]               0\n",
      "           Conv2d-64           [-1, 11, 25, 25]           5,148\n",
      "       conv_layer-65           [-1, 63, 25, 25]               0\n",
      "      Dense_block-66           [-1, 63, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 63, 25, 25]             126\n",
      "             ReLU-68           [-1, 63, 25, 25]               0\n",
      "           Conv2d-69           [-1, 31, 25, 25]           1,953\n",
      "      BatchNorm2d-70           [-1, 31, 25, 25]              62\n",
      "             ReLU-71           [-1, 31, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 31, 50, 50]           8,649\n",
      "    Encode_Decode-73           [-1, 31, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 31, 50, 50]              62\n",
      "             ReLU-75           [-1, 31, 50, 50]               0\n",
      "           Conv2d-76           [-1, 11, 50, 50]           3,069\n",
      "       conv_layer-77           [-1, 42, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 42, 50, 50]              84\n",
      "             ReLU-79           [-1, 42, 50, 50]               0\n",
      "           Conv2d-80           [-1, 11, 50, 50]           4,158\n",
      "       conv_layer-81           [-1, 53, 50, 50]               0\n",
      "      Dense_block-82           [-1, 53, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 53, 50, 50]             106\n",
      "             ReLU-84           [-1, 53, 50, 50]               0\n",
      "           Conv2d-85           [-1, 26, 50, 50]           1,378\n",
      "      BatchNorm2d-86           [-1, 26, 50, 50]              52\n",
      "             ReLU-87           [-1, 26, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 26, 100, 100]           6,084\n",
      "    Encode_Decode-89         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 39, 100, 100]              78\n",
      "             ReLU-91         [-1, 39, 100, 100]               0\n",
      "           Conv2d-92         [-1, 11, 100, 100]           3,861\n",
      "       conv_layer-93         [-1, 50, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 50, 100, 100]             100\n",
      "             ReLU-95         [-1, 50, 100, 100]               0\n",
      "           Conv2d-96         [-1, 11, 100, 100]           4,950\n",
      "       conv_layer-97         [-1, 61, 100, 100]               0\n",
      "      Dense_block-98         [-1, 61, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 61, 100, 100]             122\n",
      "            ReLU-100         [-1, 61, 100, 100]               0\n",
      "          Conv2d-101         [-1, 30, 100, 100]           1,830\n",
      "     BatchNorm2d-102         [-1, 30, 100, 100]              60\n",
      "            ReLU-103         [-1, 30, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 30, 200, 200]           8,100\n",
      "   Encode_Decode-105         [-1, 30, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 34, 200, 200]              68\n",
      "            ReLU-107         [-1, 34, 200, 200]               0\n",
      "          Conv2d-108         [-1, 11, 200, 200]           3,366\n",
      "      conv_layer-109         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 45, 200, 200]              90\n",
      "            ReLU-111         [-1, 45, 200, 200]               0\n",
      "          Conv2d-112         [-1, 11, 200, 200]           4,455\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 89,077\n",
      "Trainable params: 89,077\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 347.47\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 348.42\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]             252\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]             693\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]             729\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]             567\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           1,008\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           1,089\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]             693\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           1,134\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-42           [-1, 25, 50, 50]              50\n",
      "             ReLU-43           [-1, 25, 50, 50]               0\n",
      "           Conv2d-44            [-1, 7, 50, 50]           1,575\n",
      "       conv_layer-45           [-1, 32, 50, 50]               0\n",
      "      BatchNorm2d-46           [-1, 32, 50, 50]              64\n",
      "             ReLU-47           [-1, 32, 50, 50]               0\n",
      "           Conv2d-48            [-1, 7, 50, 50]           2,016\n",
      "       conv_layer-49           [-1, 39, 50, 50]               0\n",
      "      Dense_block-50           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-51           [-1, 39, 50, 50]              78\n",
      "             ReLU-52           [-1, 39, 50, 50]               0\n",
      "           Conv2d-53           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-54           [-1, 19, 50, 50]              38\n",
      "             ReLU-55           [-1, 19, 50, 50]               0\n",
      "  ConvTranspose2d-56         [-1, 19, 100, 100]           3,249\n",
      "    Encode_Decode-57         [-1, 19, 100, 100]               0\n",
      "      BatchNorm2d-58         [-1, 19, 100, 100]              38\n",
      "             ReLU-59         [-1, 19, 100, 100]               0\n",
      "           Conv2d-60          [-1, 7, 100, 100]           1,197\n",
      "       conv_layer-61         [-1, 26, 100, 100]               0\n",
      "      BatchNorm2d-62         [-1, 26, 100, 100]              52\n",
      "             ReLU-63         [-1, 26, 100, 100]               0\n",
      "           Conv2d-64          [-1, 7, 100, 100]           1,638\n",
      "       conv_layer-65         [-1, 33, 100, 100]               0\n",
      "      Dense_block-66         [-1, 33, 100, 100]               0\n",
      "      BatchNorm2d-67         [-1, 33, 100, 100]              66\n",
      "             ReLU-68         [-1, 33, 100, 100]               0\n",
      "           Conv2d-69         [-1, 16, 100, 100]             528\n",
      "      BatchNorm2d-70         [-1, 16, 100, 100]              32\n",
      "             ReLU-71         [-1, 16, 100, 100]               0\n",
      "  ConvTranspose2d-72         [-1, 16, 200, 200]           2,304\n",
      "    Encode_Decode-73         [-1, 16, 200, 200]               0\n",
      "      BatchNorm2d-74         [-1, 16, 200, 200]              32\n",
      "             ReLU-75         [-1, 16, 200, 200]               0\n",
      "           Conv2d-76          [-1, 7, 200, 200]           1,008\n",
      "       conv_layer-77         [-1, 23, 200, 200]               0\n",
      "      BatchNorm2d-78         [-1, 23, 200, 200]              46\n",
      "             ReLU-79         [-1, 23, 200, 200]               0\n",
      "           Conv2d-80          [-1, 7, 200, 200]           1,449\n",
      "       conv_layer-81         [-1, 30, 200, 200]               0\n",
      "      Dense_block-82         [-1, 30, 200, 200]               0\n",
      "      BatchNorm2d-83         [-1, 30, 200, 200]              60\n",
      "             ReLU-84         [-1, 30, 200, 200]               0\n",
      "           Conv2d-85         [-1, 15, 200, 200]             450\n",
      "      BatchNorm2d-86         [-1, 15, 200, 200]              30\n",
      "             ReLU-87         [-1, 15, 200, 200]               0\n",
      "  ConvTranspose2d-88          [-1, 1, 400, 400]             240\n",
      "      last_decode-89          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 23,965\n",
      "Trainable params: 23,965\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 199.17\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 199.87\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip\n",
      "kerne_size= 3\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 0\n",
      "x4= 1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             196\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             245\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             441\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]             147\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             196\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             196\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              98\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]             147\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             196\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              98\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]             147\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             196\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              98\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]             147\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             196\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             245\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             441\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]             147\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             196\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             196\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             196\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             245\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             441\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 6, 100, 100]              12\n",
      "            ReLU-123          [-1, 6, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]             294\n",
      "      conv_layer-125          [-1, 7, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 7, 100, 100]              14\n",
      "            ReLU-127          [-1, 7, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             343\n",
      "      conv_layer-129          [-1, 8, 100, 100]               0\n",
      "     Dense_block-130          [-1, 8, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 8, 100, 100]              16\n",
      "            ReLU-132          [-1, 8, 100, 100]               0\n",
      "          Conv2d-133          [-1, 4, 100, 100]              32\n",
      "     BatchNorm2d-134          [-1, 4, 100, 100]               8\n",
      "            ReLU-135          [-1, 4, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 4, 200, 200]             784\n",
      "   Encode_Decode-137          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 4, 200, 200]               8\n",
      "            ReLU-139          [-1, 4, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]             196\n",
      "      conv_layer-141          [-1, 5, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 5, 200, 200]              10\n",
      "            ReLU-143          [-1, 5, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]             245\n",
      "      conv_layer-145          [-1, 6, 200, 200]               0\n",
      "     Dense_block-146          [-1, 6, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 6, 200, 200]              12\n",
      "            ReLU-148          [-1, 6, 200, 200]               0\n",
      "          Conv2d-149          [-1, 3, 200, 200]              18\n",
      "     BatchNorm2d-150          [-1, 3, 200, 200]               6\n",
      "            ReLU-151          [-1, 3, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              48\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 7,349\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 54.47\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 55.11\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 7\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 7, 200, 200]           1,372\n",
      "        conv_layer-5         [-1, 11, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 11, 200, 200]              22\n",
      "              ReLU-7         [-1, 11, 200, 200]               0\n",
      "            Conv2d-8          [-1, 7, 200, 200]           3,773\n",
      "        conv_layer-9         [-1, 18, 200, 200]               0\n",
      "      Dense_block-10         [-1, 18, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 18, 200, 200]              36\n",
      "             ReLU-12         [-1, 18, 200, 200]               0\n",
      "           Conv2d-13          [-1, 9, 200, 200]             162\n",
      "      BatchNorm2d-14          [-1, 9, 200, 200]              18\n",
      "             ReLU-15          [-1, 9, 200, 200]               0\n",
      "           Conv2d-16          [-1, 9, 100, 100]           3,969\n",
      "    Encode_Decode-17          [-1, 9, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 9, 100, 100]              18\n",
      "             ReLU-19          [-1, 9, 100, 100]               0\n",
      "           Conv2d-20          [-1, 7, 100, 100]           3,087\n",
      "       conv_layer-21         [-1, 16, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 16, 100, 100]              32\n",
      "             ReLU-23         [-1, 16, 100, 100]               0\n",
      "           Conv2d-24          [-1, 7, 100, 100]           5,488\n",
      "       conv_layer-25         [-1, 23, 100, 100]               0\n",
      "      Dense_block-26         [-1, 23, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 23, 100, 100]              46\n",
      "             ReLU-28         [-1, 23, 100, 100]               0\n",
      "           Conv2d-29         [-1, 11, 100, 100]             253\n",
      "      BatchNorm2d-30         [-1, 11, 100, 100]              22\n",
      "             ReLU-31         [-1, 11, 100, 100]               0\n",
      "           Conv2d-32           [-1, 11, 50, 50]           5,929\n",
      "    Encode_Decode-33           [-1, 11, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 11, 50, 50]              22\n",
      "             ReLU-35           [-1, 11, 50, 50]               0\n",
      "           Conv2d-36            [-1, 7, 50, 50]           3,773\n",
      "       conv_layer-37           [-1, 18, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 18, 50, 50]              36\n",
      "             ReLU-39           [-1, 18, 50, 50]               0\n",
      "           Conv2d-40            [-1, 7, 50, 50]           6,174\n",
      "       conv_layer-41           [-1, 25, 50, 50]               0\n",
      "      Dense_block-42           [-1, 25, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 25, 50, 50]              50\n",
      "             ReLU-44           [-1, 25, 50, 50]               0\n",
      "           Conv2d-45           [-1, 12, 50, 50]             300\n",
      "      BatchNorm2d-46           [-1, 12, 50, 50]              24\n",
      "             ReLU-47           [-1, 12, 50, 50]               0\n",
      "           Conv2d-48           [-1, 12, 25, 25]           7,056\n",
      "    Encode_Decode-49           [-1, 12, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 12, 25, 25]              24\n",
      "             ReLU-51           [-1, 12, 25, 25]               0\n",
      "           Conv2d-52            [-1, 7, 25, 25]           4,116\n",
      "       conv_layer-53           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 19, 25, 25]              38\n",
      "             ReLU-55           [-1, 19, 25, 25]               0\n",
      "           Conv2d-56            [-1, 7, 25, 25]           6,517\n",
      "       conv_layer-57           [-1, 26, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 26, 25, 25]              52\n",
      "             ReLU-59           [-1, 26, 25, 25]               0\n",
      "           Conv2d-60            [-1, 7, 25, 25]           8,918\n",
      "       conv_layer-61           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 33, 25, 25]              66\n",
      "             ReLU-63           [-1, 33, 25, 25]               0\n",
      "           Conv2d-64            [-1, 7, 25, 25]          11,319\n",
      "       conv_layer-65           [-1, 40, 25, 25]               0\n",
      "      Dense_block-66           [-1, 40, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 40, 25, 25]              80\n",
      "             ReLU-68           [-1, 40, 25, 25]               0\n",
      "           Conv2d-69           [-1, 20, 25, 25]             800\n",
      "      BatchNorm2d-70           [-1, 20, 25, 25]              40\n",
      "             ReLU-71           [-1, 20, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 20, 50, 50]          19,600\n",
      "    Encode_Decode-73           [-1, 20, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 20, 50, 50]              40\n",
      "             ReLU-75           [-1, 20, 50, 50]               0\n",
      "           Conv2d-76            [-1, 7, 50, 50]           6,860\n",
      "       conv_layer-77           [-1, 27, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 27, 50, 50]              54\n",
      "             ReLU-79           [-1, 27, 50, 50]               0\n",
      "           Conv2d-80            [-1, 7, 50, 50]           9,261\n",
      "       conv_layer-81           [-1, 34, 50, 50]               0\n",
      "      Dense_block-82           [-1, 34, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 34, 50, 50]              68\n",
      "             ReLU-84           [-1, 34, 50, 50]               0\n",
      "           Conv2d-85           [-1, 17, 50, 50]             578\n",
      "      BatchNorm2d-86           [-1, 17, 50, 50]              34\n",
      "             ReLU-87           [-1, 17, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 17, 100, 100]          14,161\n",
      "    Encode_Decode-89         [-1, 17, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 17, 100, 100]              34\n",
      "             ReLU-91         [-1, 17, 100, 100]               0\n",
      "           Conv2d-92          [-1, 7, 100, 100]           5,831\n",
      "       conv_layer-93         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 24, 100, 100]              48\n",
      "             ReLU-95         [-1, 24, 100, 100]               0\n",
      "           Conv2d-96          [-1, 7, 100, 100]           8,232\n",
      "       conv_layer-97         [-1, 31, 100, 100]               0\n",
      "      Dense_block-98         [-1, 31, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 31, 100, 100]              62\n",
      "            ReLU-100         [-1, 31, 100, 100]               0\n",
      "          Conv2d-101         [-1, 15, 100, 100]             465\n",
      "     BatchNorm2d-102         [-1, 15, 100, 100]              30\n",
      "            ReLU-103         [-1, 15, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 15, 200, 200]          11,025\n",
      "   Encode_Decode-105         [-1, 15, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 19, 200, 200]              38\n",
      "            ReLU-107         [-1, 19, 200, 200]               0\n",
      "          Conv2d-108          [-1, 7, 200, 200]           6,517\n",
      "      conv_layer-109         [-1, 26, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 26, 200, 200]              52\n",
      "            ReLU-111         [-1, 26, 200, 200]               0\n",
      "          Conv2d-112          [-1, 7, 200, 200]           8,918\n",
      "      conv_layer-113         [-1, 33, 200, 200]               0\n",
      "     Dense_block-114         [-1, 33, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 33, 200, 200]              66\n",
      "            ReLU-116         [-1, 33, 200, 200]               0\n",
      "          Conv2d-117         [-1, 16, 200, 200]             528\n",
      "     BatchNorm2d-118         [-1, 16, 200, 200]              32\n",
      "            ReLU-119         [-1, 16, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             256\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 166,574\n",
      "Trainable params: 166,574\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 210.24\n",
      "Params size (MB): 0.64\n",
      "Estimated Total Size (MB): 211.48\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 7\n",
      "x1= 0\n",
      "x2= 0\n",
      "x3= 1\n",
      "x4= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 11, 200, 200]             396\n",
      "        conv_layer-5         [-1, 15, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 15, 200, 200]              30\n",
      "              ReLU-7         [-1, 15, 200, 200]               0\n",
      "            Conv2d-8         [-1, 11, 200, 200]           1,485\n",
      "        conv_layer-9         [-1, 26, 200, 200]               0\n",
      "      Dense_block-10         [-1, 26, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 26, 200, 200]              52\n",
      "             ReLU-12         [-1, 26, 200, 200]               0\n",
      "           Conv2d-13         [-1, 13, 200, 200]             338\n",
      "      BatchNorm2d-14         [-1, 13, 200, 200]              26\n",
      "             ReLU-15         [-1, 13, 200, 200]               0\n",
      "           Conv2d-16         [-1, 13, 100, 100]           1,521\n",
      "    Encode_Decode-17         [-1, 13, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 13, 100, 100]              26\n",
      "             ReLU-19         [-1, 13, 100, 100]               0\n",
      "           Conv2d-20         [-1, 11, 100, 100]           1,287\n",
      "       conv_layer-21         [-1, 24, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 24, 100, 100]              48\n",
      "             ReLU-23         [-1, 24, 100, 100]               0\n",
      "           Conv2d-24         [-1, 11, 100, 100]           2,376\n",
      "       conv_layer-25         [-1, 35, 100, 100]               0\n",
      "      Dense_block-26         [-1, 35, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 35, 100, 100]              70\n",
      "             ReLU-28         [-1, 35, 100, 100]               0\n",
      "           Conv2d-29         [-1, 17, 100, 100]             595\n",
      "      BatchNorm2d-30         [-1, 17, 100, 100]              34\n",
      "             ReLU-31         [-1, 17, 100, 100]               0\n",
      "           Conv2d-32           [-1, 17, 50, 50]           2,601\n",
      "    Encode_Decode-33           [-1, 17, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 17, 50, 50]              34\n",
      "             ReLU-35           [-1, 17, 50, 50]               0\n",
      "           Conv2d-36           [-1, 11, 50, 50]           1,683\n",
      "       conv_layer-37           [-1, 28, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 28, 50, 50]              56\n",
      "             ReLU-39           [-1, 28, 50, 50]               0\n",
      "           Conv2d-40           [-1, 11, 50, 50]           2,772\n",
      "       conv_layer-41           [-1, 39, 50, 50]               0\n",
      "      Dense_block-42           [-1, 39, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 39, 50, 50]              78\n",
      "             ReLU-44           [-1, 39, 50, 50]               0\n",
      "           Conv2d-45           [-1, 19, 50, 50]             741\n",
      "      BatchNorm2d-46           [-1, 19, 50, 50]              38\n",
      "             ReLU-47           [-1, 19, 50, 50]               0\n",
      "           Conv2d-48           [-1, 19, 25, 25]           3,249\n",
      "    Encode_Decode-49           [-1, 19, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 19, 25, 25]              38\n",
      "             ReLU-51           [-1, 19, 25, 25]               0\n",
      "           Conv2d-52           [-1, 11, 25, 25]           1,881\n",
      "       conv_layer-53           [-1, 30, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 30, 25, 25]              60\n",
      "             ReLU-55           [-1, 30, 25, 25]               0\n",
      "           Conv2d-56           [-1, 11, 25, 25]           2,970\n",
      "       conv_layer-57           [-1, 41, 25, 25]               0\n",
      "      Dense_block-58           [-1, 41, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 41, 25, 25]              82\n",
      "             ReLU-60           [-1, 41, 25, 25]               0\n",
      "           Conv2d-61           [-1, 20, 25, 25]             820\n",
      "      BatchNorm2d-62           [-1, 20, 25, 25]              40\n",
      "             ReLU-63           [-1, 20, 25, 25]               0\n",
      "           Conv2d-64           [-1, 20, 13, 13]           3,600\n",
      "    Encode_Decode-65           [-1, 20, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 20, 13, 13]              40\n",
      "             ReLU-67           [-1, 20, 13, 13]               0\n",
      "           Conv2d-68           [-1, 11, 13, 13]           1,980\n",
      "       conv_layer-69           [-1, 31, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 31, 13, 13]              62\n",
      "             ReLU-71           [-1, 31, 13, 13]               0\n",
      "           Conv2d-72           [-1, 11, 13, 13]           3,069\n",
      "       conv_layer-73           [-1, 42, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 42, 13, 13]              84\n",
      "             ReLU-75           [-1, 42, 13, 13]               0\n",
      "           Conv2d-76           [-1, 11, 13, 13]           4,158\n",
      "       conv_layer-77           [-1, 53, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 53, 13, 13]             106\n",
      "             ReLU-79           [-1, 53, 13, 13]               0\n",
      "           Conv2d-80           [-1, 11, 13, 13]           5,247\n",
      "       conv_layer-81           [-1, 64, 13, 13]               0\n",
      "      Dense_block-82           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-83           [-1, 64, 13, 13]             128\n",
      "             ReLU-84           [-1, 64, 13, 13]               0\n",
      "           Conv2d-85           [-1, 32, 13, 13]           2,048\n",
      "      BatchNorm2d-86           [-1, 32, 13, 13]              64\n",
      "             ReLU-87           [-1, 32, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 32, 25, 25]           9,216\n",
      "    Encode_Decode-89           [-1, 32, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 32, 25, 25]              64\n",
      "             ReLU-91           [-1, 32, 25, 25]               0\n",
      "           Conv2d-92           [-1, 11, 25, 25]           3,168\n",
      "       conv_layer-93           [-1, 43, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 43, 25, 25]              86\n",
      "             ReLU-95           [-1, 43, 25, 25]               0\n",
      "           Conv2d-96           [-1, 11, 25, 25]           4,257\n",
      "       conv_layer-97           [-1, 54, 25, 25]               0\n",
      "      Dense_block-98           [-1, 54, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 54, 25, 25]             108\n",
      "            ReLU-100           [-1, 54, 25, 25]               0\n",
      "          Conv2d-101           [-1, 27, 25, 25]           1,458\n",
      "     BatchNorm2d-102           [-1, 27, 25, 25]              54\n",
      "            ReLU-103           [-1, 27, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 27, 50, 50]           6,561\n",
      "   Encode_Decode-105           [-1, 27, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 44, 50, 50]              88\n",
      "            ReLU-107           [-1, 44, 50, 50]               0\n",
      "          Conv2d-108           [-1, 11, 50, 50]           4,356\n",
      "      conv_layer-109           [-1, 55, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 55, 50, 50]             110\n",
      "            ReLU-111           [-1, 55, 50, 50]               0\n",
      "          Conv2d-112           [-1, 11, 50, 50]           5,445\n",
      "      conv_layer-113           [-1, 66, 50, 50]               0\n",
      "     Dense_block-114           [-1, 66, 50, 50]               0\n",
      "     BatchNorm2d-115           [-1, 66, 50, 50]             132\n",
      "            ReLU-116           [-1, 66, 50, 50]               0\n",
      "          Conv2d-117           [-1, 33, 50, 50]           2,178\n",
      "     BatchNorm2d-118           [-1, 33, 50, 50]              66\n",
      "            ReLU-119           [-1, 33, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 33, 100, 100]           9,801\n",
      "   Encode_Decode-121         [-1, 33, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 46, 100, 100]              92\n",
      "            ReLU-123         [-1, 46, 100, 100]               0\n",
      "          Conv2d-124         [-1, 11, 100, 100]           4,554\n",
      "      conv_layer-125         [-1, 57, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 57, 100, 100]             114\n",
      "            ReLU-127         [-1, 57, 100, 100]               0\n",
      "          Conv2d-128         [-1, 11, 100, 100]           5,643\n",
      "      conv_layer-129         [-1, 68, 100, 100]               0\n",
      "     Dense_block-130         [-1, 68, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 68, 100, 100]             136\n",
      "            ReLU-132         [-1, 68, 100, 100]               0\n",
      "          Conv2d-133         [-1, 34, 100, 100]           2,312\n",
      "     BatchNorm2d-134         [-1, 34, 100, 100]              68\n",
      "            ReLU-135         [-1, 34, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 34, 200, 200]          10,404\n",
      "   Encode_Decode-137         [-1, 34, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 34, 200, 200]              68\n",
      "            ReLU-139         [-1, 34, 200, 200]               0\n",
      "          Conv2d-140         [-1, 11, 200, 200]           3,366\n",
      "      conv_layer-141         [-1, 45, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 45, 200, 200]              90\n",
      "            ReLU-143         [-1, 45, 200, 200]               0\n",
      "          Conv2d-144         [-1, 11, 200, 200]           4,455\n",
      "      conv_layer-145         [-1, 56, 200, 200]               0\n",
      "     Dense_block-146         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 56, 200, 200]             112\n",
      "            ReLU-148         [-1, 56, 200, 200]               0\n",
      "          Conv2d-149         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-150         [-1, 28, 200, 200]              56\n",
      "            ReLU-151         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             448\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 126,799\n",
      "Trainable params: 126,799\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 361.02\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 362.11\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 11\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4          [-1, 1, 200, 200]             100\n",
      "        conv_layer-5          [-1, 5, 200, 200]               0\n",
      "       BatchNorm2d-6          [-1, 5, 200, 200]              10\n",
      "              ReLU-7          [-1, 5, 200, 200]               0\n",
      "            Conv2d-8          [-1, 1, 200, 200]             125\n",
      "        conv_layer-9          [-1, 6, 200, 200]               0\n",
      "      Dense_block-10          [-1, 6, 200, 200]               0\n",
      "      BatchNorm2d-11          [-1, 6, 200, 200]              12\n",
      "             ReLU-12          [-1, 6, 200, 200]               0\n",
      "           Conv2d-13          [-1, 3, 200, 200]              18\n",
      "      BatchNorm2d-14          [-1, 3, 200, 200]               6\n",
      "             ReLU-15          [-1, 3, 200, 200]               0\n",
      "           Conv2d-16          [-1, 3, 100, 100]             225\n",
      "    Encode_Decode-17          [-1, 3, 100, 100]               0\n",
      "      BatchNorm2d-18          [-1, 3, 100, 100]               6\n",
      "             ReLU-19          [-1, 3, 100, 100]               0\n",
      "           Conv2d-20          [-1, 1, 100, 100]              75\n",
      "       conv_layer-21          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-22          [-1, 4, 100, 100]               8\n",
      "             ReLU-23          [-1, 4, 100, 100]               0\n",
      "           Conv2d-24          [-1, 1, 100, 100]             100\n",
      "       conv_layer-25          [-1, 5, 100, 100]               0\n",
      "      Dense_block-26          [-1, 5, 100, 100]               0\n",
      "      BatchNorm2d-27          [-1, 5, 100, 100]              10\n",
      "             ReLU-28          [-1, 5, 100, 100]               0\n",
      "           Conv2d-29          [-1, 2, 100, 100]              10\n",
      "      BatchNorm2d-30          [-1, 2, 100, 100]               4\n",
      "             ReLU-31          [-1, 2, 100, 100]               0\n",
      "           Conv2d-32            [-1, 2, 50, 50]             100\n",
      "    Encode_Decode-33            [-1, 2, 50, 50]               0\n",
      "      BatchNorm2d-34            [-1, 2, 50, 50]               4\n",
      "             ReLU-35            [-1, 2, 50, 50]               0\n",
      "           Conv2d-36            [-1, 1, 50, 50]              50\n",
      "       conv_layer-37            [-1, 3, 50, 50]               0\n",
      "      BatchNorm2d-38            [-1, 3, 50, 50]               6\n",
      "             ReLU-39            [-1, 3, 50, 50]               0\n",
      "           Conv2d-40            [-1, 1, 50, 50]              75\n",
      "       conv_layer-41            [-1, 4, 50, 50]               0\n",
      "      Dense_block-42            [-1, 4, 50, 50]               0\n",
      "      BatchNorm2d-43            [-1, 4, 50, 50]               8\n",
      "             ReLU-44            [-1, 4, 50, 50]               0\n",
      "           Conv2d-45            [-1, 2, 50, 50]               8\n",
      "      BatchNorm2d-46            [-1, 2, 50, 50]               4\n",
      "             ReLU-47            [-1, 2, 50, 50]               0\n",
      "           Conv2d-48            [-1, 2, 25, 25]             100\n",
      "    Encode_Decode-49            [-1, 2, 25, 25]               0\n",
      "      BatchNorm2d-50            [-1, 2, 25, 25]               4\n",
      "             ReLU-51            [-1, 2, 25, 25]               0\n",
      "           Conv2d-52            [-1, 1, 25, 25]              50\n",
      "       conv_layer-53            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-54            [-1, 3, 25, 25]               6\n",
      "             ReLU-55            [-1, 3, 25, 25]               0\n",
      "           Conv2d-56            [-1, 1, 25, 25]              75\n",
      "       conv_layer-57            [-1, 4, 25, 25]               0\n",
      "      Dense_block-58            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-59            [-1, 4, 25, 25]               8\n",
      "             ReLU-60            [-1, 4, 25, 25]               0\n",
      "           Conv2d-61            [-1, 2, 25, 25]               8\n",
      "      BatchNorm2d-62            [-1, 2, 25, 25]               4\n",
      "             ReLU-63            [-1, 2, 25, 25]               0\n",
      "           Conv2d-64            [-1, 2, 13, 13]             100\n",
      "    Encode_Decode-65            [-1, 2, 13, 13]               0\n",
      "      BatchNorm2d-66            [-1, 2, 13, 13]               4\n",
      "             ReLU-67            [-1, 2, 13, 13]               0\n",
      "           Conv2d-68            [-1, 1, 13, 13]              50\n",
      "       conv_layer-69            [-1, 3, 13, 13]               0\n",
      "      BatchNorm2d-70            [-1, 3, 13, 13]               6\n",
      "             ReLU-71            [-1, 3, 13, 13]               0\n",
      "           Conv2d-72            [-1, 1, 13, 13]              75\n",
      "       conv_layer-73            [-1, 4, 13, 13]               0\n",
      "      BatchNorm2d-74            [-1, 4, 13, 13]               8\n",
      "             ReLU-75            [-1, 4, 13, 13]               0\n",
      "           Conv2d-76            [-1, 1, 13, 13]             100\n",
      "       conv_layer-77            [-1, 5, 13, 13]               0\n",
      "      BatchNorm2d-78            [-1, 5, 13, 13]              10\n",
      "             ReLU-79            [-1, 5, 13, 13]               0\n",
      "           Conv2d-80            [-1, 1, 13, 13]             125\n",
      "       conv_layer-81            [-1, 6, 13, 13]               0\n",
      "      Dense_block-82            [-1, 6, 13, 13]               0\n",
      "      BatchNorm2d-83            [-1, 6, 13, 13]              12\n",
      "             ReLU-84            [-1, 6, 13, 13]               0\n",
      "           Conv2d-85            [-1, 3, 13, 13]              18\n",
      "      BatchNorm2d-86            [-1, 3, 13, 13]               6\n",
      "             ReLU-87            [-1, 3, 13, 13]               0\n",
      "  ConvTranspose2d-88            [-1, 3, 25, 25]             225\n",
      "    Encode_Decode-89            [-1, 3, 25, 25]               0\n",
      "      BatchNorm2d-90            [-1, 3, 25, 25]               6\n",
      "             ReLU-91            [-1, 3, 25, 25]               0\n",
      "           Conv2d-92            [-1, 1, 25, 25]              75\n",
      "       conv_layer-93            [-1, 4, 25, 25]               0\n",
      "      BatchNorm2d-94            [-1, 4, 25, 25]               8\n",
      "             ReLU-95            [-1, 4, 25, 25]               0\n",
      "           Conv2d-96            [-1, 1, 25, 25]             100\n",
      "       conv_layer-97            [-1, 5, 25, 25]               0\n",
      "      Dense_block-98            [-1, 5, 25, 25]               0\n",
      "      BatchNorm2d-99            [-1, 5, 25, 25]              10\n",
      "            ReLU-100            [-1, 5, 25, 25]               0\n",
      "          Conv2d-101            [-1, 2, 25, 25]              10\n",
      "     BatchNorm2d-102            [-1, 2, 25, 25]               4\n",
      "            ReLU-103            [-1, 2, 25, 25]               0\n",
      " ConvTranspose2d-104            [-1, 2, 50, 50]             100\n",
      "   Encode_Decode-105            [-1, 2, 50, 50]               0\n",
      "     BatchNorm2d-106            [-1, 4, 50, 50]               8\n",
      "            ReLU-107            [-1, 4, 50, 50]               0\n",
      "          Conv2d-108            [-1, 1, 50, 50]             100\n",
      "      conv_layer-109            [-1, 5, 50, 50]               0\n",
      "     BatchNorm2d-110            [-1, 5, 50, 50]              10\n",
      "            ReLU-111            [-1, 5, 50, 50]               0\n",
      "          Conv2d-112            [-1, 1, 50, 50]             125\n",
      "      conv_layer-113            [-1, 6, 50, 50]               0\n",
      "     Dense_block-114            [-1, 6, 50, 50]               0\n",
      "     BatchNorm2d-115            [-1, 6, 50, 50]              12\n",
      "            ReLU-116            [-1, 6, 50, 50]               0\n",
      "          Conv2d-117            [-1, 3, 50, 50]              18\n",
      "     BatchNorm2d-118            [-1, 3, 50, 50]               6\n",
      "            ReLU-119            [-1, 3, 50, 50]               0\n",
      " ConvTranspose2d-120          [-1, 3, 100, 100]             225\n",
      "   Encode_Decode-121          [-1, 3, 100, 100]               0\n",
      "     BatchNorm2d-122          [-1, 3, 100, 100]               6\n",
      "            ReLU-123          [-1, 3, 100, 100]               0\n",
      "          Conv2d-124          [-1, 1, 100, 100]              75\n",
      "      conv_layer-125          [-1, 4, 100, 100]               0\n",
      "     BatchNorm2d-126          [-1, 4, 100, 100]               8\n",
      "            ReLU-127          [-1, 4, 100, 100]               0\n",
      "          Conv2d-128          [-1, 1, 100, 100]             100\n",
      "      conv_layer-129          [-1, 5, 100, 100]               0\n",
      "     Dense_block-130          [-1, 5, 100, 100]               0\n",
      "     BatchNorm2d-131          [-1, 5, 100, 100]              10\n",
      "            ReLU-132          [-1, 5, 100, 100]               0\n",
      "          Conv2d-133          [-1, 2, 100, 100]              10\n",
      "     BatchNorm2d-134          [-1, 2, 100, 100]               4\n",
      "            ReLU-135          [-1, 2, 100, 100]               0\n",
      " ConvTranspose2d-136          [-1, 2, 200, 200]             100\n",
      "   Encode_Decode-137          [-1, 2, 200, 200]               0\n",
      "     BatchNorm2d-138          [-1, 2, 200, 200]               4\n",
      "            ReLU-139          [-1, 2, 200, 200]               0\n",
      "          Conv2d-140          [-1, 1, 200, 200]              50\n",
      "      conv_layer-141          [-1, 3, 200, 200]               0\n",
      "     BatchNorm2d-142          [-1, 3, 200, 200]               6\n",
      "            ReLU-143          [-1, 3, 200, 200]               0\n",
      "          Conv2d-144          [-1, 1, 200, 200]              75\n",
      "      conv_layer-145          [-1, 4, 200, 200]               0\n",
      "     Dense_block-146          [-1, 4, 200, 200]               0\n",
      "     BatchNorm2d-147          [-1, 4, 200, 200]               8\n",
      "            ReLU-148          [-1, 4, 200, 200]               0\n",
      "          Conv2d-149          [-1, 2, 200, 200]               8\n",
      "     BatchNorm2d-150          [-1, 2, 200, 200]               4\n",
      "            ReLU-151          [-1, 2, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]              32\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 3,427\n",
      "Trainable params: 3,427\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 44.32\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 44.94\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 5\n",
      "growth_rate= 1\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 |     219 |      25 |  0.001129497 |            f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1,  3,  1,  1,  0,  0],\n",
       "       [ 1,  3,  2,  1,  1,  1,  1],\n",
       "       [ 2,  6,  2,  0,  1,  0,  1],\n",
       "       [ 4,  4,  3,  1,  1,  1,  0],\n",
       "       [ 3,  7,  1,  0,  1,  1,  1],\n",
       "       [ 2,  1,  2,  1,  1,  1,  0],\n",
       "       [ 2,  4,  2,  1,  1,  1,  1],\n",
       "       [ 1, 10,  1,  1,  1,  1,  0],\n",
       "       [ 1,  8,  1,  1,  1,  1,  1],\n",
       "       [ 2,  1,  3,  1,  0,  0,  0],\n",
       "       [ 1,  1,  3,  0,  1,  0,  1],\n",
       "       [ 2,  5,  1,  0,  1,  0,  1],\n",
       "       [ 2,  2,  3,  1,  1,  0,  1],\n",
       "       [ 2, 11,  2,  1,  1,  1,  1],\n",
       "       [ 2,  2,  2,  0,  1,  1,  1],\n",
       "       [ 2,  1,  2,  1,  1,  0,  0],\n",
       "       [ 1,  6,  2,  0,  1,  1,  1],\n",
       "       [ 1,  1,  2,  1,  1,  0,  1],\n",
       "       [ 1,  1,  3,  0,  0,  1,  1],\n",
       "       [ 1, 11,  1,  1,  1,  1,  1],\n",
       "       [ 1,  1,  2,  1,  0,  0,  0],\n",
       "       [ 1,  1,  2,  0,  1,  0,  1],\n",
       "       [ 3,  8,  1,  1,  1,  1,  1],\n",
       "       [ 1,  1,  3,  1,  1,  1,  0],\n",
       "       [ 1,  1,  1,  0,  1,  0,  1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymoo.factory import get_termination\n",
    "\n",
    "termination = get_termination(\"n_gen\", 10)\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "res.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed8bc3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.15070369e-02, 5.37800000e+03],\n",
       "       [1.97237347e-02, 9.18500000e+03],\n",
       "       [1.27615110e-02, 7.12940000e+04],\n",
       "       [1.14984557e-02, 8.01930000e+04],\n",
       "       [1.05637000e-02, 2.59112000e+05],\n",
       "       [2.23934088e-02, 3.84400000e+03],\n",
       "       [1.38343917e-02, 3.93360000e+04],\n",
       "       [1.06562162e-02, 1.22494000e+05],\n",
       "       [1.19400208e-02, 7.90180000e+04],\n",
       "       [2.46245584e-02, 2.73400000e+03],\n",
       "       [3.53874449e-02, 1.16800000e+03],\n",
       "       [1.33824602e-02, 6.49870000e+04],\n",
       "       [2.04761051e-02, 8.57800000e+03],\n",
       "       [1.03725026e-02, 2.69061000e+05],\n",
       "       [1.69257929e-02, 1.04210000e+04],\n",
       "       [2.42604778e-02, 3.55200000e+03],\n",
       "       [1.55311794e-02, 2.88520000e+04],\n",
       "       [3.10807062e-02, 1.64800000e+03],\n",
       "       [3.86909857e-02, 1.01200000e+03],\n",
       "       [1.06210107e-02, 1.45919000e+05],\n",
       "       [3.29364741e-02, 1.36600000e+03],\n",
       "       [3.26892778e-02, 1.39200000e+03],\n",
       "       [9.69163956e-03, 3.83818000e+05],\n",
       "       [3.23177296e-02, 1.45800000e+03],\n",
       "       [3.02618713e-02, 1.74300000e+03]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd27c896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pareto set')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a=res.F\n",
    "plt.scatter(a[:,0],a[:,1], color=\"red\")\n",
    "plt.xlabel('RMSE_Test')\n",
    "#plt.xticks(np.arange(0,0.2))\n",
    "plt.ylabel('Num_Params')\n",
    "plt.title('Pareto set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cc994",
   "metadata": {},
   "source": [
    "### Selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "564131d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 10, 200, 200]           1,960\n",
      "        conv_layer-5         [-1, 14, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 14, 200, 200]              28\n",
      "              ReLU-7         [-1, 14, 200, 200]               0\n",
      "            Conv2d-8         [-1, 10, 200, 200]           6,860\n",
      "        conv_layer-9         [-1, 24, 200, 200]               0\n",
      "      Dense_block-10         [-1, 24, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 24, 200, 200]              48\n",
      "             ReLU-12         [-1, 24, 200, 200]               0\n",
      "           Conv2d-13         [-1, 12, 200, 200]             288\n",
      "      BatchNorm2d-14         [-1, 12, 200, 200]              24\n",
      "             ReLU-15         [-1, 12, 200, 200]               0\n",
      "           Conv2d-16         [-1, 12, 100, 100]           7,056\n",
      "    Encode_Decode-17         [-1, 12, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 12, 100, 100]              24\n",
      "             ReLU-19         [-1, 12, 100, 100]               0\n",
      "           Conv2d-20         [-1, 10, 100, 100]           5,880\n",
      "       conv_layer-21         [-1, 22, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 22, 100, 100]              44\n",
      "             ReLU-23         [-1, 22, 100, 100]               0\n",
      "           Conv2d-24         [-1, 10, 100, 100]          10,780\n",
      "       conv_layer-25         [-1, 32, 100, 100]               0\n",
      "      Dense_block-26         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 32, 100, 100]              64\n",
      "             ReLU-28         [-1, 32, 100, 100]               0\n",
      "           Conv2d-29         [-1, 16, 100, 100]             512\n",
      "      BatchNorm2d-30         [-1, 16, 100, 100]              32\n",
      "             ReLU-31         [-1, 16, 100, 100]               0\n",
      "           Conv2d-32           [-1, 16, 50, 50]          12,544\n",
      "    Encode_Decode-33           [-1, 16, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 16, 50, 50]              32\n",
      "             ReLU-35           [-1, 16, 50, 50]               0\n",
      "           Conv2d-36           [-1, 10, 50, 50]           7,840\n",
      "       conv_layer-37           [-1, 26, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 26, 50, 50]              52\n",
      "             ReLU-39           [-1, 26, 50, 50]               0\n",
      "           Conv2d-40           [-1, 10, 50, 50]          12,740\n",
      "       conv_layer-41           [-1, 36, 50, 50]               0\n",
      "      Dense_block-42           [-1, 36, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 36, 50, 50]              72\n",
      "             ReLU-44           [-1, 36, 50, 50]               0\n",
      "           Conv2d-45           [-1, 18, 50, 50]             648\n",
      "      BatchNorm2d-46           [-1, 18, 50, 50]              36\n",
      "             ReLU-47           [-1, 18, 50, 50]               0\n",
      "           Conv2d-48           [-1, 18, 25, 25]          15,876\n",
      "    Encode_Decode-49           [-1, 18, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 18, 25, 25]              36\n",
      "             ReLU-51           [-1, 18, 25, 25]               0\n",
      "           Conv2d-52           [-1, 10, 25, 25]           8,820\n",
      "       conv_layer-53           [-1, 28, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 28, 25, 25]              56\n",
      "             ReLU-55           [-1, 28, 25, 25]               0\n",
      "           Conv2d-56           [-1, 10, 25, 25]          13,720\n",
      "       conv_layer-57           [-1, 38, 25, 25]               0\n",
      "      BatchNorm2d-58           [-1, 38, 25, 25]              76\n",
      "             ReLU-59           [-1, 38, 25, 25]               0\n",
      "           Conv2d-60           [-1, 10, 25, 25]          18,620\n",
      "       conv_layer-61           [-1, 48, 25, 25]               0\n",
      "      BatchNorm2d-62           [-1, 48, 25, 25]              96\n",
      "             ReLU-63           [-1, 48, 25, 25]               0\n",
      "           Conv2d-64           [-1, 10, 25, 25]          23,520\n",
      "       conv_layer-65           [-1, 58, 25, 25]               0\n",
      "      Dense_block-66           [-1, 58, 25, 25]               0\n",
      "      BatchNorm2d-67           [-1, 58, 25, 25]             116\n",
      "             ReLU-68           [-1, 58, 25, 25]               0\n",
      "           Conv2d-69           [-1, 29, 25, 25]           1,682\n",
      "      BatchNorm2d-70           [-1, 29, 25, 25]              58\n",
      "             ReLU-71           [-1, 29, 25, 25]               0\n",
      "  ConvTranspose2d-72           [-1, 29, 50, 50]          41,209\n",
      "    Encode_Decode-73           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-74           [-1, 45, 50, 50]              90\n",
      "             ReLU-75           [-1, 45, 50, 50]               0\n",
      "           Conv2d-76           [-1, 10, 50, 50]          22,050\n",
      "       conv_layer-77           [-1, 55, 50, 50]               0\n",
      "      BatchNorm2d-78           [-1, 55, 50, 50]             110\n",
      "             ReLU-79           [-1, 55, 50, 50]               0\n",
      "           Conv2d-80           [-1, 10, 50, 50]          26,950\n",
      "       conv_layer-81           [-1, 65, 50, 50]               0\n",
      "      Dense_block-82           [-1, 65, 50, 50]               0\n",
      "      BatchNorm2d-83           [-1, 65, 50, 50]             130\n",
      "             ReLU-84           [-1, 65, 50, 50]               0\n",
      "           Conv2d-85           [-1, 32, 50, 50]           2,080\n",
      "      BatchNorm2d-86           [-1, 32, 50, 50]              64\n",
      "             ReLU-87           [-1, 32, 50, 50]               0\n",
      "  ConvTranspose2d-88         [-1, 32, 100, 100]          50,176\n",
      "    Encode_Decode-89         [-1, 32, 100, 100]               0\n",
      "      BatchNorm2d-90         [-1, 44, 100, 100]              88\n",
      "             ReLU-91         [-1, 44, 100, 100]               0\n",
      "           Conv2d-92         [-1, 10, 100, 100]          21,560\n",
      "       conv_layer-93         [-1, 54, 100, 100]               0\n",
      "      BatchNorm2d-94         [-1, 54, 100, 100]             108\n",
      "             ReLU-95         [-1, 54, 100, 100]               0\n",
      "           Conv2d-96         [-1, 10, 100, 100]          26,460\n",
      "       conv_layer-97         [-1, 64, 100, 100]               0\n",
      "      Dense_block-98         [-1, 64, 100, 100]               0\n",
      "      BatchNorm2d-99         [-1, 64, 100, 100]             128\n",
      "            ReLU-100         [-1, 64, 100, 100]               0\n",
      "          Conv2d-101         [-1, 32, 100, 100]           2,048\n",
      "     BatchNorm2d-102         [-1, 32, 100, 100]              64\n",
      "            ReLU-103         [-1, 32, 100, 100]               0\n",
      " ConvTranspose2d-104         [-1, 32, 200, 200]          50,176\n",
      "   Encode_Decode-105         [-1, 32, 200, 200]               0\n",
      "     BatchNorm2d-106         [-1, 36, 200, 200]              72\n",
      "            ReLU-107         [-1, 36, 200, 200]               0\n",
      "          Conv2d-108         [-1, 10, 200, 200]          17,640\n",
      "      conv_layer-109         [-1, 46, 200, 200]               0\n",
      "     BatchNorm2d-110         [-1, 46, 200, 200]              92\n",
      "            ReLU-111         [-1, 46, 200, 200]               0\n",
      "          Conv2d-112         [-1, 10, 200, 200]          22,540\n",
      "      conv_layer-113         [-1, 56, 200, 200]               0\n",
      "     Dense_block-114         [-1, 56, 200, 200]               0\n",
      "     BatchNorm2d-115         [-1, 56, 200, 200]             112\n",
      "            ReLU-116         [-1, 56, 200, 200]               0\n",
      "          Conv2d-117         [-1, 28, 200, 200]           1,568\n",
      "     BatchNorm2d-118         [-1, 28, 200, 200]              56\n",
      "            ReLU-119         [-1, 28, 200, 200]               0\n",
      " ConvTranspose2d-120          [-1, 1, 400, 400]             448\n",
      "     last_decode-121          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 436,411\n",
      "Trainable params: 436,411\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 348.71\n",
      "Params size (MB): 1.66\n",
      "Estimated Total Size (MB): 350.98\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more\n",
      "kerne_size= 7\n",
      "growth_rate= 10\n",
      "x1= 1\n",
      "x2= 1\n",
      "x3= 1\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: , Train RMSE: 0.39609647309293555,Validation RMSE: 0.35399449989658205\n",
      "Epoch 0: , Train loss: 5171174.03125,Validation loss: 501248.423828125\n",
      "Epoch 1: , Train RMSE: 0.21119004709394518,Validation RMSE: 0.18994342322997212\n",
      "Epoch 1: , Train loss: 1470056.73828125,Validation loss: 144314.01611328125\n",
      "Epoch 2: , Train RMSE: 0.10532545650016029,Validation RMSE: 0.10724727202104971\n",
      "Epoch 2: , Train loss: 365640.1708984375,Validation loss: 46007.909423828125\n",
      "Epoch 3: , Train RMSE: 0.07284425627992105,Validation RMSE: 0.08501588542823325\n",
      "Epoch 3: , Train loss: 174895.17578125,Validation loss: 28910.803100585938\n",
      "Epoch 4: , Train RMSE: 0.06001269629011795,Validation RMSE: 0.08561882836591467\n",
      "Epoch 4: , Train loss: 118706.2216796875,Validation loss: 29322.335083007812\n",
      "Epoch 5: , Train RMSE: 0.051214621796692165,Validation RMSE: 0.0869009322947194\n",
      "Epoch 5: , Train loss: 86452.01953125,Validation loss: 30207.088134765625\n",
      "Epoch 6: , Train RMSE: 0.045170477744276315,Validation RMSE: 0.08741327733638352\n",
      "Epoch 6: , Train loss: 67250.6630859375,Validation loss: 30564.32421875\n",
      "Epoch 7: , Train RMSE: 0.040890143652002844,Validation RMSE: 0.08756733597682485\n",
      "Epoch 7: , Train loss: 55109.246826171875,Validation loss: 30672.1533203125\n",
      "Epoch 8: , Train RMSE: 0.038009187880944664,Validation RMSE: 0.08758693574658588\n",
      "Epoch 8: , Train loss: 47617.258056640625,Validation loss: 30685.88525390625\n",
      "Epoch 9: , Train RMSE: 0.03564979580461658,Validation RMSE: 0.0849954545544753\n",
      "Epoch 9: , Train loss: 41889.125732421875,Validation loss: 28896.9091796875\n",
      "Epoch 10: , Train RMSE: 0.03383790979259376,Validation RMSE: 0.0768413997009933\n",
      "Epoch 10: , Train loss: 37739.33642578125,Validation loss: 23618.40283203125\n",
      "Epoch 11: , Train RMSE: 0.0323558844476315,Validation RMSE: 0.06481245185460333\n",
      "Epoch 11: , Train loss: 34505.931396484375,Validation loss: 16802.615661621094\n",
      "Epoch 12: , Train RMSE: 0.031119698038128352,Validation RMSE: 0.0501935508567328\n",
      "Epoch 12: , Train loss: 31919.637573242188,Validation loss: 10077.570190429688\n",
      "Epoch 13: , Train RMSE: 0.03008864050972197,Validation RMSE: 0.03817127678582367\n",
      "Epoch 13: , Train loss: 29839.554443359375,Validation loss: 5828.185485839844\n",
      "Epoch 14: , Train RMSE: 0.029209905170676717,Validation RMSE: 0.03213217937829803\n",
      "Epoch 14: , Train loss: 28122.083740234375,Validation loss: 4129.907806396484\n",
      "Epoch 15: , Train RMSE: 0.02846024230926338,Validation RMSE: 0.0297381904307033\n",
      "Epoch 15: , Train loss: 26697.118530273438,Validation loss: 3537.4398803710938\n",
      "Epoch 16: , Train RMSE: 0.027787505702147892,Validation RMSE: 0.02861463020764319\n",
      "Epoch 16: , Train loss: 25449.914794921875,Validation loss: 3275.188247680664\n",
      "Epoch 17: , Train RMSE: 0.027177146027277138,Validation RMSE: 0.02788838066239162\n",
      "Epoch 17: , Train loss: 24344.165893554688,Validation loss: 3111.047103881836\n",
      "Epoch 18: , Train RMSE: 0.026619614072941958,Validation RMSE: 0.027261090742694897\n",
      "Epoch 18: , Train loss: 23355.5830078125,Validation loss: 2972.6682739257812\n",
      "Epoch 19: , Train RMSE: 0.02611472097535812,Validation RMSE: 0.0267632174770318\n",
      "Epoch 19: , Train loss: 22478.016357421875,Validation loss: 2865.0792388916016\n",
      "Epoch 20: , Train RMSE: 0.02565156355189973,Validation RMSE: 0.02628855219398148\n",
      "Epoch 20: , Train loss: 21687.769409179688,Validation loss: 2764.351905822754\n",
      "Epoch 21: , Train RMSE: 0.025227035844449814,Validation RMSE: 0.025834008148567726\n",
      "Epoch 21: , Train loss: 20975.85400390625,Validation loss: 2669.5839080810547\n",
      "Epoch 22: , Train RMSE: 0.02483191485049181,Validation RMSE: 0.025426644298154888\n",
      "Epoch 22: , Train loss: 20323.926879882812,Validation loss: 2586.0569610595703\n",
      "Epoch 23: , Train RMSE: 0.02445678740307418,Validation RMSE: 0.025031553954756636\n",
      "Epoch 23: , Train loss: 19714.511474609375,Validation loss: 2506.3147735595703\n",
      "Epoch 24: , Train RMSE: 0.024092149467358714,Validation RMSE: 0.024642648559382578\n",
      "Epoch 24: , Train loss: 19131.027709960938,Validation loss: 2429.040512084961\n",
      "Epoch 25: , Train RMSE: 0.02373479014013691,Validation RMSE: 0.024270768464838093\n",
      "Epoch 25: , Train loss: 18567.695068359375,Validation loss: 2356.280807495117\n",
      "Epoch 26: , Train RMSE: 0.02338897798279401,Validation RMSE: 0.023931194580524045\n",
      "Epoch 26: , Train loss: 18030.579833984375,Validation loss: 2290.8082962036133\n",
      "Epoch 27: , Train RMSE: 0.0230586122947684,Validation RMSE: 0.023624083324591583\n",
      "Epoch 27: , Train loss: 17524.81884765625,Validation loss: 2232.3892517089844\n",
      "Epoch 28: , Train RMSE: 0.02274698816205703,Validation RMSE: 0.023334143320284488\n",
      "Epoch 28: , Train loss: 17054.343505859375,Validation loss: 2177.9289779663086\n",
      "Epoch 29: , Train RMSE: 0.022454150416364418,Validation RMSE: 0.023080745230598172\n",
      "Epoch 29: , Train loss: 16618.065185546875,Validation loss: 2130.883201599121\n",
      "Epoch 30: , Train RMSE: 0.022176656327970386,Validation RMSE: 0.022816935194324133\n",
      "Epoch 30: , Train loss: 16209.862670898438,Validation loss: 2082.450126647949\n",
      "Epoch 31: , Train RMSE: 0.02191677777989295,Validation RMSE: 0.022605554306635658\n",
      "Epoch 31: , Train loss: 15832.176086425781,Validation loss: 2044.0443420410156\n",
      "Epoch 32: , Train RMSE: 0.02167195147655996,Validation RMSE: 0.022373783185041157\n",
      "Epoch 32: , Train loss: 15480.437927246094,Validation loss: 2002.3446960449219\n",
      "Epoch 33: , Train RMSE: 0.02143560456115626,Validation RMSE: 0.022149709707385782\n",
      "Epoch 33: , Train loss: 15144.630310058594,Validation loss: 1962.4385604858398\n",
      "Epoch 34: , Train RMSE: 0.02120266306821052,Validation RMSE: 0.021854533053933985\n",
      "Epoch 34: , Train loss: 14817.264282226562,Validation loss: 1910.4824600219727\n",
      "Epoch 35: , Train RMSE: 0.020963220589522314,Validation RMSE: 0.021535778217270485\n",
      "Epoch 35: , Train loss: 14484.490112304688,Validation loss: 1855.1589736938477\n",
      "Epoch 36: , Train RMSE: 0.020715490055590716,Validation RMSE: 0.021224700003616783\n",
      "Epoch 36: , Train loss: 14144.175170898438,Validation loss: 1801.951560974121\n",
      "Epoch 37: , Train RMSE: 0.02046523939716497,Validation RMSE: 0.02090578329024382\n",
      "Epoch 37: , Train loss: 13804.505737304688,Validation loss: 1748.2070999145508\n",
      "Epoch 38: , Train RMSE: 0.020228660815660732,Validation RMSE: 0.02064379650529964\n",
      "Epoch 38: , Train loss: 13487.189758300781,Validation loss: 1704.6653366088867\n",
      "Epoch 39: , Train RMSE: 0.020013650291334287,Validation RMSE: 0.020443027880331612\n",
      "Epoch 39: , Train loss: 13202.002685546875,Validation loss: 1671.6695556640625\n",
      "Epoch 40: , Train RMSE: 0.019817353180081904,Validation RMSE: 0.020287146841043796\n",
      "Epoch 40: , Train loss: 12944.297973632812,Validation loss: 1646.273307800293\n",
      "Epoch 41: , Train RMSE: 0.019636003594649967,Validation RMSE: 0.020141549029287553\n",
      "Epoch 41: , Train loss: 12708.47412109375,Validation loss: 1622.7279891967773\n",
      "Epoch 42: , Train RMSE: 0.019466316515132594,Validation RMSE: 0.019955772660374096\n",
      "Epoch 42: , Train loss: 12489.779296875,Validation loss: 1592.9314498901367\n",
      "Epoch 43: , Train RMSE: 0.019302098159731447,Validation RMSE: 0.019749155292071763\n",
      "Epoch 43: , Train loss: 12279.93994140625,Validation loss: 1560.1165390014648\n",
      "Epoch 44: , Train RMSE: 0.019139813228510577,Validation RMSE: 0.019537846883963598\n",
      "Epoch 44: , Train loss: 12074.317565917969,Validation loss: 1526.9098434448242\n",
      "Epoch 45: , Train RMSE: 0.018973454591508905,Validation RMSE: 0.019343318903591873\n",
      "Epoch 45: , Train loss: 11865.335632324219,Validation loss: 1496.6559448242188\n",
      "Epoch 46: , Train RMSE: 0.018804061973349887,Validation RMSE: 0.019136272648698202\n",
      "Epoch 46: , Train loss: 11654.416931152344,Validation loss: 1464.7877235412598\n",
      "Epoch 47: , Train RMSE: 0.01863481983991388,Validation RMSE: 0.018881418690437718\n",
      "Epoch 47: , Train loss: 11445.574584960938,Validation loss: 1426.0318870544434\n",
      "Epoch 48: , Train RMSE: 0.018457101480898387,Validation RMSE: 0.0186299783082632\n",
      "Epoch 48: , Train loss: 11228.305053710938,Validation loss: 1388.3043670654297\n",
      "Epoch 49: , Train RMSE: 0.01827595156700058,Validation RMSE: 0.018435448173535974\n",
      "Epoch 49: , Train loss: 11008.982971191406,Validation loss: 1359.4629974365234\n",
      "Epoch 50: , Train RMSE: 0.018097218900556527,Validation RMSE: 0.018259822658082927\n",
      "Epoch 50: , Train loss: 10794.707580566406,Validation loss: 1333.6844940185547\n",
      "Epoch 51: , Train RMSE: 0.017925223142434884,Validation RMSE: 0.018082252604921446\n",
      "Epoch 51: , Train loss: 10590.4970703125,Validation loss: 1307.871437072754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: , Train RMSE: 0.01776660837725009,Validation RMSE: 0.017910442107903123\n",
      "Epoch 52: , Train loss: 10403.902221679688,Validation loss: 1283.1357460021973\n",
      "Epoch 53: , Train RMSE: 0.017623464358669905,Validation RMSE: 0.017769723652594466\n",
      "Epoch 53: , Train loss: 10236.930908203125,Validation loss: 1263.0523147583008\n",
      "Epoch 54: , Train RMSE: 0.017486794577831845,Validation RMSE: 0.017639371085730632\n",
      "Epoch 54: , Train loss: 10078.77197265625,Validation loss: 1244.5896492004395\n",
      "Epoch 55: , Train RMSE: 0.017353438073286605,Validation RMSE: 0.017533724605101074\n",
      "Epoch 55: , Train loss: 9925.634155273438,Validation loss: 1229.7259941101074\n",
      "Epoch 56: , Train RMSE: 0.01722465056904658,Validation RMSE: 0.01743244732355201\n",
      "Epoch 56: , Train loss: 9778.855834960938,Validation loss: 1215.560878753662\n",
      "Epoch 57: , Train RMSE: 0.01709874210304219,Validation RMSE: 0.017316070326204303\n",
      "Epoch 57: , Train loss: 9636.415710449219,Validation loss: 1199.385166168213\n",
      "Epoch 58: , Train RMSE: 0.016972322059334893,Validation RMSE: 0.017181367175333015\n",
      "Epoch 58: , Train loss: 9494.4482421875,Validation loss: 1180.7975120544434\n",
      "Epoch 59: , Train RMSE: 0.016845192204815364,Validation RMSE: 0.017051036435169822\n",
      "Epoch 59: , Train loss: 9352.74609375,Validation loss: 1162.951374053955\n",
      "Epoch 60: , Train RMSE: 0.016716082316580234,Validation RMSE: 0.016901866295147207\n",
      "Epoch 60: , Train loss: 9209.927368164062,Validation loss: 1142.6923370361328\n",
      "Epoch 61: , Train RMSE: 0.01658794332014525,Validation RMSE: 0.016766742366875205\n",
      "Epoch 61: , Train loss: 9069.269104003906,Validation loss: 1124.4945983886719\n",
      "Epoch 62: , Train RMSE: 0.016460367975309496,Validation RMSE: 0.016608805893400372\n",
      "Epoch 62: , Train loss: 8930.304809570312,Validation loss: 1103.4097328186035\n",
      "Epoch 63: , Train RMSE: 0.016335593811206733,Validation RMSE: 0.016473832998201994\n",
      "Epoch 63: , Train loss: 8795.429565429688,Validation loss: 1085.5486946105957\n",
      "Epoch 64: , Train RMSE: 0.016219827903704166,Validation RMSE: 0.016352526757049714\n",
      "Epoch 64: , Train loss: 8671.209655761719,Validation loss: 1069.6205253601074\n",
      "Epoch 65: , Train RMSE: 0.016113283893240442,Validation RMSE: 0.016235189408259774\n",
      "Epoch 65: , Train loss: 8557.665771484375,Validation loss: 1054.3255004882812\n",
      "Epoch 66: , Train RMSE: 0.016011701850852468,Validation RMSE: 0.016124699464111644\n",
      "Epoch 66: , Train loss: 8450.106689453125,Validation loss: 1040.0237312316895\n",
      "Epoch 67: , Train RMSE: 0.01591230729868759,Validation RMSE: 0.0160268340395811\n",
      "Epoch 67: , Train loss: 8345.522216796875,Validation loss: 1027.4376373291016\n",
      "Epoch 68: , Train RMSE: 0.015817450033854808,Validation RMSE: 0.01593793316420774\n",
      "Epoch 68: , Train loss: 8246.319274902344,Validation loss: 1016.0708541870117\n",
      "Epoch 69: , Train RMSE: 0.015725192234177867,Validation RMSE: 0.0158636745393795\n",
      "Epoch 69: , Train loss: 8150.403869628906,Validation loss: 1006.6246795654297\n",
      "Epoch 70: , Train RMSE: 0.01563786355282156,Validation RMSE: 0.015803034305142533\n",
      "Epoch 70: , Train loss: 8060.129913330078,Validation loss: 998.9435729980469\n",
      "Epoch 71: , Train RMSE: 0.015557916902617654,Validation RMSE: 0.01576772146964292\n",
      "Epoch 71: , Train loss: 7977.927734375,Validation loss: 994.4841613769531\n",
      "Epoch 72: , Train RMSE: 0.015492179883490519,Validation RMSE: 0.015753520995862795\n",
      "Epoch 72: , Train loss: 7910.6517333984375,Validation loss: 992.6936950683594\n",
      "Epoch 73: , Train RMSE: 0.015435477560068286,Validation RMSE: 0.015742359699982878\n",
      "Epoch 73: , Train loss: 7852.850769042969,Validation loss: 991.2875556945801\n",
      "Epoch 74: , Train RMSE: 0.015389840916953565,Validation RMSE: 0.015786383007460953\n",
      "Epoch 74: , Train loss: 7806.483825683594,Validation loss: 996.8395538330078\n",
      "Epoch 75: , Train RMSE: 0.015386641873706123,Validation RMSE: 0.0159220478920726\n",
      "Epoch 75: , Train loss: 7803.238739013672,Validation loss: 1014.0464363098145\n",
      "Epoch 76: , Train RMSE: 0.01541825912460263,Validation RMSE: 0.015887397520873803\n",
      "Epoch 76: , Train loss: 7835.340667724609,Validation loss: 1009.6375999450684\n",
      "Epoch 77: , Train RMSE: 0.015318721613076248,Validation RMSE: 0.015381969670987117\n",
      "Epoch 77: , Train loss: 7734.5001220703125,Validation loss: 946.4199638366699\n",
      "Epoch 78: , Train RMSE: 0.015060324705401775,Validation RMSE: 0.015515328057742766\n",
      "Epoch 78: , Train loss: 7475.769012451172,Validation loss: 962.9016189575195\n",
      "Epoch 79: , Train RMSE: 0.015139333252711563,Validation RMSE: 0.01570837894436448\n",
      "Epoch 79: , Train loss: 7554.41259765625,Validation loss: 987.0126762390137\n",
      "Epoch 80: , Train RMSE: 0.015106973243220231,Validation RMSE: 0.015237924453794417\n",
      "Epoch 80: , Train loss: 7522.152313232422,Validation loss: 928.7773666381836\n",
      "Epoch 81: , Train RMSE: 0.014829983759832221,Validation RMSE: 0.015151469186481921\n",
      "Epoch 81: , Train loss: 7248.840667724609,Validation loss: 918.2680740356445\n",
      "Epoch 82: , Train RMSE: 0.014765033072218731,Validation RMSE: 0.015147074708434643\n",
      "Epoch 82: , Train loss: 7185.484405517578,Validation loss: 917.7354888916016\n",
      "Epoch 83: , Train RMSE: 0.014711984494697806,Validation RMSE: 0.015180938370742574\n",
      "Epoch 83: , Train loss: 7133.944396972656,Validation loss: 921.8435592651367\n",
      "Epoch 84: , Train RMSE: 0.014673397903891158,Validation RMSE: 0.015122944778911638\n",
      "Epoch 84: , Train loss: 7096.5716552734375,Validation loss: 914.813835144043\n",
      "Epoch 85: , Train RMSE: 0.014582238602872735,Validation RMSE: 0.015131357890157664\n",
      "Epoch 85: , Train loss: 7008.669860839844,Validation loss: 915.8319664001465\n",
      "Epoch 86: , Train RMSE: 0.014557784000333139,Validation RMSE: 0.01519946495921441\n",
      "Epoch 86: , Train loss: 6985.182312011719,Validation loss: 924.0949401855469\n",
      "Epoch 87: , Train RMSE: 0.014543546767636804,Validation RMSE: 0.01505790545403303\n",
      "Epoch 87: , Train loss: 6971.5262451171875,Validation loss: 906.9620666503906\n",
      "Epoch 88: , Train RMSE: 0.014428481020837814,Validation RMSE: 0.014840764181095319\n",
      "Epoch 88: , Train loss: 6861.647888183594,Validation loss: 880.9931259155273\n",
      "Epoch 89: , Train RMSE: 0.014287956694716039,Validation RMSE: 0.014656809684299143\n",
      "Epoch 89: , Train loss: 6728.642486572266,Validation loss: 859.2882804870605\n",
      "Epoch 90: , Train RMSE: 0.014167670746838024,Validation RMSE: 0.014528630043026219\n",
      "Epoch 90: , Train loss: 6615.826599121094,Validation loss: 844.3243637084961\n",
      "Epoch 91: , Train RMSE: 0.014082982361325182,Validation RMSE: 0.014465595140341866\n",
      "Epoch 91: , Train loss: 6536.9697265625,Validation loss: 837.0137710571289\n",
      "Epoch 92: , Train RMSE: 0.014037327957784304,Validation RMSE: 0.014479422239979932\n",
      "Epoch 92: , Train loss: 6494.6551513671875,Validation loss: 838.614673614502\n",
      "Epoch 93: , Train RMSE: 0.014042869652101329,Validation RMSE: 0.0146116591029675\n",
      "Epoch 93: , Train loss: 6499.784118652344,Validation loss: 854.002326965332\n",
      "Epoch 94: , Train RMSE: 0.014130371612792604,Validation RMSE: 0.014895593764861744\n",
      "Epoch 94: , Train loss: 6581.037567138672,Validation loss: 887.5148544311523\n",
      "Epoch 95: , Train RMSE: 0.014306092614705224,Validation RMSE: 0.015190299698344898\n",
      "Epoch 95: , Train loss: 6745.73486328125,Validation loss: 922.9808197021484\n",
      "Epoch 96: , Train RMSE: 0.014374416560083404,Validation RMSE: 0.01432097418172632\n",
      "Epoch 96: , Train loss: 6810.3221435546875,Validation loss: 820.3612060546875\n",
      "Epoch 97: , Train RMSE: 0.01392269253969562,Validation RMSE: 0.014743385512894789\n",
      "Epoch 97: , Train loss: 6389.011474609375,Validation loss: 869.4696655273438\n",
      "Epoch 98: , Train RMSE: 0.014101986258147303,Validation RMSE: 0.014344687703384037\n",
      "Epoch 98: , Train loss: 6554.6239013671875,Validation loss: 823.0802612304688\n",
      "Epoch 99: , Train RMSE: 0.013764242084006091,Validation RMSE: 0.014090806641024451\n",
      "Epoch 99: , Train loss: 6244.415710449219,Validation loss: 794.2033271789551\n",
      "Epoch 100: , Train RMSE: 0.013623597146677434,Validation RMSE: 0.013860862505884815\n",
      "Epoch 100: , Train loss: 6117.455078125,Validation loss: 768.4940376281738\n",
      "Epoch 101: , Train RMSE: 0.013504296190849252,Validation RMSE: 0.01390621097859255\n",
      "Epoch 101: , Train loss: 6010.783874511719,Validation loss: 773.5308151245117\n",
      "Epoch 102: , Train RMSE: 0.013436617931045901,Validation RMSE: 0.013974557373461947\n",
      "Epoch 102: , Train loss: 5950.687438964844,Validation loss: 781.1530151367188\n",
      "Epoch 103: , Train RMSE: 0.013445659200752243,Validation RMSE: 0.014015329755482288\n",
      "Epoch 103: , Train loss: 5958.6983642578125,Validation loss: 785.7178726196289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: , Train RMSE: 0.013352209790457863,Validation RMSE: 0.013769176635504629\n",
      "Epoch 104: , Train loss: 5876.158447265625,Validation loss: 758.3609008789062\n",
      "Epoch 105: , Train RMSE: 0.0132619866362739,Validation RMSE: 0.013690906048615148\n",
      "Epoch 105: , Train loss: 5797.014343261719,Validation loss: 749.7636337280273\n",
      "Epoch 106: , Train RMSE: 0.013132056333641546,Validation RMSE: 0.013344157264086933\n",
      "Epoch 106: , Train loss: 5683.981781005859,Validation loss: 712.2661323547363\n",
      "Epoch 107: , Train RMSE: 0.013041998479302328,Validation RMSE: 0.0134967264515677\n",
      "Epoch 107: , Train loss: 5606.289154052734,Validation loss: 728.6464996337891\n",
      "Epoch 108: , Train RMSE: 0.013026001175682889,Validation RMSE: 0.013391911376983477\n",
      "Epoch 108: , Train loss: 5592.544250488281,Validation loss: 717.373161315918\n",
      "Epoch 109: , Train RMSE: 0.013018142040839169,Validation RMSE: 0.013521028318404979\n",
      "Epoch 109: , Train loss: 5585.7978515625,Validation loss: 731.2728271484375\n",
      "Epoch 110: , Train RMSE: 0.012939140170411709,Validation RMSE: 0.013324574721028692\n",
      "Epoch 110: , Train loss: 5518.2076416015625,Validation loss: 710.1771659851074\n",
      "Epoch 111: , Train RMSE: 0.012890759998500135,Validation RMSE: 0.013236087728779702\n",
      "Epoch 111: , Train loss: 5477.019012451172,Validation loss: 700.7760734558105\n",
      "Epoch 112: , Train RMSE: 0.012739274719822362,Validation RMSE: 0.01295087622251986\n",
      "Epoch 112: , Train loss: 5349.049407958984,Validation loss: 670.9007797241211\n",
      "Epoch 113: , Train RMSE: 0.012781167694202763,Validation RMSE: 0.013427915197646125\n",
      "Epoch 113: , Train loss: 5384.287841796875,Validation loss: 721.2356262207031\n",
      "Epoch 114: , Train RMSE: 0.013179894478582584,Validation RMSE: 0.014678906463098421\n",
      "Epoch 114: , Train loss: 5725.469024658203,Validation loss: 861.8811798095703\n",
      "Epoch 115: , Train RMSE: 0.01387576218714321,Validation RMSE: 0.014195711725443946\n",
      "Epoch 115: , Train loss: 6346.012145996094,Validation loss: 806.072925567627\n",
      "Epoch 116: , Train RMSE: 0.013095506606256909,Validation RMSE: 0.013694298888940293\n",
      "Epoch 116: , Train loss: 5652.385986328125,Validation loss: 750.1352882385254\n",
      "Epoch 117: , Train RMSE: 0.013048103806461448,Validation RMSE: 0.013409089434642741\n",
      "Epoch 117: , Train loss: 5611.539306640625,Validation loss: 719.2147178649902\n",
      "Epoch 118: , Train RMSE: 0.012666345050011917,Validation RMSE: 0.013116429391643212\n",
      "Epoch 118: , Train loss: 5287.9803466796875,Validation loss: 688.1628799438477\n",
      "Epoch 119: , Train RMSE: 0.012512677180720492,Validation RMSE: 0.01284408104834205\n",
      "Epoch 119: , Train loss: 5160.4512939453125,Validation loss: 659.8816719055176\n",
      "Epoch 120: , Train RMSE: 0.012427351304014745,Validation RMSE: 0.012846235048783315\n",
      "Epoch 120: , Train loss: 5090.311431884766,Validation loss: 660.1030197143555\n",
      "Epoch 121: , Train RMSE: 0.012283562620990294,Validation RMSE: 0.012529245154377368\n",
      "Epoch 121: , Train loss: 4973.199615478516,Validation loss: 627.9279365539551\n",
      "Epoch 122: , Train RMSE: 0.012141719279134468,Validation RMSE: 0.012556018428841222\n",
      "Epoch 122: , Train loss: 4859.007598876953,Validation loss: 630.6143951416016\n",
      "Epoch 123: , Train RMSE: 0.012028380405170064,Validation RMSE: 0.01240455000830374\n",
      "Epoch 123: , Train loss: 4768.716583251953,Validation loss: 615.4914436340332\n",
      "Epoch 124: , Train RMSE: 0.011997532680394121,Validation RMSE: 0.012369160131562269\n",
      "Epoch 124: , Train loss: 4744.2884521484375,Validation loss: 611.984489440918\n",
      "Epoch 125: , Train RMSE: 0.011882320169227573,Validation RMSE: 0.01232836472891024\n",
      "Epoch 125: , Train loss: 4653.606994628906,Validation loss: 607.9543075561523\n",
      "Epoch 126: , Train RMSE: 0.011873791905597574,Validation RMSE: 0.012340088738318702\n",
      "Epoch 126: , Train loss: 4646.929351806641,Validation loss: 609.1111602783203\n",
      "Epoch 127: , Train RMSE: 0.011774066190818541,Validation RMSE: 0.012115266117569098\n",
      "Epoch 127: , Train loss: 4569.199798583984,Validation loss: 587.1186923980713\n",
      "Epoch 128: , Train RMSE: 0.011767960395623429,Validation RMSE: 0.012156566919740926\n",
      "Epoch 128: , Train loss: 4564.4620361328125,Validation loss: 591.1284770965576\n",
      "Epoch 129: , Train RMSE: 0.011713260804495845,Validation RMSE: 0.012275088174351757\n",
      "Epoch 129: , Train loss: 4522.127777099609,Validation loss: 602.7111587524414\n",
      "Epoch 130: , Train RMSE: 0.011792266775642121,Validation RMSE: 0.012465485912817983\n",
      "Epoch 130: , Train loss: 4583.3370361328125,Validation loss: 621.5533561706543\n",
      "Epoch 131: , Train RMSE: 0.01186689510563215,Validation RMSE: 0.012508993804254322\n",
      "Epoch 131: , Train loss: 4641.532653808594,Validation loss: 625.8997039794922\n",
      "Epoch 132: , Train RMSE: 0.011957507000482552,Validation RMSE: 0.012855724312471336\n",
      "Epoch 132: , Train loss: 4712.685852050781,Validation loss: 661.0785903930664\n",
      "Epoch 133: , Train RMSE: 0.012104623724422945,Validation RMSE: 0.012289251851092087\n",
      "Epoch 133: , Train loss: 4829.362335205078,Validation loss: 604.1028442382812\n",
      "Epoch 134: , Train RMSE: 0.011766337282691297,Validation RMSE: 0.012572327295294023\n",
      "Epoch 134: , Train loss: 4563.2030029296875,Validation loss: 632.2536544799805\n",
      "Epoch 135: , Train RMSE: 0.012104871897630976,Validation RMSE: 0.013505916182149602\n",
      "Epoch 135: , Train loss: 4829.560363769531,Validation loss: 729.639087677002\n",
      "Epoch 136: , Train RMSE: 0.012239554519897831,Validation RMSE: 0.012121055138268595\n",
      "Epoch 136: , Train loss: 4937.628662109375,Validation loss: 587.67991065979\n",
      "Epoch 137: , Train RMSE: 0.011628535216511297,Validation RMSE: 0.012445979386043013\n",
      "Epoch 137: , Train loss: 4456.944519042969,Validation loss: 619.6096115112305\n",
      "Epoch 138: , Train RMSE: 0.011856106877784487,Validation RMSE: 0.012251711550665699\n",
      "Epoch 138: , Train loss: 4633.097229003906,Validation loss: 600.4177436828613\n",
      "Epoch 139: , Train RMSE: 0.011422400584317073,Validation RMSE: 0.012273614349159523\n",
      "Epoch 139: , Train loss: 4300.3319091796875,Validation loss: 602.5664367675781\n",
      "Epoch 140: , Train RMSE: 0.011457669316596874,Validation RMSE: 0.01206844017543806\n",
      "Epoch 140: , Train loss: 4326.929016113281,Validation loss: 582.5889930725098\n",
      "Epoch 141: , Train RMSE: 0.01135117178246876,Validation RMSE: 0.011852150527156567\n",
      "Epoch 141: , Train loss: 4246.866363525391,Validation loss: 561.8938884735107\n",
      "Epoch 142: , Train RMSE: 0.011303942548500402,Validation RMSE: 0.012239965026531244\n",
      "Epoch 142: , Train loss: 4211.599700927734,Validation loss: 599.266975402832\n",
      "Epoch 143: , Train RMSE: 0.011218392497015055,Validation RMSE: 0.011853987785737253\n",
      "Epoch 143: , Train loss: 4148.092803955078,Validation loss: 562.0681056976318\n",
      "Epoch 144: , Train RMSE: 0.011285005445901204,Validation RMSE: 0.012165531919854774\n",
      "Epoch 144: , Train loss: 4197.500427246094,Validation loss: 592.0006675720215\n",
      "Epoch 145: , Train RMSE: 0.011095796237532136,Validation RMSE: 0.011389679020452435\n",
      "Epoch 145: , Train loss: 4057.926239013672,Validation loss: 518.8991527557373\n",
      "Epoch 146: , Train RMSE: 0.011004606179822784,Validation RMSE: 0.011599552686880024\n",
      "Epoch 146: , Train loss: 3991.500732421875,Validation loss: 538.1984901428223\n",
      "Epoch 147: , Train RMSE: 0.010904891930335862,Validation RMSE: 0.011334585034212617\n",
      "Epoch 147: , Train loss: 3919.493377685547,Validation loss: 513.8912715911865\n",
      "Epoch 148: , Train RMSE: 0.010944597922543532,Validation RMSE: 0.011504348720467262\n",
      "Epoch 148: , Train loss: 3948.0880126953125,Validation loss: 529.4001579284668\n",
      "Epoch 149: , Train RMSE: 0.010804083388071286,Validation RMSE: 0.011230932713751744\n",
      "Epoch 149: , Train loss: 3847.362060546875,Validation loss: 504.53539848327637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.010759183686854822, 436411)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "evalu_fun(train_data,valid_data,test_data,k=3,growth_rate=10,x=2,x1=1,x2=1,x3=1,x4=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae2b390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 200, 200]             144\n",
      "       BatchNorm2d-2          [-1, 4, 200, 200]               8\n",
      "              ReLU-3          [-1, 4, 200, 200]               0\n",
      "            Conv2d-4         [-1, 19, 200, 200]             684\n",
      "        conv_layer-5         [-1, 23, 200, 200]               0\n",
      "       BatchNorm2d-6         [-1, 23, 200, 200]              46\n",
      "              ReLU-7         [-1, 23, 200, 200]               0\n",
      "            Conv2d-8         [-1, 19, 200, 200]           3,933\n",
      "        conv_layer-9         [-1, 42, 200, 200]               0\n",
      "      Dense_block-10         [-1, 42, 200, 200]               0\n",
      "      BatchNorm2d-11         [-1, 42, 200, 200]              84\n",
      "             ReLU-12         [-1, 42, 200, 200]               0\n",
      "           Conv2d-13         [-1, 21, 200, 200]             882\n",
      "      BatchNorm2d-14         [-1, 21, 200, 200]              42\n",
      "             ReLU-15         [-1, 21, 200, 200]               0\n",
      "           Conv2d-16         [-1, 21, 100, 100]           3,969\n",
      "    Encode_Decode-17         [-1, 21, 100, 100]               0\n",
      "      BatchNorm2d-18         [-1, 21, 100, 100]              42\n",
      "             ReLU-19         [-1, 21, 100, 100]               0\n",
      "           Conv2d-20         [-1, 19, 100, 100]           3,591\n",
      "       conv_layer-21         [-1, 40, 100, 100]               0\n",
      "      BatchNorm2d-22         [-1, 40, 100, 100]              80\n",
      "             ReLU-23         [-1, 40, 100, 100]               0\n",
      "           Conv2d-24         [-1, 19, 100, 100]           6,840\n",
      "       conv_layer-25         [-1, 59, 100, 100]               0\n",
      "      Dense_block-26         [-1, 59, 100, 100]               0\n",
      "      BatchNorm2d-27         [-1, 59, 100, 100]             118\n",
      "             ReLU-28         [-1, 59, 100, 100]               0\n",
      "           Conv2d-29         [-1, 29, 100, 100]           1,711\n",
      "      BatchNorm2d-30         [-1, 29, 100, 100]              58\n",
      "             ReLU-31         [-1, 29, 100, 100]               0\n",
      "           Conv2d-32           [-1, 29, 50, 50]           7,569\n",
      "    Encode_Decode-33           [-1, 29, 50, 50]               0\n",
      "      BatchNorm2d-34           [-1, 29, 50, 50]              58\n",
      "             ReLU-35           [-1, 29, 50, 50]               0\n",
      "           Conv2d-36           [-1, 19, 50, 50]           4,959\n",
      "       conv_layer-37           [-1, 48, 50, 50]               0\n",
      "      BatchNorm2d-38           [-1, 48, 50, 50]              96\n",
      "             ReLU-39           [-1, 48, 50, 50]               0\n",
      "           Conv2d-40           [-1, 19, 50, 50]           8,208\n",
      "       conv_layer-41           [-1, 67, 50, 50]               0\n",
      "      Dense_block-42           [-1, 67, 50, 50]               0\n",
      "      BatchNorm2d-43           [-1, 67, 50, 50]             134\n",
      "             ReLU-44           [-1, 67, 50, 50]               0\n",
      "           Conv2d-45           [-1, 33, 50, 50]           2,211\n",
      "      BatchNorm2d-46           [-1, 33, 50, 50]              66\n",
      "             ReLU-47           [-1, 33, 50, 50]               0\n",
      "           Conv2d-48           [-1, 33, 25, 25]           9,801\n",
      "    Encode_Decode-49           [-1, 33, 25, 25]               0\n",
      "      BatchNorm2d-50           [-1, 33, 25, 25]              66\n",
      "             ReLU-51           [-1, 33, 25, 25]               0\n",
      "           Conv2d-52           [-1, 19, 25, 25]           5,643\n",
      "       conv_layer-53           [-1, 52, 25, 25]               0\n",
      "      BatchNorm2d-54           [-1, 52, 25, 25]             104\n",
      "             ReLU-55           [-1, 52, 25, 25]               0\n",
      "           Conv2d-56           [-1, 19, 25, 25]           8,892\n",
      "       conv_layer-57           [-1, 71, 25, 25]               0\n",
      "      Dense_block-58           [-1, 71, 25, 25]               0\n",
      "      BatchNorm2d-59           [-1, 71, 25, 25]             142\n",
      "             ReLU-60           [-1, 71, 25, 25]               0\n",
      "           Conv2d-61           [-1, 35, 25, 25]           2,485\n",
      "      BatchNorm2d-62           [-1, 35, 25, 25]              70\n",
      "             ReLU-63           [-1, 35, 25, 25]               0\n",
      "           Conv2d-64           [-1, 35, 13, 13]          11,025\n",
      "    Encode_Decode-65           [-1, 35, 13, 13]               0\n",
      "      BatchNorm2d-66           [-1, 35, 13, 13]              70\n",
      "             ReLU-67           [-1, 35, 13, 13]               0\n",
      "           Conv2d-68           [-1, 19, 13, 13]           5,985\n",
      "       conv_layer-69           [-1, 54, 13, 13]               0\n",
      "      BatchNorm2d-70           [-1, 54, 13, 13]             108\n",
      "             ReLU-71           [-1, 54, 13, 13]               0\n",
      "           Conv2d-72           [-1, 19, 13, 13]           9,234\n",
      "       conv_layer-73           [-1, 73, 13, 13]               0\n",
      "      BatchNorm2d-74           [-1, 73, 13, 13]             146\n",
      "             ReLU-75           [-1, 73, 13, 13]               0\n",
      "           Conv2d-76           [-1, 19, 13, 13]          12,483\n",
      "       conv_layer-77           [-1, 92, 13, 13]               0\n",
      "      BatchNorm2d-78           [-1, 92, 13, 13]             184\n",
      "             ReLU-79           [-1, 92, 13, 13]               0\n",
      "           Conv2d-80           [-1, 19, 13, 13]          15,732\n",
      "       conv_layer-81          [-1, 111, 13, 13]               0\n",
      "      Dense_block-82          [-1, 111, 13, 13]               0\n",
      "      BatchNorm2d-83          [-1, 111, 13, 13]             222\n",
      "             ReLU-84          [-1, 111, 13, 13]               0\n",
      "           Conv2d-85           [-1, 55, 13, 13]           6,105\n",
      "      BatchNorm2d-86           [-1, 55, 13, 13]             110\n",
      "             ReLU-87           [-1, 55, 13, 13]               0\n",
      "  ConvTranspose2d-88           [-1, 55, 25, 25]          27,225\n",
      "    Encode_Decode-89           [-1, 55, 25, 25]               0\n",
      "      BatchNorm2d-90           [-1, 55, 25, 25]             110\n",
      "             ReLU-91           [-1, 55, 25, 25]               0\n",
      "           Conv2d-92           [-1, 19, 25, 25]           9,405\n",
      "       conv_layer-93           [-1, 74, 25, 25]               0\n",
      "      BatchNorm2d-94           [-1, 74, 25, 25]             148\n",
      "             ReLU-95           [-1, 74, 25, 25]               0\n",
      "           Conv2d-96           [-1, 19, 25, 25]          12,654\n",
      "       conv_layer-97           [-1, 93, 25, 25]               0\n",
      "      Dense_block-98           [-1, 93, 25, 25]               0\n",
      "      BatchNorm2d-99           [-1, 93, 25, 25]             186\n",
      "            ReLU-100           [-1, 93, 25, 25]               0\n",
      "          Conv2d-101           [-1, 46, 25, 25]           4,278\n",
      "     BatchNorm2d-102           [-1, 46, 25, 25]              92\n",
      "            ReLU-103           [-1, 46, 25, 25]               0\n",
      " ConvTranspose2d-104           [-1, 46, 50, 50]          19,044\n",
      "   Encode_Decode-105           [-1, 46, 50, 50]               0\n",
      "     BatchNorm2d-106           [-1, 75, 50, 50]             150\n",
      "            ReLU-107           [-1, 75, 50, 50]               0\n",
      "          Conv2d-108           [-1, 19, 50, 50]          12,825\n",
      "      conv_layer-109           [-1, 94, 50, 50]               0\n",
      "     BatchNorm2d-110           [-1, 94, 50, 50]             188\n",
      "            ReLU-111           [-1, 94, 50, 50]               0\n",
      "          Conv2d-112           [-1, 19, 50, 50]          16,074\n",
      "      conv_layer-113          [-1, 113, 50, 50]               0\n",
      "     Dense_block-114          [-1, 113, 50, 50]               0\n",
      "     BatchNorm2d-115          [-1, 113, 50, 50]             226\n",
      "            ReLU-116          [-1, 113, 50, 50]               0\n",
      "          Conv2d-117           [-1, 56, 50, 50]           6,328\n",
      "     BatchNorm2d-118           [-1, 56, 50, 50]             112\n",
      "            ReLU-119           [-1, 56, 50, 50]               0\n",
      " ConvTranspose2d-120         [-1, 56, 100, 100]          28,224\n",
      "   Encode_Decode-121         [-1, 56, 100, 100]               0\n",
      "     BatchNorm2d-122         [-1, 56, 100, 100]             112\n",
      "            ReLU-123         [-1, 56, 100, 100]               0\n",
      "          Conv2d-124         [-1, 19, 100, 100]           9,576\n",
      "      conv_layer-125         [-1, 75, 100, 100]               0\n",
      "     BatchNorm2d-126         [-1, 75, 100, 100]             150\n",
      "            ReLU-127         [-1, 75, 100, 100]               0\n",
      "          Conv2d-128         [-1, 19, 100, 100]          12,825\n",
      "      conv_layer-129         [-1, 94, 100, 100]               0\n",
      "     Dense_block-130         [-1, 94, 100, 100]               0\n",
      "     BatchNorm2d-131         [-1, 94, 100, 100]             188\n",
      "            ReLU-132         [-1, 94, 100, 100]               0\n",
      "          Conv2d-133         [-1, 47, 100, 100]           4,418\n",
      "     BatchNorm2d-134         [-1, 47, 100, 100]              94\n",
      "            ReLU-135         [-1, 47, 100, 100]               0\n",
      " ConvTranspose2d-136         [-1, 47, 200, 200]          19,881\n",
      "   Encode_Decode-137         [-1, 47, 200, 200]               0\n",
      "     BatchNorm2d-138         [-1, 47, 200, 200]              94\n",
      "            ReLU-139         [-1, 47, 200, 200]               0\n",
      "          Conv2d-140         [-1, 19, 200, 200]           8,037\n",
      "      conv_layer-141         [-1, 66, 200, 200]               0\n",
      "     BatchNorm2d-142         [-1, 66, 200, 200]             132\n",
      "            ReLU-143         [-1, 66, 200, 200]               0\n",
      "          Conv2d-144         [-1, 19, 200, 200]          11,286\n",
      "      conv_layer-145         [-1, 85, 200, 200]               0\n",
      "     Dense_block-146         [-1, 85, 200, 200]               0\n",
      "     BatchNorm2d-147         [-1, 85, 200, 200]             170\n",
      "            ReLU-148         [-1, 85, 200, 200]               0\n",
      "          Conv2d-149         [-1, 42, 200, 200]           3,570\n",
      "     BatchNorm2d-150         [-1, 42, 200, 200]              84\n",
      "            ReLU-151         [-1, 42, 200, 200]               0\n",
      " ConvTranspose2d-152          [-1, 1, 400, 400]             672\n",
      "     last_decode-153          [-1, 1, 400, 400]               0\n",
      "================================================================\n",
      "Total params: 342,698\n",
      "Trainable params: 342,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.61\n",
      "Forward/backward pass size (MB): 545.83\n",
      "Params size (MB): 1.31\n",
      "Estimated Total Size (MB): 547.75\n",
      "----------------------------------------------------------------\n",
      "Dense_C8_skip_more_one\n",
      "kerne_size= 3\n",
      "growth_rate= 19\n",
      "x1= 0\n",
      "x2= 1\n",
      "x3= 0\n",
      "x4= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: , Train RMSE: 0.3709196643917574,Validation RMSE: 0.41061354447966797\n",
      "Epoch 0: , Train loss: 4534682.859375,Validation loss: 674413.931640625\n",
      "Epoch 1: , Train RMSE: 0.14649832376953092,Validation RMSE: 0.17957644054286986\n",
      "Epoch 1: , Train loss: 707379.572265625,Validation loss: 128990.7919921875\n",
      "Epoch 2: , Train RMSE: 0.08463320015923845,Validation RMSE: 0.0874480293483739\n",
      "Epoch 2: , Train loss: 236085.181640625,Validation loss: 30588.63134765625\n",
      "Epoch 3: , Train RMSE: 0.06774813215371646,Validation RMSE: 0.08680733633373058\n",
      "Epoch 3: , Train loss: 151280.1181640625,Validation loss: 30142.054565429688\n",
      "Epoch 4: , Train RMSE: 0.057284548939914914,Validation RMSE: 0.08794920634507462\n",
      "Epoch 4: , Train loss: 108158.88427734375,Validation loss: 30940.251586914062\n",
      "Epoch 5: , Train RMSE: 0.05029889633480848,Validation RMSE: 0.08834504522258653\n",
      "Epoch 5: , Train loss: 83388.10693359375,Validation loss: 31219.388061523438\n",
      "Epoch 6: , Train RMSE: 0.043828555454021624,Validation RMSE: 0.08812276253531473\n",
      "Epoch 6: , Train loss: 63314.25732421875,Validation loss: 31062.485107421875\n",
      "Epoch 7: , Train RMSE: 0.039975384109951086,Validation RMSE: 0.0786128947001366\n",
      "Epoch 7: , Train loss: 52671.11279296875,Validation loss: 24719.948852539062\n",
      "Epoch 8: , Train RMSE: 0.03716587470832069,Validation RMSE: 0.07022788485029914\n",
      "Epoch 8: , Train loss: 45527.721923828125,Validation loss: 19727.8232421875\n",
      "Epoch 9: , Train RMSE: 0.03514123311881138,Validation RMSE: 0.05689712167978567\n",
      "Epoch 9: , Train loss: 40702.510498046875,Validation loss: 12949.129821777344\n",
      "Epoch 10: , Train RMSE: 0.033918809921867216,Validation RMSE: 0.04921774854821949\n",
      "Epoch 10: , Train loss: 37920.007568359375,Validation loss: 9689.547088623047\n",
      "Epoch 11: , Train RMSE: 0.03290894516755165,Validation RMSE: 0.04256193194801501\n",
      "Epoch 11: , Train loss: 35695.63623046875,Validation loss: 7246.072204589844\n",
      "Epoch 12: , Train RMSE: 0.03202532764039766,Validation RMSE: 0.036895973473829675\n",
      "Epoch 12: , Train loss: 33804.48828125,Validation loss: 5445.251434326172\n",
      "Epoch 13: , Train RMSE: 0.03132201222844523,Validation RMSE: 0.033520445264075834\n",
      "Epoch 13: , Train loss: 32336.01611328125,Validation loss: 4494.481002807617\n",
      "Epoch 14: , Train RMSE: 0.030758335615416046,Validation RMSE: 0.031644186118079946\n",
      "Epoch 14: , Train loss: 31182.638916015625,Validation loss: 4005.4180603027344\n",
      "Epoch 15: , Train RMSE: 0.030330345895829613,Validation RMSE: 0.031051281566862585\n",
      "Epoch 15: , Train loss: 30320.888916015625,Validation loss: 3856.7283477783203\n",
      "Epoch 16: , Train RMSE: 0.0298294440605439,Validation RMSE: 0.030069354126530053\n",
      "Epoch 16: , Train loss: 29327.667358398438,Validation loss: 3616.6642303466797\n",
      "Epoch 17: , Train RMSE: 0.029109609835338314,Validation RMSE: 0.02908060723091843\n",
      "Epoch 17: , Train loss: 27929.294921875,Validation loss: 3382.7268676757812\n",
      "Epoch 18: , Train RMSE: 0.02856122967910149,Validation RMSE: 0.029175176399959434\n",
      "Epoch 18: , Train loss: 26886.9169921875,Validation loss: 3404.763671875\n",
      "Epoch 19: , Train RMSE: 0.02833095480279344,Validation RMSE: 0.029660109241719135\n",
      "Epoch 19: , Train loss: 26455.11328125,Validation loss: 3518.8883209228516\n",
      "Epoch 20: , Train RMSE: 0.027972265698006576,Validation RMSE: 0.028586320289119393\n",
      "Epoch 20: , Train loss: 25789.474487304688,Validation loss: 3268.7108306884766\n",
      "Epoch 21: , Train RMSE: 0.027137694073486728,Validation RMSE: 0.02713729867882469\n",
      "Epoch 21: , Train loss: 24273.538330078125,Validation loss: 2945.731918334961\n",
      "Epoch 22: , Train RMSE: 0.026330211201008168,Validation RMSE: 0.026460140697194563\n",
      "Epoch 22: , Train loss: 22850.509521484375,Validation loss: 2800.556182861328\n",
      "Epoch 23: , Train RMSE: 0.025913277673165414,Validation RMSE: 0.02612795211685521\n",
      "Epoch 23: , Train loss: 22132.57275390625,Validation loss: 2730.679527282715\n",
      "Epoch 24: , Train RMSE: 0.02532118316303597,Validation RMSE: 0.025693922738858874\n",
      "Epoch 24: , Train loss: 21132.7099609375,Validation loss: 2640.710662841797\n",
      "Epoch 25: , Train RMSE: 0.024844169568899583,Validation RMSE: 0.02520042299944976\n",
      "Epoch 25: , Train loss: 20343.991821289062,Validation loss: 2540.245277404785\n",
      "Epoch 26: , Train RMSE: 0.024503582085796453,Validation RMSE: 0.024940429591904782\n",
      "Epoch 26: , Train loss: 19790.025634765625,Validation loss: 2488.100112915039\n",
      "Epoch 27: , Train RMSE: 0.024300641270604023,Validation RMSE: 0.0247917405156764\n",
      "Epoch 27: , Train loss: 19463.57763671875,Validation loss: 2458.5215911865234\n",
      "Epoch 28: , Train RMSE: 0.024071182494950095,Validation RMSE: 0.024542107034649558\n",
      "Epoch 28: , Train loss: 19097.743408203125,Validation loss: 2409.2600708007812\n",
      "Epoch 29: , Train RMSE: 0.023766910807104292,Validation RMSE: 0.02441413109365364\n",
      "Epoch 29: , Train loss: 18617.984985351562,Validation loss: 2384.199188232422\n",
      "Epoch 30: , Train RMSE: 0.023478422222361597,Validation RMSE: 0.024261439387995267\n",
      "Epoch 30: , Train loss: 18168.748779296875,Validation loss: 2354.4697647094727\n",
      "Epoch 31: , Train RMSE: 0.023233666890378896,Validation RMSE: 0.024076768484156016\n",
      "Epoch 31: , Train loss: 17791.916015625,Validation loss: 2318.7631225585938\n",
      "Epoch 32: , Train RMSE: 0.022994435143982767,Validation RMSE: 0.023806788082356214\n",
      "Epoch 32: , Train loss: 17427.40380859375,Validation loss: 2267.052635192871\n",
      "Epoch 33: , Train RMSE: 0.022719565022061895,Validation RMSE: 0.023541874972971926\n",
      "Epoch 33: , Train loss: 17013.247802734375,Validation loss: 2216.879508972168\n",
      "Epoch 34: , Train RMSE: 0.022426190177679495,Validation RMSE: 0.023197375392437315\n",
      "Epoch 34: , Train loss: 16576.704833984375,Validation loss: 2152.472900390625\n",
      "Epoch 35: , Train RMSE: 0.02212608271729335,Validation RMSE: 0.022726640215308427\n",
      "Epoch 35: , Train loss: 16136.01416015625,Validation loss: 2066.000701904297\n",
      "Epoch 36: , Train RMSE: 0.02180403161332266,Validation RMSE: 0.022197382571595807\n",
      "Epoch 36: , Train loss: 15669.70458984375,Validation loss: 1970.8951721191406\n",
      "Epoch 37: , Train RMSE: 0.02146890142765325,Validation RMSE: 0.021813128792954876\n",
      "Epoch 37: , Train loss: 15191.716491699219,Validation loss: 1903.2503509521484\n",
      "Epoch 38: , Train RMSE: 0.02121890046622029,Validation RMSE: 0.021748658369055363\n",
      "Epoch 38: , Train loss: 14839.967651367188,Validation loss: 1892.0165634155273\n",
      "Epoch 39: , Train RMSE: 0.02113414652782768,Validation RMSE: 0.022077836798145484\n",
      "Epoch 39: , Train loss: 14721.654846191406,Validation loss: 1949.7235107421875\n",
      "Epoch 40: , Train RMSE: 0.02122891070751581,Validation RMSE: 0.022508206333262056\n",
      "Epoch 40: , Train loss: 14853.972778320312,Validation loss: 2026.477409362793\n",
      "Epoch 41: , Train RMSE: 0.021250829239312683,Validation RMSE: 0.021311351443130996\n",
      "Epoch 41: , Train loss: 14884.66162109375,Validation loss: 1816.6948013305664\n",
      "Epoch 42: , Train RMSE: 0.020663549317534637,Validation RMSE: 0.021841540485450835\n",
      "Epoch 42: , Train loss: 14073.335632324219,Validation loss: 1908.2115631103516\n",
      "Epoch 43: , Train RMSE: 0.020942593441289577,Validation RMSE: 0.021263327155599948\n",
      "Epoch 43: , Train loss: 14455.999572753906,Validation loss: 1808.5163269042969\n",
      "Epoch 44: , Train RMSE: 0.020305174916292378,Validation RMSE: 0.020836468249649517\n",
      "Epoch 44: , Train loss: 13589.412231445312,Validation loss: 1736.6336364746094\n",
      "Epoch 45: , Train RMSE: 0.0201087456292461,Validation RMSE: 0.020406639060361415\n",
      "Epoch 45: , Train loss: 13327.760009765625,Validation loss: 1665.7236709594727\n",
      "Epoch 46: , Train RMSE: 0.019757043269650477,Validation RMSE: 0.02055253767879899\n",
      "Epoch 46: , Train loss: 12865.631408691406,Validation loss: 1689.6272201538086\n",
      "Epoch 47: , Train RMSE: 0.019676976500476017,Validation RMSE: 0.0201890877492\n",
      "Epoch 47: , Train loss: 12761.565002441406,Validation loss: 1630.3970565795898\n",
      "Epoch 48: , Train RMSE: 0.019370559341195,Validation RMSE: 0.02008430845286098\n",
      "Epoch 48: , Train loss: 12367.204040527344,Validation loss: 1613.5177841186523\n",
      "Epoch 49: , Train RMSE: 0.019212012646037196,Validation RMSE: 0.020140306089967527\n",
      "Epoch 49: , Train loss: 12165.583129882812,Validation loss: 1622.527717590332\n",
      "Epoch 50: , Train RMSE: 0.019097452088203685,Validation RMSE: 0.019966028257851147\n",
      "Epoch 50: , Train loss: 12020.929809570312,Validation loss: 1594.5691375732422\n",
      "Epoch 51: , Train RMSE: 0.018905973495938276,Validation RMSE: 0.019686065524687383\n",
      "Epoch 51: , Train loss: 11781.085083007812,Validation loss: 1550.1647033691406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: , Train RMSE: 0.018773158219094664,Validation RMSE: 0.019737363804932555\n",
      "Epoch 52: , Train loss: 11616.141235351562,Validation loss: 1558.2541198730469\n",
      "Epoch 53: , Train RMSE: 0.01888412100000697,Validation RMSE: 0.02040243681583874\n",
      "Epoch 53: , Train loss: 11753.866455078125,Validation loss: 1665.037712097168\n",
      "Epoch 54: , Train RMSE: 0.019336956270050363,Validation RMSE: 0.021491767637921096\n",
      "Epoch 54: , Train loss: 12324.333251953125,Validation loss: 1847.5843048095703\n",
      "Epoch 55: , Train RMSE: 0.019696625787099534,Validation RMSE: 0.0192298541981074\n",
      "Epoch 55: , Train loss: 12787.06494140625,Validation loss: 1479.149169921875\n",
      "Epoch 56: , Train RMSE: 0.01893422413198858,Validation RMSE: 0.020772993377838746\n",
      "Epoch 56: , Train loss: 11816.319641113281,Validation loss: 1726.0690155029297\n",
      "Epoch 57: , Train RMSE: 0.019210380257089786,Validation RMSE: 0.0193812224701923\n",
      "Epoch 57: , Train loss: 12163.515869140625,Validation loss: 1502.5271377563477\n",
      "Epoch 58: , Train RMSE: 0.018743386988175407,Validation RMSE: 0.018800379653911927\n",
      "Epoch 58: , Train loss: 11579.327758789062,Validation loss: 1413.8171005249023\n",
      "Epoch 59: , Train RMSE: 0.018312617070471566,Validation RMSE: 0.01886348524712056\n",
      "Epoch 59: , Train loss: 11053.200073242188,Validation loss: 1423.3243026733398\n",
      "Epoch 60: , Train RMSE: 0.018150115005254094,Validation RMSE: 0.01901041493315667\n",
      "Epoch 60: , Train loss: 10857.903198242188,Validation loss: 1445.5835037231445\n",
      "Epoch 61: , Train RMSE: 0.01816403303692542,Validation RMSE: 0.01921666799293286\n",
      "Epoch 61: , Train loss: 10874.561889648438,Validation loss: 1477.1213150024414\n",
      "Epoch 62: , Train RMSE: 0.018152782448122334,Validation RMSE: 0.019303549510307667\n",
      "Epoch 62: , Train loss: 10861.094909667969,Validation loss: 1490.5080947875977\n",
      "Epoch 63: , Train RMSE: 0.018194652114427234,Validation RMSE: 0.018914453615086292\n",
      "Epoch 63: , Train loss: 10911.255249023438,Validation loss: 1431.026222229004\n",
      "Epoch 64: , Train RMSE: 0.01814648769867138,Validation RMSE: 0.018704690738620657\n",
      "Epoch 64: , Train loss: 10853.563720703125,Validation loss: 1399.4618225097656\n",
      "Epoch 65: , Train RMSE: 0.017977348618034437,Validation RMSE: 0.018628317620673882\n",
      "Epoch 65: , Train loss: 10652.1796875,Validation loss: 1388.056869506836\n",
      "Epoch 66: , Train RMSE: 0.017774470086129614,Validation RMSE: 0.01849032344859117\n",
      "Epoch 66: , Train loss: 10413.111694335938,Validation loss: 1367.568244934082\n",
      "Epoch 67: , Train RMSE: 0.017716633168774042,Validation RMSE: 0.01859986889598131\n",
      "Epoch 67: , Train loss: 10345.454833984375,Validation loss: 1383.8204917907715\n",
      "Epoch 68: , Train RMSE: 0.017751081799112358,Validation RMSE: 0.018978905110348755\n",
      "Epoch 68: , Train loss: 10385.725830078125,Validation loss: 1440.7953567504883\n",
      "Epoch 69: , Train RMSE: 0.017785372966635647,Validation RMSE: 0.01899690211288342\n",
      "Epoch 69: , Train loss: 10425.890441894531,Validation loss: 1443.5291595458984\n",
      "Epoch 70: , Train RMSE: 0.017810809731470277,Validation RMSE: 0.018918759228868254\n",
      "Epoch 70: , Train loss: 10455.734130859375,Validation loss: 1431.6778030395508\n",
      "Epoch 71: , Train RMSE: 0.01763441030206335,Validation RMSE: 0.01881877452350844\n",
      "Epoch 71: , Train loss: 10249.651184082031,Validation loss: 1416.5850982666016\n",
      "Epoch 72: , Train RMSE: 0.017341676613294027,Validation RMSE: 0.018129770427245593\n",
      "Epoch 72: , Train loss: 9912.184326171875,Validation loss: 1314.7543029785156\n",
      "Epoch 73: , Train RMSE: 0.01709229584306786,Validation RMSE: 0.017960407184538885\n",
      "Epoch 73: , Train loss: 9629.151184082031,Validation loss: 1290.3049049377441\n",
      "Epoch 74: , Train RMSE: 0.01694242606692129,Validation RMSE: 0.01766681423965334\n",
      "Epoch 74: , Train loss: 9461.029602050781,Validation loss: 1248.4653015136719\n",
      "Epoch 75: , Train RMSE: 0.016743964462845824,Validation RMSE: 0.017286795335200812\n",
      "Epoch 75: , Train loss: 9240.677001953125,Validation loss: 1195.3331718444824\n",
      "Epoch 76: , Train RMSE: 0.01664738070092748,Validation RMSE: 0.01763796501276621\n",
      "Epoch 76: , Train loss: 9134.378967285156,Validation loss: 1244.3912391662598\n",
      "Epoch 77: , Train RMSE: 0.01698130146023735,Validation RMSE: 0.018948210705752273\n",
      "Epoch 77: , Train loss: 9504.497192382812,Validation loss: 1436.1387557983398\n",
      "Epoch 78: , Train RMSE: 0.017442148272649834,Validation RMSE: 0.018414801588022747\n",
      "Epoch 78: , Train loss: 10027.37255859375,Validation loss: 1356.4196701049805\n",
      "Epoch 79: , Train RMSE: 0.016990376605323484,Validation RMSE: 0.018971100914459766\n",
      "Epoch 79: , Train loss: 9514.65869140625,Validation loss: 1439.6106796264648\n",
      "Epoch 80: , Train RMSE: 0.017460557399861486,Validation RMSE: 0.018393155995770308\n",
      "Epoch 80: , Train loss: 10048.55029296875,Validation loss: 1353.2327499389648\n",
      "Epoch 81: , Train RMSE: 0.016749457854255995,Validation RMSE: 0.017918462346897885\n",
      "Epoch 81: , Train loss: 9246.741394042969,Validation loss: 1284.285171508789\n",
      "Epoch 82: , Train RMSE: 0.016716864399674628,Validation RMSE: 0.01678747363624576\n",
      "Epoch 82: , Train loss: 9210.789184570312,Validation loss: 1127.277084350586\n",
      "Epoch 83: , Train RMSE: 0.016118458756481935,Validation RMSE: 0.01693082668131512\n",
      "Epoch 83: , Train loss: 8563.163330078125,Validation loss: 1146.6115684509277\n",
      "Epoch 84: , Train RMSE: 0.015963422171784696,Validation RMSE: 0.01648717665163629\n",
      "Epoch 84: , Train loss: 8399.224731445312,Validation loss: 1087.307975769043\n",
      "Epoch 85: , Train RMSE: 0.015887384519757384,Validation RMSE: 0.01625355573045654\n",
      "Epoch 85: , Train loss: 8319.400207519531,Validation loss: 1056.7122955322266\n",
      "Epoch 86: , Train RMSE: 0.015666506257339508,Validation RMSE: 0.016179796484668104\n",
      "Epoch 86: , Train loss: 8089.6832275390625,Validation loss: 1047.1432571411133\n",
      "Epoch 87: , Train RMSE: 0.015633847355803965,Validation RMSE: 0.016010152248299606\n",
      "Epoch 87: , Train loss: 8055.9903564453125,Validation loss: 1025.2999000549316\n",
      "Epoch 88: , Train RMSE: 0.015474726663437103,Validation RMSE: 0.016147861774961393\n",
      "Epoch 88: , Train loss: 7892.8377685546875,Validation loss: 1043.013759613037\n",
      "Epoch 89: , Train RMSE: 0.015460669365424938,Validation RMSE: 0.016433610173047862\n",
      "Epoch 89: , Train loss: 7878.5045166015625,Validation loss: 1080.2541732788086\n",
      "Epoch 90: , Train RMSE: 0.015405917220844115,Validation RMSE: 0.016392801814812553\n",
      "Epoch 90: , Train loss: 7822.801727294922,Validation loss: 1074.8958053588867\n",
      "Epoch 91: , Train RMSE: 0.01536351153655121,Validation RMSE: 0.016282856574574053\n",
      "Epoch 91: , Train loss: 7779.795562744141,Validation loss: 1060.5256729125977\n",
      "Epoch 92: , Train RMSE: 0.015300383470572115,Validation RMSE: 0.01580815483975157\n",
      "Epoch 92: , Train loss: 7715.9931640625,Validation loss: 999.5910377502441\n",
      "Epoch 93: , Train RMSE: 0.015067145912101332,Validation RMSE: 0.015408536265501531\n",
      "Epoch 93: , Train loss: 7482.54248046875,Validation loss: 949.6919593811035\n",
      "Epoch 94: , Train RMSE: 0.01496360975611452,Validation RMSE: 0.01563089683649297\n",
      "Epoch 94: , Train loss: 7380.060974121094,Validation loss: 977.2997436523438\n",
      "Epoch 95: , Train RMSE: 0.01501659435249064,Validation RMSE: 0.015358431906477807\n",
      "Epoch 95: , Train loss: 7432.417572021484,Validation loss: 943.5257225036621\n",
      "Epoch 96: , Train RMSE: 0.01476818529485418,Validation RMSE: 0.015294482534034511\n",
      "Epoch 96: , Train loss: 7188.552825927734,Validation loss: 935.6847839355469\n",
      "Epoch 97: , Train RMSE: 0.014879334102118598,Validation RMSE: 0.017066951799742717\n",
      "Epoch 97: , Train loss: 7297.165466308594,Validation loss: 1165.1233749389648\n",
      "Epoch 98: , Train RMSE: 0.015444698102395836,Validation RMSE: 0.015352456538057018\n",
      "Epoch 98: , Train loss: 7862.235534667969,Validation loss: 942.7916870117188\n",
      "Epoch 99: , Train RMSE: 0.01469644930657832,Validation RMSE: 0.01661204141367052\n",
      "Epoch 99: , Train loss: 7118.8861083984375,Validation loss: 1103.8396797180176\n",
      "Epoch 100: , Train RMSE: 0.01526430533632792,Validation RMSE: 0.015158920115808171\n",
      "Epoch 100: , Train loss: 7679.647613525391,Validation loss: 919.1714363098145\n",
      "Epoch 101: , Train RMSE: 0.014491929512242242,Validation RMSE: 0.01571643164584725\n",
      "Epoch 101: , Train loss: 6922.1280517578125,Validation loss: 988.0248947143555\n",
      "Epoch 102: , Train RMSE: 0.014407451451560678,Validation RMSE: 0.015226297657103397\n",
      "Epoch 102: , Train loss: 6841.660705566406,Validation loss: 927.3605613708496\n",
      "Epoch 103: , Train RMSE: 0.01439202771528817,Validation RMSE: 0.014872336750272741\n",
      "Epoch 103: , Train loss: 6827.02001953125,Validation loss: 884.7456016540527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: , Train RMSE: 0.014125393463876661,Validation RMSE: 0.015077655749356999\n",
      "Epoch 104: , Train loss: 6576.4013671875,Validation loss: 909.3428115844727\n",
      "Epoch 105: , Train RMSE: 0.014087799983592093,Validation RMSE: 0.014642581935117301\n",
      "Epoch 105: , Train loss: 6541.442932128906,Validation loss: 857.6208229064941\n",
      "Epoch 106: , Train RMSE: 0.014004477456866065,Validation RMSE: 0.014433935774078975\n",
      "Epoch 106: , Train loss: 6464.292816162109,Validation loss: 833.3540077209473\n",
      "Epoch 107: , Train RMSE: 0.013848140263610946,Validation RMSE: 0.014367606741351223\n",
      "Epoch 107: , Train loss: 6320.771789550781,Validation loss: 825.7124938964844\n",
      "Epoch 108: , Train RMSE: 0.01375196781201558,Validation RMSE: 0.014167372083865636\n",
      "Epoch 108: , Train loss: 6233.283752441406,Validation loss: 802.8577270507812\n",
      "Epoch 109: , Train RMSE: 0.01358977801377674,Validation RMSE: 0.013867659749331095\n",
      "Epoch 109: , Train loss: 6087.120910644531,Validation loss: 769.2479476928711\n",
      "Epoch 110: , Train RMSE: 0.01349992938196394,Validation RMSE: 0.013884073091805275\n",
      "Epoch 110: , Train loss: 6006.897155761719,Validation loss: 771.0699424743652\n",
      "Epoch 111: , Train RMSE: 0.013438802739082661,Validation RMSE: 0.013697164250391292\n",
      "Epoch 111: , Train loss: 5952.622772216797,Validation loss: 750.4492340087891\n",
      "Epoch 112: , Train RMSE: 0.013310461697058181,Validation RMSE: 0.014081370361734801\n",
      "Epoch 112: , Train loss: 5839.470153808594,Validation loss: 793.139965057373\n",
      "Epoch 113: , Train RMSE: 0.013432002335016013,Validation RMSE: 0.014093843616250802\n",
      "Epoch 113: , Train loss: 5946.599914550781,Validation loss: 794.545711517334\n",
      "Epoch 114: , Train RMSE: 0.013321367483819587,Validation RMSE: 0.01356098472463044\n",
      "Epoch 114: , Train loss: 5849.0430908203125,Validation loss: 735.6012268066406\n",
      "Epoch 115: , Train RMSE: 0.013311571297909549,Validation RMSE: 0.014711461718796861\n",
      "Epoch 115: , Train loss: 5840.443786621094,Validation loss: 865.708423614502\n",
      "Epoch 116: , Train RMSE: 0.013807667794319786,Validation RMSE: 0.014197805149072353\n",
      "Epoch 116: , Train loss: 6283.879699707031,Validation loss: 806.3106842041016\n",
      "Epoch 117: , Train RMSE: 0.013379636939079108,Validation RMSE: 0.014419285369180449\n",
      "Epoch 117: , Train loss: 5900.324005126953,Validation loss: 831.6631622314453\n",
      "Epoch 118: , Train RMSE: 0.013738592993467344,Validation RMSE: 0.014703589664134077\n",
      "Epoch 118: , Train loss: 6221.164978027344,Validation loss: 864.7821960449219\n",
      "Epoch 119: , Train RMSE: 0.013361907859223294,Validation RMSE: 0.014015302231218036\n",
      "Epoch 119: , Train loss: 5884.697570800781,Validation loss: 785.714786529541\n",
      "Epoch 120: , Train RMSE: 0.013466122139812431,Validation RMSE: 0.013744121231123965\n",
      "Epoch 120: , Train loss: 5976.8492431640625,Validation loss: 755.6034736633301\n",
      "Epoch 121: , Train RMSE: 0.012993211388192523,Validation RMSE: 0.014150135867271941\n",
      "Epoch 121: , Train loss: 5564.4239501953125,Validation loss: 800.9053802490234\n",
      "Epoch 122: , Train RMSE: 0.013097515914638947,Validation RMSE: 0.013288017074844992\n",
      "Epoch 122: , Train loss: 5654.120666503906,Validation loss: 706.2855911254883\n",
      "Epoch 123: , Train RMSE: 0.012819596063752506,Validation RMSE: 0.013330628780407557\n",
      "Epoch 123: , Train loss: 5416.7137451171875,Validation loss: 710.8226547241211\n",
      "Epoch 124: , Train RMSE: 0.012658254973730703,Validation RMSE: 0.01333366842246194\n",
      "Epoch 124: , Train loss: 5281.227569580078,Validation loss: 711.1468544006348\n",
      "Epoch 125: , Train RMSE: 0.012654916893593167,Validation RMSE: 0.013005256837085517\n",
      "Epoch 125: , Train loss: 5278.442535400391,Validation loss: 676.5468215942383\n",
      "Epoch 126: , Train RMSE: 0.012472122735362464,Validation RMSE: 0.013110596628296141\n",
      "Epoch 126: , Train loss: 5127.054748535156,Validation loss: 687.5509757995605\n",
      "Epoch 127: , Train RMSE: 0.012503347152410842,Validation RMSE: 0.01303516052995931\n",
      "Epoch 127: , Train loss: 5152.7584228515625,Validation loss: 679.6616401672363\n",
      "Epoch 128: , Train RMSE: 0.012428598936116383,Validation RMSE: 0.013264014551833469\n",
      "Epoch 128: , Train loss: 5091.333557128906,Validation loss: 703.736328125\n",
      "Epoch 129: , Train RMSE: 0.012464870346921232,Validation RMSE: 0.013026464960520784\n",
      "Epoch 129: , Train loss: 5121.093841552734,Validation loss: 678.7551574707031\n",
      "Epoch 130: , Train RMSE: 0.012435862053912944,Validation RMSE: 0.013383421412487303\n",
      "Epoch 130: , Train loss: 5097.285919189453,Validation loss: 716.4638748168945\n",
      "Epoch 131: , Train RMSE: 0.012593183568542695,Validation RMSE: 0.013225385186511734\n",
      "Epoch 131: , Train loss: 5227.0694580078125,Validation loss: 699.643253326416\n",
      "Epoch 132: , Train RMSE: 0.012480100254205049,Validation RMSE: 0.01333543108094234\n",
      "Epoch 132: , Train loss: 5133.615661621094,Validation loss: 711.334888458252\n",
      "Epoch 133: , Train RMSE: 0.012653588951760747,Validation RMSE: 0.013735325837882504\n",
      "Epoch 133: , Train loss: 5277.334808349609,Validation loss: 754.6367034912109\n",
      "Epoch 134: , Train RMSE: 0.012701612244771938,Validation RMSE: 0.013094677330082146\n",
      "Epoch 134: , Train loss: 5317.468231201172,Validation loss: 685.8822975158691\n",
      "Epoch 135: , Train RMSE: 0.012588731804199694,Validation RMSE: 0.014256147564390793\n",
      "Epoch 135: , Train loss: 5223.37451171875,Validation loss: 812.9509735107422\n",
      "Epoch 136: , Train RMSE: 0.012937435907344957,Validation RMSE: 0.01325928308876291\n",
      "Epoch 136: , Train loss: 5516.754089355469,Validation loss: 703.2343521118164\n",
      "Epoch 137: , Train RMSE: 0.012472916975527186,Validation RMSE: 0.014121496187967902\n",
      "Epoch 137: , Train loss: 5127.707763671875,Validation loss: 797.666618347168\n",
      "Epoch 138: , Train RMSE: 0.01285630027613202,Validation RMSE: 0.01278317856170649\n",
      "Epoch 138: , Train loss: 5447.775695800781,Validation loss: 653.6386165618896\n",
      "Epoch 139: , Train RMSE: 0.012367133263046016,Validation RMSE: 0.013565680697805024\n",
      "Epoch 139: , Train loss: 5041.099670410156,Validation loss: 736.1107711791992\n",
      "Epoch 140: , Train RMSE: 0.012415054199355324,Validation RMSE: 0.013189567042338549\n",
      "Epoch 140: , Train loss: 5080.242492675781,Validation loss: 695.858715057373\n",
      "Epoch 141: , Train RMSE: 0.012430124771195953,Validation RMSE: 0.012789751503851568\n",
      "Epoch 141: , Train loss: 5092.583740234375,Validation loss: 654.3109741210938\n",
      "Epoch 142: , Train RMSE: 0.012052245405506212,Validation RMSE: 0.012978139837721774\n",
      "Epoch 142: , Train loss: 4787.658172607422,Validation loss: 673.7284545898438\n",
      "Epoch 143: , Train RMSE: 0.011947111685267079,Validation RMSE: 0.012676864864542978\n",
      "Epoch 143: , Train loss: 4704.495422363281,Validation loss: 642.8116111755371\n",
      "Epoch 144: , Train RMSE: 0.01184406436042028,Validation RMSE: 0.012533056837610015\n",
      "Epoch 144: , Train loss: 4623.690124511719,Validation loss: 628.3100547790527\n",
      "Epoch 145: , Train RMSE: 0.011650714912129856,Validation RMSE: 0.012540070490266328\n",
      "Epoch 145: , Train loss: 4473.962646484375,Validation loss: 629.0134716033936\n",
      "Epoch 146: , Train RMSE: 0.01167771990820894,Validation RMSE: 0.012391686373611373\n",
      "Epoch 146: , Train loss: 4494.7269287109375,Validation loss: 614.2155647277832\n",
      "Epoch 147: , Train RMSE: 0.011601507113122096,Validation RMSE: 0.012659189593996837\n",
      "Epoch 147: , Train loss: 4436.2501220703125,Validation loss: 641.0203247070312\n",
      "Epoch 148: , Train RMSE: 0.011610641495946043,Validation RMSE: 0.012512324056236278\n",
      "Epoch 148: , Train loss: 4443.238586425781,Validation loss: 626.2330131530762\n",
      "Epoch 149: , Train RMSE: 0.011585190389520049,Validation RMSE: 0.012450791431075048\n",
      "Epoch 149: , Train loss: 4423.780334472656,Validation loss: 620.0888290405273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.012149072170544652, 342698)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "evalu_fun(train_data,valid_data,test_data,k=1,growth_rate=19,x=1,x1=0,x2=1,x3=0,x4=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc84fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c6264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=np.array([[1.04534897e-02, 3.42698000e+05],\n",
    "       [1.95530642e-02, 1.21760000e+04],\n",
    "       [2.38634139e-02, 3.02600000e+03],\n",
    "       [9.88223311e-03, 1.16167200e+06],\n",
    "       [1.68375230e-02, 3.35200000e+04],\n",
    "       [1.03049298e-02, 1.15408500e+06],\n",
    "       [1.55876648e-02, 4.40290000e+04],\n",
    "       [1.36610569e-02, 1.11325000e+05],\n",
    "       [1.97765148e-02, 1.20030000e+04],\n",
    "       [2.66066761e-02, 2.38400000e+03],\n",
    "       [1.66556806e-02, 3.84300000e+04],\n",
    "       [1.84929561e-02, 1.58960000e+04],\n",
    "       [1.36604024e-02, 1.37773000e+05],\n",
    "       [2.04542299e-02, 8.57800000e+03],\n",
    "       [3.83915624e-02, 1.01200000e+03],\n",
    "       [2.79909238e-02, 2.16600000e+03],\n",
    "       [2.32561915e-02, 6.63800000e+03],\n",
    "       [1.18050268e-02, 2.69061000e+05],\n",
    "       [2.81069512e-02, 1.81200000e+03],\n",
    "       [3.18072676e-02, 1.39000000e+03],\n",
    "       [1.20447973e-02, 1.48558000e+05],\n",
    "       [1.90524354e-02, 1.33160000e+04],\n",
    "       [3.38766967e-02, 1.29400000e+03],\n",
    "       [1.75316066e-02, 2.60970000e+04],\n",
    "       [1.24759808e-02, 1.46722000e+05],\n",
    "       [1.39693812e-02, 5.85420000e+04],\n",
    "       [3.57105693e-02, 1.16800000e+03],\n",
    "       [1.15170502e-02, 3.14378000e+05]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be7e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[2.18777417e-02, 3.47542000e+05],\n",
    "       [5.10757998e-02, 1.45800000e+03],\n",
    "       [4.19581472e-02, 1.81200000e+03],\n",
    "       [2.35066070e-02, 2.37533000e+05],\n",
    "       [2.44868917e-02, 1.68762000e+05],\n",
    "       [2.31570056e-02, 3.07063000e+05],\n",
    "       [2.44701033e-02, 2.03498000e+05],\n",
    "       [2.86211836e-02, 4.59140000e+04],\n",
    "       [2.56780531e-02, 1.09990000e+05],\n",
    "       [2.65491290e-02, 7.90180000e+04],\n",
    "       [2.21539980e-02, 3.08619000e+05],\n",
    "       [3.38182939e-02, 1.20030000e+04],\n",
    "       [3.02249377e-02, 2.15410000e+04],\n",
    "       [3.76529543e-02, 3.02600000e+03],\n",
    "       [3.58561627e-02, 5.83000000e+03],\n",
    "       [3.01157378e-02, 2.15800000e+04],\n",
    "       [5.24906523e-02, 1.01200000e+03],\n",
    "       [2.48055085e-02, 1.22494000e+05],\n",
    "       [2.80469888e-02, 6.11390000e+04],\n",
    "       [3.00628942e-02, 3.16610000e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaeb059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
